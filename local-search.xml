<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>markdown中的数学公式</title>
    <link href="/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"/>
    <url>/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h3 id="符号大全"><a href="#符号大全" class="headerlink" title="符号大全"></a>符号大全</h3><table><thead><tr><th align="left">写法</th><th align="center">符号</th><th align="left">备注</th></tr></thead><tbody><tr><td align="left">\sin(x)</td><td align="center">$$\sin(x)$$</td><td align="left">正弦函数</td></tr><tr><td align="left">\log(x)</td><td align="center">$$\log(x)$$</td><td align="left">对数函数</td></tr><tr><td align="left">\sum_{i&#x3D;0}^n</td><td align="center">$$\sum_{i&#x3D;0}^n$$</td><td align="left">累加和</td></tr><tr><td align="left">\prod_{i&#x3D;0}^n</td><td align="center">$$\prod_{i&#x3D;0}^n$$</td><td align="left">累积乘</td></tr><tr><td align="left">\displaystyle</td><td align="center">$$\displaystyle$$</td><td align="left">块显示</td></tr><tr><td align="left">\ldots</td><td align="center">$$\ldots$$</td><td align="left">底部省略号</td></tr><tr><td align="left">\cdots</td><td align="center">$$\cdots$$</td><td align="left">中部省略号</td></tr><tr><td align="left">\int_a^b</td><td align="center">$$\int_a^b$$</td><td align="left">积分符号</td></tr><tr><td align="left">\lim</td><td align="center">$$\lim$$</td><td align="left">极限函数</td></tr><tr><td align="left">\to</td><td align="center">$$\to$$</td><td align="left">箭头</td></tr><tr><td align="left">\vec{a}</td><td align="center">$$\vec{a}$$</td><td align="left">矢量a</td></tr><tr><td align="left">90^\circ</td><td align="center">$$90^\circ$$</td><td align="left">度数的圆圈</td></tr><tr><td align="left">\uparrow</td><td align="center">$$\uparrow$$</td><td align="left">上箭头</td></tr><tr><td align="left">\Uparrow</td><td align="center">$$\Uparrow$$</td><td align="left">双上箭头</td></tr><tr><td align="left">\partial y</td><td align="center">$$\partial y$$</td><td align="left">导数&#x2F;偏导</td></tr><tr><td align="left">\infty</td><td align="center">$$\infty$$</td><td align="left">无穷</td></tr><tr><td align="left">\Pi</td><td align="center">$$\Pi$$</td><td align="left">累乘</td></tr><tr><td align="left">\sqrt{x}</td><td align="center">$$\sqrt{x}$$</td><td align="left">求平方根</td></tr><tr><td align="left">\overline{a+b}</td><td align="center">$$\overline{a+b}$$</td><td align="left">上划线</td></tr><tr><td align="left">\underline{a+b}</td><td align="center">$$\underline{a+b}$$</td><td align="left">下划线</td></tr><tr><td align="left">\overbrace{a+b}</td><td align="center">$$\overbrace{a+b}$$</td><td align="left">上括号</td></tr><tr><td align="left">\underbrace{a+b}</td><td align="center">$$\underbrace{a+b}$$</td><td align="left">下括号</td></tr><tr><td align="left">\pm{a}{b}</td><td align="center">$$\pm{a}{b}$$</td><td align="left">正负号</td></tr><tr><td align="left">\mp{a}{b}</td><td align="center">$$\mp{a}{b}$$</td><td align="left">负正号</td></tr><tr><td align="left">\times</td><td align="center">$$\times$$</td><td align="left">乘法</td></tr><tr><td align="left">\cdot</td><td align="center">$$\cdot$$</td><td align="left">点乘</td></tr><tr><td align="left">\ast</td><td align="center">$$\ast$$</td><td align="left">星乘</td></tr><tr><td align="left">\div</td><td align="center">$$\div$$</td><td align="left">除法</td></tr><tr><td align="left">\frac{1}{5}</td><td align="center">$$\frac{1}{5}$$</td><td align="left">分数</td></tr><tr><td align="left">\drac{1}{5}</td><td align="center">$$已废弃$$</td><td align="left">分数，字体更大</td></tr><tr><td align="left">\leq</td><td align="center">$$\leq$$</td><td align="left">小于等于</td></tr><tr><td align="left">\not</td><td align="center">$$\not$$</td><td align="left">非</td></tr><tr><td align="left">\geq</td><td align="center">$$\geq$$</td><td align="left">大于等于</td></tr><tr><td align="left">\neq</td><td align="center">$$\neq$$</td><td align="left">不等于</td></tr><tr><td align="left">\nleq</td><td align="center">$$\nleq$$</td><td align="left">不小于等于</td></tr><tr><td align="left">\ngeq</td><td align="center">$$\ngeq$$</td><td align="left">不大于等于</td></tr><tr><td align="left">\sim</td><td align="center">$$\sim$$</td><td align="left">相关符号</td></tr><tr><td align="left">\approx</td><td align="center">$$\approx$$</td><td align="left">约等于</td></tr><tr><td align="left">\equiv</td><td align="center">$$\equiv$$</td><td align="left">常等于&#x2F;横等于</td></tr><tr><td align="left">\bigodot</td><td align="center">$$\bigodot$$</td><td align="left">加运算符</td></tr><tr><td align="left">\bigotimes</td><td align="center">$$\bigotimes$$</td><td align="left">乘运算符</td></tr></tbody></table><h3 id="集合符号"><a href="#集合符号" class="headerlink" title="集合符号"></a>集合符号</h3><table><thead><tr><th>写法</th><th align="center">符号</th><th>备注</th></tr></thead><tbody><tr><td>\in</td><td align="center">$$\in$$</td><td>属于</td></tr><tr><td>\notin</td><td align="center">$$\notin$$</td><td>不属于</td></tr><tr><td>\subset</td><td align="center">$$\subset$$</td><td>真子集</td></tr><tr><td>\not \subset</td><td align="center">$$\not \subset$$</td><td>非子集</td></tr><tr><td>\subseteq</td><td align="center">$$\subseteq$$</td><td>子集</td></tr><tr><td>\supset</td><td align="center">$$\supset$$</td><td>超集</td></tr><tr><td>\supseteq</td><td align="center">$$\supseteq$$</td><td>超集</td></tr><tr><td>\cup</td><td align="center">$$\cup$$</td><td>并集</td></tr><tr><td>\cap</td><td align="center">$$\cap$$</td><td>交集</td></tr><tr><td>\mathbb{R}</td><td align="center">$$\mathbb{R}$$</td><td>实数集</td></tr><tr><td>\emptyset</td><td align="center">$$\emptyset$$</td><td>空集</td></tr></tbody></table><h3 id="希腊符号"><a href="#希腊符号" class="headerlink" title="希腊符号"></a>希腊符号</h3><table><thead><tr><th>写法</th><th align="center">符号</th></tr></thead><tbody><tr><td>\alpha</td><td align="center">α</td></tr><tr><td>\beta</td><td align="center">β</td></tr><tr><td>\gamma</td><td align="center">γ</td></tr><tr><td>\Gamma</td><td align="center">Γ</td></tr><tr><td>\theta</td><td align="center">θ</td></tr><tr><td>\Theta</td><td align="center">Θ</td></tr><tr><td>\delta</td><td align="center">δ</td></tr><tr><td>\Delta</td><td align="center">Δ</td></tr><tr><td>\triangledown</td><td align="center">▽</td></tr><tr><td>\epsilon</td><td align="center">ϵ</td></tr><tr><td>\zeta</td><td align="center">ζ</td></tr><tr><td>\eta</td><td align="center">η</td></tr><tr><td>\kappa</td><td align="center">κ</td></tr><tr><td>\lambda</td><td align="center">λ</td></tr><tr><td>\mu</td><td align="center">μ</td></tr><tr><td>\nu</td><td align="center">ν</td></tr><tr><td>\xi</td><td align="center">ξ</td></tr><tr><td>\pi</td><td align="center">π</td></tr><tr><td>\sigma</td><td align="center">σ</td></tr><tr><td>\tau</td><td align="center">τ</td></tr><tr><td>\upsilon</td><td align="center">υ</td></tr><tr><td>\phi</td><td align="center">ϕ</td></tr><tr><td>\omega</td><td align="center">ω</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-5-TensorFlow</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/</url>
    
    <content type="html"><![CDATA[<h2 id="环境的安装"><a href="#环境的安装" class="headerlink" title="环境的安装"></a>环境的安装</h2><p>首先去conda官网下载  <a href="https://repo.anaconda.com/">conda</a></p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230912155352950.png" alt="选择合适的版本"></p><p>linux系统先使用bash安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo bash xxx.sh<br></code></pre></td></tr></table></figure><p>安装后在pycharm配置conda环境，然后新建AI项目，选择conda，然后在所选择的解释器中安装tensorflow</p><p>选择pycharm自动安装（会自动安装其他依赖，十分方便）</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230912155649291.png" alt="tensorflow安装"></p><p>所需安装：</p><ul><li>conda</li><li>tensorflow</li></ul><p>如果你是N卡，可继续在项目终端中输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install cudatoolkit<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install cudnn<br></code></pre></td></tr></table></figure><p>安装GUP加速</p><h2 id="1-1-人工智能三学派"><a href="#1-1-人工智能三学派" class="headerlink" title="1.1 人工智能三学派"></a>1.1 人工智能三学派</h2><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230911172021989.png" alt="三学派"></p><p>行为主义：机器人的摔倒预测</p><p>符号主义：用公式描述的人工智能，让PC具有了理性思维</p><p>连接主义：仿造人的感性思维</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230911172351969.png" alt="神经网络是连接主义"></p><h2 id="1-2神经网络的设计过程"><a href="#1-2神经网络的设计过程" class="headerlink" title="1.2神经网络的设计过程"></a>1.2神经网络的设计过程</h2><p>用神经网络实现鸢尾花的分类：<strong>梯度下降</strong></p><p>目的：找到一组参数w和b，使得损失函数最小。</p><p>梯度：函数对各参数<strong>求偏导</strong>后的向量。 <u>梯度下降的方向是函数减小的方向</u></p><p>梯度下降法：沿损失函数梯度下降的方向，寻找损失函数的最小值，得到最优参数的方法</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230912105643070.png" alt="梯度下降示意图"></p><p>学习率（lr）：设置过小，收敛缓慢；设置过大，无法收敛（找不到最小值）</p><p>反向传播：从后向前，逐层求损失函数对每层神经元参数的偏导数，迭代更新所有参数。</p><p>损失函数:<br>$$<br>loss &#x3D; （w + 1 )^2<br>$$</p><p>$$<br>\frac{\part loss}{\part w} &#x3D; 2w +2<br>$$</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>w = tf.Variable(tf.constant(<span class="hljs-number">5</span>, dtype=tf.float32))<br>lr = <span class="hljs-number">0.2</span>  <span class="hljs-comment"># 学习率</span><br>epoch = <span class="hljs-number">40</span>   <span class="hljs-comment"># 循环迭代数</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):  <span class="hljs-comment"># for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环40次迭代。</span><br>    <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:  <span class="hljs-comment"># with结构到grads框起了梯度的计算过程。</span><br>        loss = tf.square(w + <span class="hljs-number">1</span>)<br>    grads = tape.gradient(loss, w)  <span class="hljs-comment"># .gradient函数告知谁对谁求导</span><br><br>    w.assign_sub(lr * grads)  <span class="hljs-comment"># .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;After %s epoch,w is %f,loss is %f&quot;</span> % (epoch, w.numpy(), loss))<br><br><span class="hljs-comment"># lr初始值：0.2   请自改学习率  0.001  0.999 看收敛过程</span><br><span class="hljs-comment"># 最终目的：找到 loss 最小 即 w = -1 的最优参数w</span><br><br></code></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python">After <span class="hljs-number">0</span> epoch,w <span class="hljs-keyword">is</span> <span class="hljs-number">2.600000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">36.000000</span><br>After <span class="hljs-number">1</span> epoch,w <span class="hljs-keyword">is</span> <span class="hljs-number">1.160000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">12.959999</span><br>After <span class="hljs-number">2</span> epoch,w <span class="hljs-keyword">is</span> <span class="hljs-number">0.296000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">4.665599</span><br>After <span class="hljs-number">3</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.222400</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">1.679616</span><br>After <span class="hljs-number">4</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.533440</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.604662</span><br>After <span class="hljs-number">5</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.720064</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.217678</span><br>After <span class="hljs-number">6</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.832038</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.078364</span><br>After <span class="hljs-number">7</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.899223</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.028211</span><br>After <span class="hljs-number">8</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.939534</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.010156</span><br>After <span class="hljs-number">9</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.963720</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.003656</span><br>After <span class="hljs-number">10</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.978232</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.001316</span><br>After <span class="hljs-number">11</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.986939</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000474</span><br>After <span class="hljs-number">12</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.992164</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000171</span><br>After <span class="hljs-number">13</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.995298</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000061</span><br>After <span class="hljs-number">14</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.997179</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000022</span><br>After <span class="hljs-number">15</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.998307</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000008</span><br>After <span class="hljs-number">16</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.998984</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000003</span><br>After <span class="hljs-number">17</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999391</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000001</span><br>After <span class="hljs-number">18</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999634</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">19</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999781</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">20</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999868</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">21</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999921</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">22</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999953</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">23</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999972</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">24</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999983</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">25</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999990</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">26</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999994</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">27</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999996</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">28</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999998</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">29</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999999</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">30</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999999</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">31</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">32</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">33</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">34</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">35</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">36</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">37</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">38</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">39</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br></code></pre></td></tr></table></figure><h2 id="1-3-张量生成"><a href="#1-3-张量生成" class="headerlink" title="1.3 张量生成"></a>1.3 张量生成</h2><p>张量（Tensor：多维数组 &#x2F;列表  ）        阶 ：张量的维数</p><table><thead><tr><th>维数</th><th>阶</th><th>名</th><th>例</th></tr></thead><tbody><tr><td>0-D</td><td>0</td><td>标量 scalar</td><td>s&#x3D;1</td></tr><tr><td>1-D</td><td>1</td><td>向量 vector</td><td>v&#x3D;[1,2,3]</td></tr><tr><td>2-D</td><td>2</td><td>矩阵 matrix</td><td>m&#x3D;[[1,2],[3,4],[5,6]]</td></tr><tr><td>n-D</td><td>n</td><td>张量 tensor</td><td>t&#x3D;[[[[……]]]] (n个)</td></tr></tbody></table><p>数据类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">·tf.<span class="hljs-built_in">int</span>   tf.<span class="hljs-built_in">float</span> ...<br>tf.<span class="hljs-built_in">int</span> <span class="hljs-number">32</span>  , tf.<span class="hljs-built_in">float</span> <span class="hljs-number">32</span>  , tf.<span class="hljs-built_in">float</span> <span class="hljs-number">64</span><br>·tf.<span class="hljs-built_in">bool</span><br>tf.constant([true, false])<br>·tf.string<br>tf.constant(<span class="hljs-string">&quot;Hello world!&quot;</span>)<br></code></pre></td></tr></table></figure><p>创建Tensor</p><p><code>tf.constant(张量内容，dtype=数据类型(可选))</code></p><p>创建全为0的张量 <code>tf.zeros(维度)</code>  </p><p>​ 纬度:一维直接写个数；二维[行，列]；多维[n,m,j,k,…..]</p><p>创建全为1的张量 <code>tf.ones(纬度)</code></p><p>创建全为指定值的张量 <code>tf.fill(维度，指定值)</code></p><p>正态分部的随机数，默认值为0,标准差为1</p><p><code>tf.random.normal(纬度，mean=均值，stddev=标准差)</code></p><p>生成截断式正态分布的随机数</p><p><code>tf.random.truncated_normal(纬度，mean=均值，stddev=标准差)</code></p><p>在正态分布中如果随机生成的数据的取值在（$$\mu\pm2\sigma$$)</p><p>生成均匀分布的随机数</p><p><code>tf.random.uniform(纬度，minval=最小值，maxval=最大值)</code></p><h2 id="1-4-TF2常用函数"><a href="#1-4-TF2常用函数" class="headerlink" title="1.4 TF2常用函数"></a>1.4 TF2常用函数</h2><p>强制tensor转换为该数据类型<br><code>tf.cast (张量名，dtype=数据类型)</code><br>计算张量维度上元素的最小值<br><code>tf.reduce_min (张量名)</code><br>计算张量维度上元素的最大值<br><code>tf.reduce_max (张量名)</code></p><p>理解axis<br>在一个二维张量或数组中，可以通过调整 axis 等于0或1 控制执行维度。<br> axis&#x3D;0代表跨行（经度，down)，而axis&#x3D;1代表跨列（纬度，across)<br> 如果不指定axis，则所有元素参与计算。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913093248414.png" alt="理解axis"></p><p>计算张量沿着指定维度的平均值<br><code>tf.reduce_mean (张量名，axis=操作轴)</code>  (不指定axis，则对所有元素进行操作)<br>计算张量沿着指定维度的和<br><code>tf.reduce_sum (张量名，axis=操作轴)</code></p><p><code>tf.Variable () </code>将变量标记为“可训练”，被标记的变量会在反向传播<br>中记录梯度信息。神经网络训练中，常用该函数标记待训练参数。<br><code>tf.Variable(初始值)</code><br><code>w = tf.Variable(tf.random.normal([2, 2], mean=0, stddev=1))</code></p><p>TensorFlow中的数学运算<br>对应元素的四则运算：<code>tf.add</code>，<code>tf.subtract</code>，<code>tf.multiply</code>，<code>tf.divide</code>    </p><p> 只有纬度相同的张量才能做四则运算。<br>平方、次方与开方：<code> tf.square</code>，<code>tf.pow</code>，<code>tf.sqrt</code><br>矩阵乘：<code>tf.matmul</code></p><p>切分传入张量的第一维度，生成输入特征&#x2F;标签对，构建数据集<br><code>data = tf.data.Dataset.from_tensor_slices((输入特征, 标签))</code><br>（Numpy和Tensor格式都可用该语句读入数据）</p><p><code>tf.GradientTape</code><br>with结构记录计算过程，gradient求出张量的梯度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> tf.GradientTape( ) <span class="hljs-keyword">as</span> tape:<br>若干个计算过程<br>grad=tape.gradient(函数，对谁求导)<br></code></pre></td></tr></table></figure><p>enumerate是python的内建函数，它可遍历每个元素(如列表、元组<br>或字符串)，组合为：索引 元素，常在for循环中使用。<br><code>enumerate(列表名)</code></p><p>独热编码：在分类问题中，常用独热码做标签，标记类别：1表示是，0表示非。 <code>tf.one_hot (待转换数据, depth=几分类)</code></p><p>当n分类的n个输出 （y0 ，y1, …… yn-1）通过softmax( ) 函数，<br>便符合概率分布了。也就是说，将多个权重占比划分归为1。<br>$$<br>\forall x \ \ P(X &#x3D; x) \in [0,1] 且 \sum_{x}P(X &#x3D; x) &#x3D; 1<br>$$</p><p>assign_sub 赋值操作，更新参数的值并返回。<br>调用assign_sub前，先用 tf.Variable 定义变量 w 为可训练（可自更新）。<br>w.assign_sub (w要自减的内容)</p><p>返回张量沿指定维度最大值的索引<br>tf.argmax (张量名,axis&#x3D;操作轴)     numpy中也有类似函数</p><h2 id="1-5-鸢尾花数据集的读入"><a href="#1-5-鸢尾花数据集的读入" class="headerlink" title="1.5 鸢尾花数据集的读入"></a>1.5 鸢尾花数据集的读入</h2><p>Setosa Iris（狗尾草鸢尾），Versicolour Iris（杂色鸢尾），Virginica Iris（弗吉尼亚鸢尾）</p><p>鸢尾花数据来源：sklearn框架</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913105626307.png" alt="3种鸢尾花"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets <br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> DataFrame<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>x_data = datasets.load_iris().data  <span class="hljs-comment"># .data返回iris数据集所有输入特征</span><br>y_data = datasets.load_iris().target  <span class="hljs-comment"># .target返回iris数据集所有标签</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_data from datasets: \n&quot;</span>, x_data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y_data from datasets: \n&quot;</span>, y_data)<br><br>x_data = DataFrame(x_data, columns=[<span class="hljs-string">&#x27;花萼长度&#x27;</span>, <span class="hljs-string">&#x27;花萼宽度&#x27;</span>, <span class="hljs-string">&#x27;花瓣长度&#x27;</span>, <span class="hljs-string">&#x27;花瓣宽度&#x27;</span>])  <span class="hljs-comment"># 为表格增加行索引（左侧）和列标签（上方）</span><br>pd.set_option(<span class="hljs-string">&#x27;display.unicode.east_asian_width&#x27;</span>, <span class="hljs-literal">True</span>)  <span class="hljs-comment"># 设置列名对齐</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_data add index: \n&quot;</span>, x_data)<br><br>x_data[<span class="hljs-string">&#x27;类别&#x27;</span>] = y_data  <span class="hljs-comment"># 新加一列，列标签为‘类别’，数据为y_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_data add a column: \n&quot;</span>, x_data)<br><br><span class="hljs-comment"># 类型维度不确定时，建议用print函数打印出来确认效果</span><br></code></pre></td></tr></table></figure><h2 id="1-8-神经网络实现鸢尾花的分类"><a href="#1-8-神经网络实现鸢尾花的分类" class="headerlink" title="1.8 神经网络实现鸢尾花的分类"></a>1.8 神经网络实现鸢尾花的分类</h2><p>1.准备数据</p><p>​数据集读入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 从sklearn包datasets 读入数据集：</span><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> datasets<br>x_data = datasets.load_iris().data <span class="hljs-comment"># 返回iris数据集所有输入特征</span><br>y_data = datasets.load_iris().target <span class="hljs-comment"># 返回iris数据集所有标签</span><br></code></pre></td></tr></table></figure><p>​数据集乱序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">116</span>) <span class="hljs-comment"># 使用相同的seed，使输入特征/标签一一对应</span><br>np.random.shuffle(x_data)<br>np.random.seed(<span class="hljs-number">116</span>)<br>np.random.shuffle(y_data)<br>tf.random.set_seed(<span class="hljs-number">116</span>)<br></code></pre></td></tr></table></figure><p>​分成用不相见的训练集和测试集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x_train = x_data[:-<span class="hljs-number">30</span>]<br>y_train = y_data[:-<span class="hljs-number">30</span>]<br>x_test = x_data[-<span class="hljs-number">30</span>:]<br>y_test = y_data[-<span class="hljs-number">30</span>:]<br></code></pre></td></tr></table></figure><p>​配成【输入特征，标签】对，每次喂入一个batch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(<span class="hljs-number">32</span>)<br>test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="hljs-number">32</span>)<br></code></pre></td></tr></table></figure><p>2.搭建网络</p><p>​定义神经网络中的所有可训练参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">w1 = tf.Variable(tf.random.truncated_normal([ <span class="hljs-number">4</span>, <span class="hljs-number">3</span> ], stddev=<span class="hljs-number">0.1</span>, seed=<span class="hljs-number">1</span>)) <span class="hljs-comment"># 四种特征，三个结果</span><br>b1 = tf.Variable(tf.random.truncated_normal([ <span class="hljs-number">3</span> ], stddev=<span class="hljs-number">0.1</span>, seed=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913140637316.png" alt="输入层与输出层"></p><p>3.参数优化</p><p>​嵌套循环迭代，with结构更新参数，显示当前loss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch): <span class="hljs-comment">#数据集级别迭代</span><br><span class="hljs-keyword">for</span> step, (x_train, y_train) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_db): <span class="hljs-comment">#batch级别迭代</span><br><span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape: <span class="hljs-comment"># 记录梯度信息</span><br>前向传播过程计算y<br>计算总loss<br>grads = tape.gradient(loss, [ w1, b1 ])<br>w1.assign_sub(lr * grads[<span class="hljs-number">0</span>]) <span class="hljs-comment">#参数自更新</span><br>b1.assign_sub(lr * grads[<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, loss_all/<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><p>4.测试效果</p><p>​计算当前参数前向传播后的准确率，显示当前acc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> x_test, y_test <span class="hljs-keyword">in</span> test_db:<br>y = tf.matmul(h, w) + b <span class="hljs-comment"># y为预测结果</span><br>y = tf.nn.softmax(y)<br><span class="hljs-comment"># y符合概率分布</span><br>pred = tf.argmax(y, axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 返回y中最大值的索引，即预测的分类</span><br>pred = tf.cast(pred, dtype=y_test.dtype) <span class="hljs-comment">#调整数据类型与标签一致</span><br>correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)<br>correct = tf.reduce_sum (correct) <span class="hljs-comment"># 将每个batch的correct数加起来</span><br>total_correct += <span class="hljs-built_in">int</span> (correct) <span class="hljs-comment"># 将所有batch中的correct数加起来</span><br>total_number += x_test.shape [<span class="hljs-number">0</span>]<br>acc = total_correct / total_number<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;test_acc:&quot;</span>, acc)<br></code></pre></td></tr></table></figure><p>5.acc &#x2F; loss 可视化（查看效果）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.title(<span class="hljs-string">&#x27;Acc Curve&#x27;</span>) <span class="hljs-comment"># 图片标题</span><br>plt.xlabel(<span class="hljs-string">&#x27;Epoch&#x27;</span>) <span class="hljs-comment"># x轴名称</span><br>plt.ylabel(<span class="hljs-string">&#x27;Acc&#x27;</span>) <span class="hljs-comment"># y轴名称</span><br>plt.plot(test_acc, label=<span class="hljs-string">&quot;$Accuracy$&quot;</span>) <span class="hljs-comment"># 逐点画出test_acc值并连线</span><br>plt.legend()<br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="2-1-预备知识"><a href="#2-1-预备知识" class="headerlink" title="2.1 预备知识"></a>2.1 预备知识</h2><p>函数：</p><p><code>tf.where()</code>  条件语句真返回A，条件语句假返回B<br><code>tf.where(条件语句，真返回A，假返回B)</code></p><p><code>np.random.RandomState.rand()</code>返回一个[0,1)之间的随机数<br><code>np.random.RandomState.rand(维度) #维度为空，返回标量</code></p><p><code>np.vstack()</code>将两个数组按垂直方向叠加<br><code>np.vstack(数组1，数组2)</code></p><p><code>np.mgrid[ ] </code>返回间隔数值点，可同时返回多组， [起始值 结束值)<br><code>np.mgrid[ 起始值 : 结束值 : 步长 ，起始值 : 结束值 : 步长 , … ]</code></p><p><code> x.ravel( )</code> 将x变为一维数组，“把. 前变量拉直”<br><code>np.c\_[ ] </code>使返回的间隔数值点配对<br><code>np.c\_[ 数组1，数组2， … ]</code></p><h2 id="2-2-复杂度学习率"><a href="#2-2-复杂度学习率" class="headerlink" title="2.2 复杂度学习率"></a>2.2 复杂度学习率</h2><p>NN复杂度：多用NN层数和NN参数的个数表示</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913145516199.png" alt="复杂度"></p><p>空间复杂度：<br>    层数 &#x3D; 隐藏层的层数 + 1个输出层<br>    图为2层NN<br>                总参数 &#x3D; 总w + 总b<br>                图中 3x4+4 + 4x2+2 &#x3D; 26</p><p>时间复杂度：<br>    乘加运算次数<br>    左图 3x4 +  4x2 &#x3D; 20</p><p>学习率：</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913150028635.png" alt="学习率"></p><p>指数衰减学习率：<br>可以先用较大的学习率，快速得到较优解，然后逐步减小学习率，使<br>模型在训练后期稳定。<br><code>指数衰减学习率 = 初始学习率 * 学习率衰减率（ 当前轮数 / 多少轮衰减一次 ）</code></p><h2 id="2-3-激活函数"><a href="#2-3-激活函数" class="headerlink" title="2.3 激活函数"></a>2.3 激活函数</h2><p>优秀的激活函数：<br>• 非线性： 激活函数非线性时，多层神经网络可逼近所有函数<br>• 可微性： 优化器大多用梯度下降更新参数<br>• 单调性： 当激活函数是单调的，能保证单层网络的损失函数是凸函数<br>• 近似恒等性： f(x)≈x当参数初始化为随机小值时，神经网络更稳定</p><p>激活函数输出值的范围：<br>• 激活函数输出为有限值时，基于梯度的优化方法更稳定<br>• 激活函数输出为无限值时，建议调小学习率</p><p>Sigmoid函数：<br>$$<br>f(x) &#x3D; \frac{1}{1 + e ^ {-x}}<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913151017142.png" alt="Sigmoid函数"></p><p>特点<br>（1）易造成梯度消失<br>（2）输出非0均值，收敛慢<br>（3）幂运算复杂，训练时间长<br>目前Sigmoid函数因计算复杂，已接近弃用。</p><p>Tanh函数：<br>$$<br>f(x) &#x3D; \frac{1-e^{-2x}}{1+e^{-2x}}<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913151343657.png" alt="Tanh函数"></p><p>特点<br>（1）输出是0均值<br>（2）易造成梯度消失<br>（3）幂运算复杂，训练时间长</p><p>Relu函数：<br>$$<br>f(x) &#x3D; max(x , 0) &#x3D; \begin{cases}0 \quad x&lt;0 \x \quad x\geq0 \end{cases}<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913152152906.png" alt="Relu函数"></p><p>优点：<br>（1） 解决了梯度消失问题 (在正区间)<br>（2） 只需判断输入是否大于0，计算速度快<br>（3） 收敛速度远快于sigmoid和tanh</p><p>缺点：<br>（1） 输出非0均值，收敛慢<br>（2） Dead RelU问题：某些神经元可能永远不会被激活，导致相应的参数永远不能被更新。（神经元死亡）</p><p>Leaky Relu函数：<br>$$<br>f(x) &#x3D; max (ax,x)<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913152543744.png" alt="Leaky Relu函数"></p><p>理论上来讲，Leaky Relu有Relu的所有优点，外加不会有Dead Relu问题，但是在实际操作当中，并没有完全证明Leaky Relu总是好于Relu。</p><p>对于初学者的建议：<br>首选relu激活函数；<br>学习率设置较小值；<br>输入特征标准化，即让输入特征满足以0为均值，1为标准差的正态分布；<br>初始参数中心化，即让随机生成的参数满足以0为均值，<br>$$<br>\sqrt{\frac{2}{当前层输入特征个数}}<br>$$<br>为标准差的正态分布。</p><h2 id="2-4-损失函数"><a href="#2-4-损失函数" class="headerlink" title="2.4 损失函数"></a>2.4 损失函数</h2><p>预测值（y）与已知答案（_y）的差距</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913153356947.png" alt="主流的三种计算方法"></p><p>均方误差mse：<br>$$<br>MSE(y_,y)&#x3D;\frac{\sum_{i&#x3D;1}^n (y-y_)^2}{n}<br>$$<br><code>lost_mse = tf.reduce_mean(tf.square(y_-y))</code></p><p>自定义函数：</p><p>可在一定程度上优化实际问题中的预测误差。</p><p>交叉熵CE：</p><p>表明了两个概率分布之间的距离，交叉熵越大，表明两个概率分布越远<br>$$<br>H(y_,y) &#x3D; - \sum y_ \times ln\ y<br>$$<br>交叉熵越小，证明数据距离真实越准确。</p><p>softmax与交叉熵的结合：</p><p>在TensorFlow中提供了函数<code>tf.nn.softmax_cross_entropy_with_logits(y_，y)</code>输出先过softmax函数，再计算y与y_的交叉熵损失函数。</p><h2 id="2-5-缓解过拟合"><a href="#2-5-缓解过拟合" class="headerlink" title="2.5 缓解过拟合"></a>2.5 缓解过拟合</h2><p>欠拟合与过拟合</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913162344502.png" alt="欠拟合与过拟合"></p><table><thead><tr><th>欠拟合的解决方法：<br/>增加输入特征项<br/>增加网络参数<br/>减少正则化参数</th><th>过拟合的解决方法：<br/>数据清洗<br/>增大训练集<br/>采用正则化<br/>增大正则化参数</th></tr></thead></table><p>正则化缓解过拟合：</p><p>正则化在损失函数中引入模型复杂度指标，利用给W加权值，弱化了训练<br>数据的噪声（一般不正则化b）</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913162811491.png" alt="正则化"></p><p>正则化的选择<br>L1正则化大概率会使很多参数变为零，因此该方法可通过稀疏参数，即减少参数的数量，降低复杂度。<br>L2正则化会使参数很接近零但不为零，因此该方法可通过减小参数值的大小降低复杂度。</p><p>使用L2正则化缓解过拟合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:  <span class="hljs-comment"># 记录梯度信息</span><br><br>           h1 = tf.matmul(x_train, w1) + b1  <span class="hljs-comment"># 记录神经网络乘加运算</span><br>           h1 = tf.nn.relu(h1)<br>           y = tf.matmul(h1, w2) + b2<br><br>           <span class="hljs-comment"># 采用均方误差损失函数mse = mean(sum(y-out)^2)</span><br>           loss_mse = tf.reduce_mean(tf.square(y_train - y))<br>           <span class="hljs-comment"># 添加l2正则化</span><br>           loss_regularization = []<br>           <span class="hljs-comment"># tf.nn.l2_loss(w)=sum(w ** 2) / 2</span><br>           loss_regularization.append(tf.nn.l2_loss(w1))<br>           loss_regularization.append(tf.nn.l2_loss(w2))<br>           <span class="hljs-comment"># 求和</span><br>           <span class="hljs-comment"># 例：x=tf.constant(([1,1,1],[1,1,1]))</span><br>           <span class="hljs-comment">#   tf.reduce_sum(x)</span><br>           <span class="hljs-comment"># &gt;&gt;&gt;6</span><br>           loss_regularization = tf.reduce_sum(loss_regularization)<br>           loss = loss_mse + <span class="hljs-number">0.03</span> * loss_regularization  <span class="hljs-comment"># REGULARIZER = 0.03</span><br><br>       <span class="hljs-comment"># 计算loss对各个参数的梯度</span><br>       variables = [w1, b1, w2, b2]<br>       grads = tape.gradient(loss, variables)<br></code></pre></td></tr></table></figure><p>下表可以看出，L2正则化函数可有效的缓解过饱和现象</p><table><thead><tr><th><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913170454005.png" alt="未填加L2正则化"></th><th><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913170523568.png" alt="加入了L2正则化"></th></tr></thead></table><h2 id="2-6-优化器"><a href="#2-6-优化器" class="headerlink" title="2.6 优化器"></a>2.6 优化器</h2><p>是引导神经网络更新参数的工具。</p><p>神经网络参数优化器：<br>待优化参数𝒘，损失函数loss，学习率lr，每次迭代一个batch，t表示当前batch迭代的总次数：</p><ol><li>计算t时刻损失函数关于当前参数的梯度 $g_t&#x3D;\triangledown loss &#x3D; \frac{\partial loss}{\partial (w_t)} $</li><li>计算t时刻一阶动量 $m_t$ 和二阶动量$V_t$</li><li>计算t时刻下降梯度：$\eta_t &#x3D;\frac{lr·m_t}{\sqrt{V_t}}$</li><li>计算t+1时刻参数：$w_{t+1} &#x3D; w_t - \eta_t &#x3D; w_t - \frac{lr·m_t}{\sqrt{V_t}}$</li></ol><p>一阶动量：与梯度相关的函数<br>二阶动量：与梯度平方相关的函数</p><p>SGD(无momentum)，常用的梯度下降算法：</p><p>$m_t &#x3D; g_t $ $V_t &#x3D; 1$</p><p>$\eta_t &#x3D; \frac{lr·m_t}{\sqrt{V_t}} $</p><p>$w_{t+1} &#x3D; w_t -\eta_t &#x3D; w_t - \frac{lr·m_t}{\sqrt{V_t}} \ &#x3D;w_t - lr·g_t $</p><p>$w_{t+1} &#x3D; w_t -lr \ast \frac{\partial loss}{\partial w_t}  \ 参数更新公式$</p><p>SGDM(含momentum的SGD)，在SGD的基础上增加了一阶动量</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-4-PyTorch</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-3-数据分析实战</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-2-Pandas</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-1-Numpy</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/</url>
    
    <content type="html"><![CDATA[<p>NumPy用于数据分析，提供了大量的维度数组与矩阵运算，NumPy 通常与 SciPy（Scientific Python）和 Matplotlib（绘图库）一起使用。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><code>sudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose</code></p><p>或使用pycharm在import numpy后自动导入。</p><h3 id="N-维数组对象-ndarray"><a href="#N-维数组对象-ndarray" class="headerlink" title="N 维数组对象 ndarray"></a>N 维数组对象 ndarray</h3><p>ndarray 中的每个元素在内存中都有相同存储大小的区域</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.array(<span class="hljs-built_in">object</span>, dtype = <span class="hljs-literal">None</span>, copy = <span class="hljs-literal">True</span>, order = <span class="hljs-literal">None</span>, subok = <span class="hljs-literal">False</span>, ndmin = <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">object</td><td align="left">数组或嵌套的数列</td></tr><tr><td align="left">dtype</td><td align="left">数组元素的数据类型，可选</td></tr><tr><td align="left">copy</td><td align="left">对象是否需要复制，可选</td></tr><tr><td align="left">order</td><td align="left">创建数组的样式，C为行方向，F为列方向，A为任意方向（默认）</td></tr><tr><td align="left">subok</td><td align="left">默认返回一个与基类类型一致的数组</td></tr><tr><td align="left">ndmin</td><td align="left">指定生成数组的最小维度</td></tr></tbody></table><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>int8, int16, int32, int64 四种数据类型可以使用字符串 ‘i1’, ‘i2’,’i4’,’i8’ 代替</p><table><thead><tr><th align="left">名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">bool_</td><td align="left">布尔型数据类型（True 或者 False）</td></tr><tr><td align="left">int_</td><td align="left">默认的整数类型（类似于 C 语言中的 long，int32 或 int64）</td></tr><tr><td align="left">intc</td><td align="left">与 C 的 int 类型一样，一般是 int32 或 int 64</td></tr><tr><td align="left">intp</td><td align="left">用于索引的整数类型（类似于 C 的 ssize_t，一般情况下仍然是 int32 或 int64）</td></tr><tr><td align="left">int8</td><td align="left">字节（-128 to 127）</td></tr><tr><td align="left">int16</td><td align="left">整数（-32768 to 32767）</td></tr><tr><td align="left">int32</td><td align="left">整数（-2147483648 to 2147483647）</td></tr><tr><td align="left">int64</td><td align="left">整数（-9223372036854775808 to 9223372036854775807）</td></tr><tr><td align="left">uint8</td><td align="left">无符号整数（0 to 255）</td></tr><tr><td align="left">uint16</td><td align="left">无符号整数（0 to 65535）</td></tr><tr><td align="left">uint32</td><td align="left">无符号整数（0 to 4294967295）</td></tr><tr><td align="left">uint64</td><td align="left">无符号整数（0 to 18446744073709551615）</td></tr><tr><td align="left">float_</td><td align="left">float64 类型的简写</td></tr><tr><td align="left">float16</td><td align="left">半精度浮点数，包括：1 个符号位，5 个指数位，10 个尾数位</td></tr><tr><td align="left">float32</td><td align="left">单精度浮点数，包括：1 个符号位，8 个指数位，23 个尾数位</td></tr><tr><td align="left">float64</td><td align="left">双精度浮点数，包括：1 个符号位，11 个指数位，52 个尾数位</td></tr><tr><td align="left">complex_</td><td align="left">complex128 类型的简写，即 128 位复数</td></tr><tr><td align="left">complex64</td><td align="left">复数，表示双 32 位浮点数（实数部分和虚数部分）</td></tr><tr><td align="left">complex128</td><td align="left">复数，表示双 64 位浮点数（实数部分和虚数部分）</td></tr></tbody></table><p>在创建dtype中（数据类型对象），每个内建类型都有一个唯一定义它的字符代码</p><table><thead><tr><th align="left">字符</th><th align="left">对应类型</th></tr></thead><tbody><tr><td align="left">b</td><td align="left">布尔型</td></tr><tr><td align="left">i</td><td align="left">(有符号) 整型</td></tr><tr><td align="left">u</td><td align="left">无符号整型 integer</td></tr><tr><td align="left">f</td><td align="left">浮点型</td></tr><tr><td align="left">c</td><td align="left">复数浮点型</td></tr><tr><td align="left">m</td><td align="left">timedelta（时间间隔）</td></tr><tr><td align="left">M</td><td align="left">datetime（日期时间）</td></tr><tr><td align="left">O</td><td align="left">(Python) 对象</td></tr><tr><td align="left">S, a</td><td align="left">(byte-)字符串</td></tr><tr><td align="left">U</td><td align="left">Unicode</td></tr><tr><td align="left">V</td><td align="left">原始数据 (void)</td></tr></tbody></table><h3 id="Numpy数组"><a href="#Numpy数组" class="headerlink" title="Numpy数组"></a>Numpy数组</h3><p>维数——秩（rank），维度——轴（axis）</p><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">ndarray.ndim</td><td align="left">秩，即轴的数量或维度的数量</td></tr><tr><td align="left">ndarray.shape</td><td align="left">数组的维度，对于矩阵，n 行 m 列</td></tr><tr><td align="left">ndarray.size</td><td align="left">数组元素的总个数，相当于 .shape 中 n*m 的值</td></tr><tr><td align="left">ndarray.dtype</td><td align="left">ndarray 对象的元素类型</td></tr><tr><td align="left">ndarray.itemsize</td><td align="left">ndarray 对象中每个元素的大小，以字节为单位</td></tr><tr><td align="left">ndarray.flags</td><td align="left">ndarray 对象的内存信息</td></tr><tr><td align="left">ndarray.real</td><td align="left">ndarray元素的实部</td></tr><tr><td align="left">ndarray.imag</td><td align="left">ndarray 元素的虚部</td></tr><tr><td align="left">ndarray.data</td><td align="left">包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。</td></tr></tbody></table><p>数组的创建</p><p><code>numpy.empty</code> 方法用来创建一个指定形状（shape）、数据类型（dtype）且未初始化的数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.empty(shape, dtype = <span class="hljs-built_in">float</span>, order = <span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">shape</td><td align="left">数组形状</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选</td></tr><tr><td align="left">order</td><td align="left">有”C”和”F”两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序。</td></tr></tbody></table><p><code>numpy.zeros</code> 创建指定大小的数组，数组元素以 0 来填充：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.zeros(shape, dtype = <span class="hljs-built_in">float</span>, order = <span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">shape</td><td align="left">数组形状</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选 默认为浮点数</td></tr><tr><td align="left">order</td><td align="left">‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组</td></tr></tbody></table><p><code>numpy.ones</code> 创建指定形状的数组，数组元素以 1 来填充：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.ones(shape, dtype = <span class="hljs-literal">None</span>, order = <span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">shape</td><td align="left">数组形状</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选 默认为浮点数</td></tr><tr><td align="left">order</td><td align="left">‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组</td></tr></tbody></table><p><code>numpy.zeros_like</code>  <code>numpy.ones_like</code> 创建一个模仿数组，以1或者0进行填充。</p><p>numpy.asarray 类似 numpy.array，但 numpy.asarray 参数只有三个，比 numpy.array 少两个。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">numpy.asarray(a, dtype = None, <span class="hljs-keyword">order</span> <span class="hljs-title">= None</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">a</td><td align="left">任意形式的输入参数，可以是，列表, 列表的元组, 元组, 元组的元组, 元组的列表，多维数组</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选</td></tr><tr><td align="left">order</td><td align="left">可选，有”C”和”F”两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序。</td></tr></tbody></table><p>例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>x = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>a = np.asarray(x)<br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-built_in">print</span>(a)<br></code></pre></td></tr></table></figure><h6 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br><span class="hljs-comment">#由此可以看出list和array的区别</span><br></code></pre></td></tr></table></figure><p><code>numpy.frombuffer</code> 用于实现动态数组。</p><p><code>numpy.frombuffer</code> 接受 buffer 输入参数，以流的形式读入转化成 ndarray 对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.frombuffer(buffer, dtype = <span class="hljs-built_in">float</span>, count = -<span class="hljs-number">1</span>, offset = <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">buffer</td><td align="left">可以是任意对象，会以流的形式读入。</td></tr><tr><td align="left">dtype</td><td align="left">返回数组的数据类型，可选</td></tr><tr><td align="left">count</td><td align="left">读取的数据数量，默认为-1，读取所有数据。</td></tr><tr><td align="left">offset</td><td align="left">读取的起始位置，默认为0。</td></tr></tbody></table><p><code>numpy.fromiter</code> 方法从可迭代对象中建立 ndarray 对象，返回一维数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.fromiter(iterable, dtype, count=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">iterable</td><td align="left">可迭代对象</td></tr><tr><td align="left">dtype</td><td align="left">返回数组的数据类型</td></tr><tr><td align="left">count</td><td align="left">读取的数据数量，默认为-1，读取所有数据</td></tr></tbody></table><p>从数值范围创建数组</p><p>numpy 包中的使用 arange 函数创建数值范围并返回 ndarray 对象，函数格式如下：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">numpy.<span class="hljs-built_in">arange</span>(start, stop, step, dtype)<br></code></pre></td></tr></table></figure><p>根据 start 与 stop 指定的范围以及 step 设定的步长，生成一个 ndarray。</p><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>start</code></td><td align="left">起始值，默认为<code>0</code></td></tr><tr><td align="left"><code>stop</code></td><td align="left">终止值（不包含）</td></tr><tr><td align="left"><code>step</code></td><td align="left">步长，默认为<code>1</code></td></tr><tr><td align="left"><code>dtype</code></td><td align="left">返回<code>ndarray</code>的数据类型，如果没有提供，则会使用输入数据的类型。</td></tr></tbody></table><p><code>numpy.linspace</code> 函数用于创建一个一维数组，数组是一个等<strong>差数列构</strong>成的，格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">np.linspace(start, stop, <span class="hljs-attribute">num</span>=50, <span class="hljs-attribute">endpoint</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">retstep</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">dtype</span>=None)<br></code></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>start</code></td><td align="left">序列的起始值</td></tr><tr><td align="left"><code>stop</code></td><td align="left">序列的终止值，如果<code>endpoint</code>为<code>true</code>，该值包含于数列中</td></tr><tr><td align="left"><code>num</code></td><td align="left">要生成的等步长的样本数量，默认为<code>50</code></td></tr><tr><td align="left"><code>endpoint</code></td><td align="left">该值为 <code>true</code> 时，数列中包含<code>stop</code>值，反之不包含，默认是True。</td></tr><tr><td align="left"><code>retstep</code></td><td align="left">如果为 True 时，生成的数组中会显示间距，反之不显示。</td></tr><tr><td align="left"><code>dtype</code></td><td align="left"><code>ndarray</code> 的数据类型</td></tr></tbody></table><p><code>numpy.logspace</code> 函数用于创建一个于<strong>等比数列</strong>。格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">np.logspace(start, stop, <span class="hljs-attribute">num</span>=50, <span class="hljs-attribute">endpoint</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">base</span>=10.0, <span class="hljs-attribute">dtype</span>=None)<br></code></pre></td></tr></table></figure><p>base 参数意思是取对数的时候 log 的下标。</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>start</code></td><td align="left">序列的起始值为：base ** start</td></tr><tr><td align="left"><code>stop</code></td><td align="left">序列的终止值为：base ** stop。如果<code>endpoint</code>为<code>true</code>，该值包含于数列中</td></tr><tr><td align="left"><code>num</code></td><td align="left">要生成的等步长的样本数量，默认为<code>50</code></td></tr><tr><td align="left"><code>endpoint</code></td><td align="left">该值为 <code>true</code> 时，数列中中包含<code>stop</code>值，反之不包含，默认是True。</td></tr><tr><td align="left"><code>base</code></td><td align="left">对数 log 的底数。</td></tr><tr><td align="left"><code>dtype</code></td><td align="left"><code>ndarray</code> 的数据类型</td></tr></tbody></table><h3 id="切片和索引"><a href="#切片和索引" class="headerlink" title="切片和索引"></a>切片和索引</h3><p>与list的切片相差不大，使用slice方法或者[:::] (start:finish:step)即可，另外对于多维数组的切分，可使用省略号<code>...</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br><span class="hljs-built_in">print</span>(a[..., <span class="hljs-number">1</span>])  <span class="hljs-comment"># 第2列元素</span><br><span class="hljs-built_in">print</span>(a[<span class="hljs-number">1</span>, ...])  <span class="hljs-comment"># 第2行元素</span><br><span class="hljs-built_in">print</span>(a[..., <span class="hljs-number">1</span>:])  <span class="hljs-comment"># 第2列及剩下的所有元素</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">[[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br> [<span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br> [<span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span>]]<br>---------------------<br>[<span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br>---------------------<br>[<span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br>---------------------<br>[[<span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br> [<span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br> [<span class="hljs-number">5</span> <span class="hljs-number">6</span>]]<br></code></pre></td></tr></table></figure><p>整数数组索引是指使用一个数组来访问另一个数组的元素。这个数组中的每个元素都是目标数组中某个维度上的索引值。</p><p>以下实例获取了 4X3 数组中的四个角的元素。 行索引是 [0,0] 和 [3,3]，而列索引是 [0,2] 和 [0,2]。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br> <br>x = np.array([[  <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>],[  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>],[  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],[  <span class="hljs-number">9</span>,  <span class="hljs-number">10</span>,  <span class="hljs-number">11</span>]])  <br><span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;我们的数组是：&#x27;</span> )<br><span class="hljs-built_in">print</span> (x)<br><span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;\n&#x27;</span>)<br>rows = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]]) <br>cols = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]]) <br><span class="hljs-comment">#这里的索引是0 0,0 2,3 0,3 2</span><br>y = x[rows,cols]  <br><span class="hljs-built_in">print</span>  (<span class="hljs-string">&#x27;这个数组的四个角元素是：&#x27;</span>)<br><span class="hljs-built_in">print</span> (y)<br><br></code></pre></td></tr></table></figure><h6 id="Output-1"><a href="#Output-1" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">我们的数组是：<br>[[ <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>]<br> [ <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>]<br> [ <span class="hljs-number">6</span>  <span class="hljs-number">7</span>  <span class="hljs-number">8</span>]<br> [ <span class="hljs-number">9</span> <span class="hljs-number">10</span> <span class="hljs-number">11</span>]]<br><br><br>这个数组的四个角元素是：<br>[[ <span class="hljs-number">0</span>  <span class="hljs-number">2</span>]<br> [ <span class="hljs-number">9</span> <span class="hljs-number">11</span>]]<br></code></pre></td></tr></table></figure><p>关于 np.ix_ 的具体使用：</p><p><code>x[np.ix_([1,5,7,2],[0,3,1,2])]</code> 这句话会输出一个4*4的矩阵，其中的元素分别是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]<br>x[<span class="hljs-number">5</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">5</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">5</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">5</span>,<span class="hljs-number">2</span>]<br>x[<span class="hljs-number">7</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">7</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">7</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">7</span>,<span class="hljs-number">2</span>]<br>x[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure><p>相当于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">y=np.array([[x[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], x[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], x[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]],\<br>            [x[<span class="hljs-number">5</span>,<span class="hljs-number">0</span>], x[<span class="hljs-number">5</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">5</span>,<span class="hljs-number">1</span>],x[<span class="hljs-number">5</span>,<span class="hljs-number">2</span>]],\<br>            [x[<span class="hljs-number">7</span>,<span class="hljs-number">0</span>] ,x[<span class="hljs-number">7</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">7</span>,<span class="hljs-number">1</span>], x[<span class="hljs-number">7</span>,<span class="hljs-number">2</span>]],\<br>            [x[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>], x[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>], x[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]]])<br></code></pre></td></tr></table></figure><p>就是说，如果 np.xi_ 中输入两个列表，则第一个列表存的是待提取元素的行标，第二个列表存的是待提取元素的列标，第一个列表中的每个元素都会遍历第二个列表中的每个值，构成新矩阵的一行元素。</p><h3 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h3><p>广播(Broadcast)是 numpy 对不同形状(shape)的数组进行数值计算的方式， 对数组的算术运算通常在相应的元素上进行。</p><p>如果两个数组 a 和 b 形状相同，即满足 <strong>a.shape &#x3D;&#x3D; b.shape</strong>，那么 a*b 的结果就是 a 与 b 数组对应位相乘。这要求维数相同，且各维度的长度相同。</p><p>但是两个数组形状不同时，numpy就触发了广播机制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>              [<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>],<br>              [<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">20</span>],<br>              [<span class="hljs-number">30</span>, <span class="hljs-number">30</span>, <span class="hljs-number">30</span>]])<br>b = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<br><span class="hljs-built_in">print</span>(a + b)<br></code></pre></td></tr></table></figure><p><img src="https://www.runoob.com/wp-content/uploads/2018/10/image0020619.gif" alt="img"></p><h6 id="Output-2"><a href="#Output-2" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">[[ <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>]<br> [<span class="hljs-number">10</span> <span class="hljs-number">11</span> <span class="hljs-number">12</span>]<br> [<span class="hljs-number">20</span> <span class="hljs-number">21</span> <span class="hljs-number">22</span>]<br> [<span class="hljs-number">30</span> <span class="hljs-number">31</span> <span class="hljs-number">32</span>]]<br></code></pre></td></tr></table></figure><h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><p>NumPy 迭代器对象<code>numpy.nditer</code>提供了一种灵活访问一个或者多个数组元素的方式。</p><p><code>for x in np.nditer(a, order=&#39;F&#39;):</code>Fortran order，即是列序优先；</p><p><code>for x in np.nditer(a.T, order=&#39;C&#39;):</code>C order，即是行序优先；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.nditer(a, op_flags=[<span class="hljs-string">&#x27;readwrite&#x27;</span>]): <br>    x[...]=<span class="hljs-number">2</span>*x <br></code></pre></td></tr></table></figure><p><strong>x[…]</strong> 是修改原 numpy 元素，x 只是个拷贝。</p><p>order &#x3D; ‘C’，numpy 实例（也就是一个多维数组）本身的存储顺序不会因为转置或 order &#x3D; ‘C’ 或 ‘F’ 而改变。</p><p>只是 numpy 实例中，存储了一个默认的访问顺序的字段。</p><p>numpy.copy 做了特殊处理，它拷贝的时候不是直接把对方的内存复制，而是按照上面 order 指定的顺序逐一拷贝。</p><p><strong>for x in np.nditer(a, order &#x3D; ‘C’)</strong>: 可以在循环中另外指定顺序，如果未指定，则按照上面数组的order顺序访问。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.nditer(a, flags = [<span class="hljs-string">&#x27;external_loop&#x27;</span>], order = <span class="hljs-string">&#x27;F&#x27;</span>): <br>    <span class="hljs-built_in">print</span> (x, end=<span class="hljs-string">&quot;, &quot;</span> )<br></code></pre></td></tr></table></figure><p>**flags &#x3D; [‘external_loop’]**，当数组的 order 与在循环中指定的 order 顺序不同时，打印为多个一维数组，当相同时，是整个一个一维数组。</p><h3 id="数组操作"><a href="#数组操作" class="headerlink" title="数组操作"></a>数组操作</h3><p>这一部分基本上一些方法，这里只对方法的函数名和描述给出。</p><p><strong>修改数组形状</strong></p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>reshape</code></td><td align="left">不改变数据的条件下修改形状 numpy.reshape(arr, newshape, order&#x3D;’C’)</td></tr><tr><td align="left"><code>flat</code></td><td align="left">数组元素迭代器</td></tr><tr><td align="left"><code>flatten</code></td><td align="left">返回一份数组拷贝，对拷贝所做的修改不会影响原始数组 ndarray.flatten(order&#x3D;’C’)</td></tr><tr><td align="left"><code>ravel</code></td><td align="left">返回展开数组 numpy.ravel(a, order&#x3D;’C’)</td></tr></tbody></table><p><strong>翻转数组</strong></p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>transpose</code></td><td align="left">对换数组的维度 numpy.transpose(arr, axes)</td></tr><tr><td align="left"><code>ndarray.T</code></td><td align="left">和 <code>self.transpose()</code> 相同</td></tr><tr><td align="left"><code>rollaxis</code></td><td align="left">向后滚动指定的轴 numpy.rollaxis(arr, axis, start)</td></tr><tr><td align="left"><code>swapaxes</code></td><td align="left">对换数组的两个轴 numpy.swapaxes(arr, axis1, axis2)</td></tr></tbody></table><p><strong>修改数组维度</strong></p><table><thead><tr><th align="left">维度</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>broadcast</code></td><td align="left">产生模仿广播的对象</td></tr><tr><td align="left"><code>broadcast_to</code></td><td align="left">将数组广播到新形状 numpy.broadcast_to(array, shape, subok)</td></tr><tr><td align="left"><code>expand_dims</code></td><td align="left">扩展数组的形状  numpy.expand_dims(arr, axis)</td></tr><tr><td align="left"><code>squeeze</code></td><td align="left">从数组的形状中删除一维条目 numpy.squeeze(arr, axis)</td></tr></tbody></table><p><strong>连接数组</strong></p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>concatenate</code></td><td align="left">连接沿现有轴的数组序列 numpy.concatenate((a1, a2, …), axis)</td></tr><tr><td align="left"><code>stack</code></td><td align="left">沿着新的轴加入一系列数组。 numpy.stack(arrays, axis)</td></tr><tr><td align="left"><code>hstack</code></td><td align="left">水平堆叠序列中的数组（列方向）</td></tr><tr><td align="left"><code>vstack</code></td><td align="left">竖直堆叠序列中的数组（行方向）</td></tr></tbody></table><p><strong>分割数组</strong></p><table><thead><tr><th align="left">函数</th><th align="left">数组及操作</th></tr></thead><tbody><tr><td align="left"><code>split</code></td><td align="left">将一个数组分割为多个子数组 numpy.split(ary, indices_or_sections, axis)</td></tr><tr><td align="left"><code>hsplit</code></td><td align="left">将一个数组水平分割为多个子数组（按列）</td></tr><tr><td align="left"><code>vsplit</code></td><td align="left">将一个数组垂直分割为多个子数组（按行）</td></tr></tbody></table><p><strong>数组元素的添加与删除</strong></p><table><thead><tr><th align="left">函数</th><th align="left">元素及描述</th></tr></thead><tbody><tr><td align="left"><code>resize</code></td><td align="left">返回指定形状的新数组 numpy.resize(arr, shape)</td></tr><tr><td align="left"><code>append</code></td><td align="left">将值添加到数组末尾 numpy.append(arr, values, axis&#x3D;None)</td></tr><tr><td align="left"><code>insert</code></td><td align="left">沿指定轴将值插入到指定下标之前 numpy.insert(arr, obj, values, axis)</td></tr><tr><td align="left"><code>delete</code></td><td align="left">删掉某个轴的子数组，并返回删除后的新数组 Numpy.delete(arr, obj, axis)</td></tr><tr><td align="left"><code>unique</code></td><td align="left">查找数组内的唯一元素 numpy.unique(arr, return_index, return_inverse, return_counts)</td></tr></tbody></table><h3 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h3><p>Numpy也是内置位运算函数的，我认为这部分了解即可</p><p><a href="https://www.runoob.com/numpy/numpy-binary-operators.html">菜鸟教程-NumPy 位运算</a></p><p>NumPy <strong>“bitwise_”</strong> 开头的函数是位运算函数。</p><p>NumPy 位运算包括以下几个函数：</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>bitwise_and</code></td><td align="left">对数组元素执行位与操作</td></tr><tr><td align="left"><code>bitwise_or</code></td><td align="left">对数组元素执行位或操作</td></tr><tr><td align="left"><code>invert</code></td><td align="left">按位取反</td></tr><tr><td align="left"><code>left_shift</code></td><td align="left">向左移动二进制表示的位</td></tr><tr><td align="left"><code>right_shift</code></td><td align="left">向右移动二进制表示的位</td></tr></tbody></table><p><strong>注：</strong>也可以使用 “&amp;”、 “~”、 “|” 和 “^” 等操作符进行计算。</p><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>Numpy的字符串函数是基于Python内置库中的标准字符串函数。</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>add()</code></td><td align="left">对两个数组的逐个字符串元素进行连接</td></tr><tr><td align="left"><code>multiply()</code></td><td align="left">返回按元素多重连接后的字符串</td></tr><tr><td align="left"><code>center()</code></td><td align="left">居中字符串</td></tr><tr><td align="left"><code>capitalize()</code></td><td align="left">将字符串第一个字母转换为大写</td></tr><tr><td align="left"><code>title()</code></td><td align="left">将字符串的每个单词的第一个字母转换为大写</td></tr><tr><td align="left"><code>lower()</code></td><td align="left">数组元素转换为小写</td></tr><tr><td align="left"><code>upper()</code></td><td align="left">数组元素转换为大写</td></tr><tr><td align="left"><code>split()</code></td><td align="left">指定分隔符对字符串进行分割，并返回数组列表</td></tr><tr><td align="left"><code>splitlines()</code></td><td align="left">返回元素中的行列表，以换行符分割</td></tr><tr><td align="left"><code>strip()</code></td><td align="left">移除元素开头或者结尾处的特定字符</td></tr><tr><td align="left"><code>join()</code></td><td align="left">通过指定分隔符来连接数组中的元素</td></tr><tr><td align="left"><code>replace()</code></td><td align="left">使用新字符串替换字符串中的所有子字符串</td></tr><tr><td align="left"><code>decode()</code></td><td align="left">数组元素依次调用<code>str.decode</code></td></tr><tr><td align="left"><code>encode()</code></td><td align="left">数组元素依次调用<code>str.encode</code></td></tr></tbody></table><h3 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h3><p>提供了标准的三角函数：**sin()、cos()、tan()**。</p><p><strong>arcsin，arccos，和 arctan</strong> 函数返回给定角度的 sin，cos 和 tan 的反三角函数。</p><p>这些函数的结果可以通过<code>numpy.degrees()</code>函数将弧度转换为角度。</p><p><code>numpy.around()</code> 函数返回指定数字的四舍五入值。<br><code>numpy.around(a,decimals)</code> decimals: 舍入的小数位数。 默认值为0。 如果为负，整数将四舍五入到小数点左侧的位置</p><p><code>numpy.floor()</code> 返回小于或者等于指定表达式的最大整数，即向下取整。</p><p><code>numpy.ceil()</code> 返回大于或者等于指定表达式的最小整数，即向上取整。</p><p>NumPy 算术函数包含简单的加减乘除: <strong>add()<strong>，</strong>subtract()<strong>，</strong>multiply()</strong> 和 **divide()**。</p><p><code>numpy.reciprocal() </code>函数返回参数逐元素的<strong>倒数</strong>。如 <strong>1&#x2F;4</strong> 倒数为 <strong>4&#x2F;1</strong>。</p><p><code>numpy.power() </code>函数将第一个输入数组中的元素作为底数，计算它与第二个输入数组中相应元素的幂。</p><p><code>numpy.mod() </code>计算输入数组中相应元素的相除后的余数。函数<code>numpy.remainder()</code>也产生相同的结果。</p><h3 id="统计学"><a href="#统计学" class="headerlink" title="统计学"></a>统计学</h3><p>NumPy 提供了很多统计函数，用于从数组中查找最小元素，最大元素，百分位标准差和方差等。</p><p>这些统计学函数通常带有较多的传入参数，详见<a href="https://www.runoob.com/numpy/numpy-statistical-functions.html">统计学函数</a></p><p><code>numpy.amin()</code> 用于计算数组中的元素沿指定轴的最小值。</p><p><code>numpy.amax() </code>用于计算数组中的元素沿指定轴的最大值。</p><p><code>numpy.ptp()</code>函数计算数组中元素最大值与最小值的差（最大值 - 最小值）。</p><p><code>numpy.percentile()</code>百分位数是统计中使用的度量，表示小于这个值的观察值的百分比。 </p><p><code>numpy.median() </code>函数用于计算数组 a 中元素的中位数（中值）</p><p><code>numpy.mean()</code> 函数返回数组中元素的算术平均值，如果提供了轴，则沿其计算。</p><p><code>numpy.average() </code>函数根据在另一个数组中给出的各自的权重计算数组中元素的加权平均值。</p><p>标准差是一组数据平均值分散程度的一种度量。标准差是方差的算术平方根。</p><p>标准差公式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">std = sqrt(mean((x - x.mean())**<span class="hljs-number">2</span>))<br><span class="hljs-comment">#使用例：</span><br><span class="hljs-built_in">print</span> (np.std([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]))<br>&gt;&gt; <span class="hljs-number">1.1180339887498949</span><br></code></pre></td></tr></table></figure><p>统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数，</p><p>即 <code>mean((x - x.mean())** 2)</code></p><p>换句话说，标准差是方差的平方根。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#使用例：</span><br><span class="hljs-built_in">print</span> (np.var([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]))<br>&gt;&gt; <span class="hljs-number">1.25</span><br></code></pre></td></tr></table></figure><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><table><thead><tr><th align="left">种类</th><th align="left">速度</th><th align="left">最坏情况</th></tr></thead><tbody><tr><td align="left"><code>quicksort</code>（快速排序）</td><td align="left">1</td><td align="left"><code>O(n^2)</code></td></tr><tr><td align="left"><code>mergesort</code>（归并排序）</td><td align="left">2</td><td align="left"><code>O(n*log(n))</code></td></tr><tr><td align="left"><code>heapsort</code>（堆排序）</td><td align="left">3</td><td align="left"><code>O(n*log(n))</code></td></tr></tbody></table><p><code>numpy.sort() </code>函数返回输入数组的排序副本，numpy中还能以字段关键字排序。</p><p>倒序使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = <span class="hljs-built_in">abs</span>(np.sort(-x)) <br></code></pre></td></tr></table></figure><p><code>numpy.argsort() </code>函数返回的是数组值从小到大的索引值。</p><p><code>numpy.lexsort() </code>用于对多个序列进行排序。把它想象成对电子表格进行排序，每一列代表一个序列，排序时优先照顾靠后的列。</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>msort(a)</code></td><td align="left">数组按第一个轴排序，返回排序后的数组副本。np.msort(a) 相等于 np.sort(a, axis&#x3D;0)。</td></tr><tr><td align="left"><code>sort_complex(a)</code></td><td align="left">对复数按照先实部后虚部的顺序进行排序。</td></tr><tr><td align="left"><code>partition(a, kth[, axis, kind, order])</code></td><td align="left">指定一个数，对数组进行分区</td></tr><tr><td align="left"><code>argpartition(a, kth[, axis, kind, order])</code></td><td align="left">可以通过关键字 kind 指定算法沿着指定轴对数组进行分区</td></tr></tbody></table><p><code>numpy.argmax()</code> 和 <code>numpy.argmin()</code>函数分别沿给定轴返回最大和最小元素的索引。</p><p><code>numpy.nonzero() </code>函数返回输入数组中非零元素的索引。</p><p><code>numpy.where() </code>函数返回输入数组中满足给定条件的元素的索引。</p><p><code>numpy.extract()</code>函数根据某个条件从数组中抽取元素，返回满条件的元素。</p><h3 id="字节交换"><a href="#字节交换" class="headerlink" title="字节交换"></a>字节交换</h3><ul><li><strong>大端模式：</strong>指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中，这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放；这和我们的阅读习惯一致。</li><li><strong>小端模式：</strong>指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低。</li></ul><p><code>numpy.ndarray.byteswap() </code>函数将 ndarray 中每个元素中的字节进行大小端转换。</p><p>(我并不知道这样做这有什么用)</p><h3 id="副本和视图"><a href="#副本和视图" class="headerlink" title="副本和视图"></a>副本和视图</h3><p>和数据库语言的副本、视图类似。</p><p>视图或浅拷贝：<code>ndarray.view() </code>方会创建一个新的数组对象，该方法创建的新数组的维数变化不会改变原始数据的维数。</p><p>副本或深拷贝：<code>ndarray.copy() </code>函数创建一个副本。 对副本数据进行修改，不会影响到原始数据，它们物理内存不在同一位置。</p><h3 id="矩阵（matrix）与线性代数"><a href="#矩阵（matrix）与线性代数" class="headerlink" title="矩阵（matrix）与线性代数"></a>矩阵（matrix）与线性代数</h3><p>一个 m * n 的矩阵</p><p>转置： numpy.transpose 函数来对换数组的维度，还可以使用 <strong>T</strong> 属性。例如有个 m 行 n 列的矩阵，使用 t() 函数就能转换为 n 行 m 列的矩阵。</p><p><code>matlib.empty() </code>函数返回一个新的矩阵。</p><p><code>numpy.matlib.zeros() </code>函数创建一个以 0 填充的矩阵。</p><p><code>numpy.matlib.ones()</code>函数创建一个以 1 填充的矩阵。</p><p><code>numpy.matlib.eye()</code> 函数返回一个矩阵，对角线元素为 1，其他位置为零。</p><p><code>numpy.matlib.identity() </code>函数返回给定大小的单位矩阵。</p><p><code>numpy.matlib.rand() </code>函数创建一个给定大小的矩阵，数据是随机填充的。</p><p><strong>线性代数</strong>函数库 <strong>linalg</strong>，该库包含了线性代数所需的所有功能</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>dot</code></td><td align="left">两个数组的点积，即元素对应相乘。numpy.dot(a, b, out&#x3D;None)</td></tr><tr><td align="left"><code>vdot</code></td><td align="left">两个向量的点积</td></tr><tr><td align="left"><code>inner</code></td><td align="left">两个数组的内积</td></tr><tr><td align="left"><code>matmul</code></td><td align="left">两个数组的矩阵积</td></tr><tr><td align="left"><code>determinant</code></td><td align="left">数组的行列式</td></tr><tr><td align="left"><code>solve</code></td><td align="left">求解线性矩阵方程</td></tr><tr><td align="left"><code>inv</code></td><td align="left">计算矩阵的乘法逆矩阵</td></tr></tbody></table><p><code>numpy.linalg.det() </code>函数计算输入矩阵的行列式。</p><p><code>numpy.linalg.solve() </code>函数给出了矩阵形式的线性方程的解。</p><p><a href="https://www.runoob.com/numpy/numpy-linear-algebra.html">详见</a></p><h3 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h3><p>NumPy 为 ndarray 对象引入了一个简单的文件格式：<strong>npy</strong>。</p><p>npy 文件用于存储重建 ndarray 所需的数据、图形、dtype 和其他信息。</p><p><code>numpy.save() </code>函数将数组保存到以 .npy 为扩展名的文件中。</p><p><code>numpy.savez() </code>函数将多个数组保存到以 npz 为扩展名的文件中。</p><p><code>savetxt()</code> 函数是以简单的文本文件格式存储数据，对应的使用<code> loadtxt()</code> 函数来获取数据。</p><h3 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h3><p>Matplotlib 是 Python 的绘图库。 它可与 NumPy 一起使用，提供了一种有效的 MatLab 开源替代方案。 它也可以和图形工具包一起使用，如 PyQt 和 wxPython。</p><p><a href="https://search.bilibili.com/all?keyword=Matplotlib&from_source=webtop_search&spm_id_from=333.1007&search_source=5">详见</a></p><p>FINISH TIME ： </p><p>10:37:37  2023年9月12日星期二</p>]]></content>
    
    
    
    <tags>
      
      <tag>Numpy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1-基础部分-2-数学基础</title>
    <link href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <url>/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>1-基础部分-1-Python</title>
    <link href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/"/>
    <url>/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/</url>
    
    <content type="html"><![CDATA[<h1>Chapter 1</h1><h2 id="1-1-分解序列"><a href="#1-1-分解序列" class="headerlink" title="1.1 分解序列"></a>1.1 分解序列</h2><p>需要元素数量匹配，除了元组和列表，其余可迭代也可执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data = [<span class="hljs-string">&#x27;ACME&#x27;</span>, <span class="hljs-number">50</span>, <span class="hljs-number">91.9</span>, (<span class="hljs-number">2023</span>, <span class="hljs-number">9</span>, <span class="hljs-number">9</span>)]<br>name, shares, price, data = data<br><br><span class="hljs-built_in">print</span>(name, data)<br><br></code></pre></td></tr></table></figure><h6 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">ACME (<span class="hljs-number">2023</span>, <span class="hljs-number">9</span>, <span class="hljs-number">9</span>)<br></code></pre></td></tr></table></figure><h2 id="1-2-从可迭代对象中分解元素"><a href="#1-2-从可迭代对象中分解元素" class="headerlink" title="1.2 从可迭代对象中分解元素"></a>1.2 从可迭代对象中分解元素</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">avg</span>(<span class="hljs-params">nums</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(nums)/<span class="hljs-built_in">len</span>(nums)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">drop_fst_and_lst</span>(<span class="hljs-params">self</span>):<br>    fst, *mid, lst = self<br>    <span class="hljs-keyword">return</span> avg(mid)<br><br><br>grades = [<span class="hljs-number">100</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(drop_fst_and_lst(grades))<br></code></pre></td></tr></table></figure><h6 id="Output-1"><a href="#Output-1" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">10.0</span><br></code></pre></td></tr></table></figure><p>Tips:</p><p>将函数传入值改为self可避免暴露函数内的变量名。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">line = <span class="hljs-string">&#x27;gting:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false&#x27;</span><br><br>unmae, *fields, homedir, sh = line<span class="hljs-selector-class">.split</span>(<span class="hljs-string">&#x27;:&#x27;</span>)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(unmae)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(homedir)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(sh)</span></span><br></code></pre></td></tr></table></figure><h6 id="Output-2"><a href="#Output-2" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">gting<br>/var/empty<br>/usr/<span class="hljs-built_in">bin</span>/false<br></code></pre></td></tr></table></figure><h2 id="1-3-双向队列"><a href="#1-3-双向队列" class="headerlink" title="1.3 双向队列"></a>1.3 双向队列</h2><p>初始化：<code>q = deque(maxlen=?)</code></p><p><code>q.append(?)</code> 右侧插入元素</p><p><code>q.appendleft(?)</code> 左侧插入元素</p><p><code>q.pop()</code> 弹出右侧元素</p><p><code>q.popleft()</code> 弹出左侧元素</p><p>如果不指定队列的大小就是一个无限的队列，可在两段进行插入和弹出，并且都是O(1)，而列表是O(n)</p><h2 id="1-4-堆heapq"><a href="#1-4-堆heapq" class="headerlink" title="1.4 堆heapq"></a>1.4 堆<code>heapq</code></h2><p>找到最大或者最小的N个元素。</p><p><code>imort heapq</code></p><p><code>heapq</code>中有两个函数 <code>nlargest()</code> 和 <code>nsmallest()</code> </p><p><code>heapq.nlargest(?, ?list, key)</code> 取出最大的前三项，最小同理。</p><p><code>heapq.heapify(?list)</code>将list排序为小顶堆</p><p><code>heapq.heappop()</code> 获取弹出对顶元素，O(logn)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> heapq<br><br>portfolio = [<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;IBM&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">100</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">91.1</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;AAPL&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">50</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">543.22</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;FB&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">200</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">21.09</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;HPQ&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">31.75</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;YHOO&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">16.35</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;ACME&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">75</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">115.65</span>&#125;<br>]<br><br>cheap = heapq.nsmallest(<span class="hljs-number">3</span>, portfolio, key=<span class="hljs-keyword">lambda</span> s: s[<span class="hljs-string">&#x27;price&#x27;</span>])<br>expensive = heapq.nlargest(<span class="hljs-number">3</span>, portfolio, key=<span class="hljs-keyword">lambda</span> s: s[<span class="hljs-string">&#x27;price&#x27;</span>])<br><br><span class="hljs-built_in">print</span>(cheap)<br><span class="hljs-built_in">print</span>(expensive)<br></code></pre></td></tr></table></figure><h6 id="Output-3"><a href="#Output-3" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">[&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;YHOO&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">16.35</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;FB&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">200</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">21.09</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;HPQ&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">31.75</span>&#125;]<br>[&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;AAPL&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">50</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">543.22</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;ACME&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">75</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">115.65</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;IBM&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">100</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">91.1</span>&#125;]<br></code></pre></td></tr></table></figure><h2 id="1-5-优先队列"><a href="#1-5-优先队列" class="headerlink" title="1.5 优先队列"></a>1.5 优先队列</h2><p>使用 <code>heap</code>实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># example.py</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Example of a priority queue</span><br><br><span class="hljs-keyword">import</span> heapq<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PriorityQueue</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._queue = []<br>        self._index = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">push</span>(<span class="hljs-params">self, item, priority</span>):<br>        heapq.heappush(self._queue, (-priority, self._index, item))<br>        self._index += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pop</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> heapq.heappop(self._queue)[-<span class="hljs-number">1</span>]<br><br><br><span class="hljs-comment"># Example use</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Item</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name</span>):<br>        self.name = name<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Item(&#123;!r&#125;)&#x27;</span>.<span class="hljs-built_in">format</span>(self.name)<br><br><br>q = PriorityQueue()<br>q.push(Item(<span class="hljs-string">&#x27;foo&#x27;</span>), <span class="hljs-number">1</span>)<br>q.push(Item(<span class="hljs-string">&#x27;bar&#x27;</span>), <span class="hljs-number">5</span>)<br>q.push(Item(<span class="hljs-string">&#x27;spam&#x27;</span>), <span class="hljs-number">4</span>)<br>q.push(Item(<span class="hljs-string">&#x27;grok&#x27;</span>), <span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be bar:&quot;</span>, q.pop())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be spam:&quot;</span>, q.pop())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be foo:&quot;</span>, q.pop())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be grok:&quot;</span>, q.pop())<br></code></pre></td></tr></table></figure><h6 id="Output-4"><a href="#Output-4" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">Should be bar: Item(<span class="hljs-string">&#x27;bar&#x27;</span>)<br>Should be spam: Item(<span class="hljs-string">&#x27;spam&#x27;</span>)<br>Should be foo: Item(<span class="hljs-string">&#x27;foo&#x27;</span>)<br>Should be grok: Item(<span class="hljs-string">&#x27;grok&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="1-6-一键多值字典multdct"><a href="#1-6-一键多值字典multdct" class="headerlink" title="1.6 一键多值字典multdct"></a>1.6 一键多值字典<code>multdct</code></h2><p>使用<code>from collections import defaultdict</code></p><p>使用例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">d = defaultdict(<span class="hljs-built_in">list</span>)<br>d[<span class="hljs-string">&#x27;a&#x27;</span>].append(<span class="hljs-number">1</span>)<br>d[<span class="hljs-string">&#x27;a&#x27;</span>].append(<span class="hljs-number">2</span>)<br><br>d2 = defaultdict(<span class="hljs-built_in">set</span>)<br>d2[<span class="hljs-string">&#x27;a&#x27;</span>].add(<span class="hljs-number">1</span>)<br>d2[<span class="hljs-string">&#x27;a&#x27;</span>].add(<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><h2 id="1-7-有序字典"><a href="#1-7-有序字典" class="headerlink" title="1.7 有序字典"></a>1.7 有序字典</h2><p>使用<code>from collections import OrderedDict</code> 会严格按照字典添加的顺序进行。</p><p>可在JSON编码中控制各字段的顺序。</p><p>1.8 字典中的计算</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习入门</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3-机器学习-1-理论</title>
    <link href="/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/"/>
    <url>/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>test1</title>
    <link href="/2023/09/08/test1/"/>
    <url>/2023/09/08/test1/</url>
    
    <content type="html"><![CDATA[<p>Hello World</p><p>Hello Everyone</p><p><code>print(&#39;hello world!&#39;)</code></p><p>你好！</p><p>Test image</p><p><img src="/../images/Irena.png"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/09/05/hello-world/"/>
    <url>/2023/09/05/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
