<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>0-SAM2POINT: SEGMENT ANY 3D AS VIDEOS IN ZERO-SHOT AND PROMPTABLE MANNERS</title>
    <link href="/2024/10/08/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/"/>
    <url>/2024/10/08/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/</url>
    
    <content type="html"><![CDATA[<h2 id="SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS"><a href="#SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS" class="headerlink" title="SAM2POINT: SEGMENT ANY 3D AS VIDEOS IN ZERO-SHOT AND PROMPTABLE MANNERS"></a>SAM2POINT: SEGMENT ANY 3D AS VIDEOS IN ZERO-SHOT AND PROMPTABLE MANNERS</h2><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008112130387.png" alt="SAM2POINT"></p><blockquote><p>arXiv:2408.16768v1 [cs.CV] 29 Aug 2024 </p><p>SAM2POINT：以零镜头和提示的方式将任何 3D 分割为视频</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>SAM2有Zero-shot和可提示的3D分割，本文作者提出SAM2POINT将任何3D数据解释为多向视频，利用SAM2进行空间分割，支持3D点，蒙版，框提示进行分割，并且泛化到3D 对象、室内场景、室外场景和原始激光雷达各种场景。</p><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008150840497.png" alt="方法比较"></p><p>SAM自被提出后，在各个领域有广泛的应用，但是有效地调整 SAM 以适应 3D 分割仍然是一个尚未解决的挑战，存在的问题有：2D-3D 投影效率低下、3D 空间信息退化、失去提示灵活性、有限的域可转移性，本文提出的SAM2POINT展示在不同环境中有效的分割潜力，具体是：将任何 3D 分割为视频，支持多个 3D 提示、可推广到各种场景的优点。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008150615480.png" alt="图1：SAM2POINT"></p><p>图1:SAM2POINT 的分割范式。我们引入了一个零镜头和可提示的框架，用于通过 SAM 2 进行稳健的 3D 分割（Ravi et al.， 2024）。它支持各种用户提供的 3D 提示，并且可以泛化到不同的 3D 场景。3D 提示和分段结果分别以红色和绿色突出显示</p><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008162421021.png" alt="图2:SAM2POINT的详细方法"></p><p>图 2：SAM2POINT 的详细方法。将任何输入的 3D 数据转换为体素化表示，并利用用户提供的 3D 提示沿六个方向划分 3D 空间，从而有效地模拟 SAM 2 的六个不同视频以执行零镜头分割。</p><h4 id="1-将3D数据视为视频"><a href="#1-将3D数据视为视频" class="headerlink" title="1.将3D数据视为视频"></a>1.将3D数据视为视频</h4><p>将3D的一个点视为$P&#x3D;(x,y,z,r,g,b)$，将P表示为一种数据格式，很好的保留细粒度的空间几何图形，采用3D体索化技术（在之前的工作中，体索化在3D空间中避免信息退化和繁琐的后处理）。</p><p>3D体索化表示为$v \in R ^{w\times h\times l \times l}$，每个体索为$v&#x3D;(r,g,b)$，根据在最近的体索中心位置设置v的值，此格式与视频很类似，视频数据包含t帧的时间依赖性，作者将体索表示为一系列的多向视频，从而让SAM2以与视频相同的方式分割3D。</p><h4 id="2-可提示的分割"><a href="#2-可提示的分割" class="headerlink" title="2.可提示的分割"></a>2.可提示的分割</h4><p>SAM2POINT支持3种不同的提示方式进行分割：</p><ul><li>3D点提示：$p_p&#x3D;(x_p,y_p,z_p)$，为空间中的锚点，以此点分为F、B、L、R、U、D六个面，然后将其视为6个不同的视频，该点作为第一帧，$P_p$作为2D投影点提示，应用SAM2进行并发分割，最后将6个视频整合为最终的3D蒙版预测。</li></ul><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008163405740.png" alt="3D点提示"></p><ul><li>3D框提示：$b_p&#x3D;(x_p,y_p,z_p,w_p,h_p,l_p)$，使用$b_p$的几何中心为锚点，进行3D点提示，对于6个面的其中一个面，使用$b_p$投影到目标2D面，作为分割的框点，另外还支持$(\alpha p,\beta p,\gamma p)$的旋转角度的3D框，原理同上。</li></ul><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008163421100.png" alt="3D框提示"></p><ul><li>3D蒙版提示：$M_p\in R^{n\times 1}$，其中1或0表示蒙版或未蒙版区域，以蒙版的重心作为提示点，分割为6个面的视频，3D 蒙版提示与每个部分之间的交集用作分段的 2D 蒙版提示。这种类型的提示还可以用作后优化步骤，以提高先前预测的 3D 掩码的准确性。</li></ul><p><img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008163434701.png" alt="3D蒙版提示"></p><h4 id="3-任何3D场景"><a href="#3-任何3D场景" class="headerlink" title="3.任何3D场景"></a>3.任何3D场景</h4><p>3D 对象：具有广泛的类别，在不同实例中具有独特的特征，包括颜色、形状和几何形状。对象的相邻组件可能会相互重叠、遮挡或集成，这需要模型准确识别零件分割的细微差异。</p><p>室内场景：通常以多个对象布置在密闭空间（如房间）内为特征。复杂的空间布局、外观的相似性以及对象之间的不同方向给模型从背景中分割它们带来了挑战。</p><p>室外场：与室内场景不同，主要是由于物体（建筑物、车辆和人类）的鲜明尺寸对比和更大比例的点云（从一个房间到整条街道）。这些变化使对象的分割变得复杂，无论是在全局范围内还是在细粒度级别。</p><p>原始激光雷达（Raw LiDAR）：例如自动驾驶中，与典型的点云不同，因为它分布稀疏且缺乏 RGB 信息。稀疏性要求模型推断缺失的语义来理解场景，而缺乏颜色迫使模型仅依靠几何线索来区分对象。在 SAM2POINT 中，直接通过 LiDAR 强度设置 3D 体素的 RGB 值。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>论文仅展示了3种分割方式在4种数据上的分割结果，并未对分割的准确率进行展示，上文展示了3种分割结果在3D对象分割的结果，其余3种数据详见原文4DEMOS部分。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p> SAM2POINT利用 Segment Anything 2 到 3D 分割，具有零镜头和可提示的框架。通过将 3D 数据表示为多向视频，SAM2POINT 支持各种类型的用户提供的提示（3D 点、框和掩码），并在各种 3D 场景（3D 对象、室内场景、室外环境和原始稀疏 LiDAR）中表现出强大的泛化能力。SAM2POINT 为调整 SAM 2 以实现有效和高效的 3D 理解提供了独特的见解。作者希望方法可以作为可快速 3D 分割的基础基线，鼓励进一步研究以充分利用 SAM 2 在 3D 领域的潜力。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-A novel attention-guided convolutional network for the detection of</title>
    <link href="/2024/09/29/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/"/>
    <url>/2024/09/29/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/</url>
    
    <content type="html"><![CDATA[<h2 id="A-novel-attention-guided-convolutional-network-for-the-detection-of"><a href="#A-novel-attention-guided-convolutional-network-for-the-detection-of" class="headerlink" title="A novel attention-guided convolutional network for the detection of"></a>A novel attention-guided convolutional network for the detection of</h2><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205246880.png" alt="TITLE"></p><h2 id="用于宫颈癌筛查中异常宫颈细胞检测的新型注意力引导的卷积网络"><a href="#用于宫颈癌筛查中异常宫颈细胞检测的新型注意力引导的卷积网络" class="headerlink" title="用于宫颈癌筛查中异常宫颈细胞检测的新型注意力引导的卷积网络"></a>用于宫颈癌筛查中异常宫颈细胞检测的新型注意力引导的卷积网络</h2><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>一些研究已经在探索了自动检测宫颈癌的可能性，论文中举出了如以下提出的三种方法，而这些方法也存在问题，就是那些机器学习方法利用了为特定任务设计的传统手工特征，而这些特征通常不够健壮。</p><p>卷积神经网络（CNN）等深度学习的内容也被用于医学图像，因为它可以学习输入的分层特征，然而卷积神经网络也有其局限性，CNN模型的结构一般用于分类，对于细胞、器官或病变区域的定位不太适用。</p><p>Faster R-CNN解决了定位的问题，它是一种深度学习物体检测方法。由以下三部分构成：</p><p>1、CNN主干模块，用于提取有用的特征；</p><p>2、RPN区域建议网络模块，用于生成高质量的区域建议（ROIs）；</p><p>3、Faster R-CNN模块用这些高质量的ROI特征作为输入进行分类和检测的任务。</p><p>Faster R-CNN重点在显微镜图像中的细胞检测、超声图像中的胎儿头部检测、牙齿根尖周裂缝中的牙齿检测以及MR图像中的转移淋巴结检测。目前只有两项研究构建用于宫颈细胞检测的Faster R-CNN，一个是将检测并将观察到的细胞分类为不同等级的恶性程度，一个是对宫颈脱落细胞进行检测和分类，用于早期诊断。</p><p>而用于宫颈细胞检测的Faster R-CNN也存在两个问题：</p><p>1、不能处理细胞的不同尺寸变换；</p><p>2、临床知识如宫颈细胞的大小和形状被模型忽略了。</p><p>本研究提出了一种新型的注意力特征金字塔网络（AttFPN),作用是自动检测和分类Thinprep Pap图像中非正常宫颈细胞。创新：</p><p>1、开发了注意力模块，与多尺度特征融合更有效地重新提取特征。</p><p>2、在区域建议网络中根据真实的宫颈细胞大小分布来设计anchor boxes（锚框）的尺寸和长宽比</p><h2 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h2><p>宫颈癌检测任务分为三个阶段：1、标注过异常细胞的异常斑块用来训练AttFPN模型，重点在于检测特定图像斑块中的异常细胞；2、使用分类网络，根据检测到的异常细胞以及异常概率预测每个图片的异常概率；3、总结一个病例中的所有图片的预测结果，预测该病例的最终病例等级分类。</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205711778.png" alt="模型介绍"></p><p>AttFPN模型</p><p>AttFPN结合了注意力模块和多尺度特征融合，网络结构是DenseNet-169；</p><p>检测部分，模型对输入进行学习，训练完成后给定一个image可以检测到异常的宫颈细胞并且得到他们的异常概率；</p><p>分类部分，检测到的异常细胞的最大概率为图像的异常概率。</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205742324.png" alt="AttFPN模型"></p><p>AttFPN结合了注意力模块和多尺度特征融合，网络结构是DenseNet-169；</p><p>检测部分，模型对输入进行学习，训练完成后给定一个image可以检测到异常的宫颈细胞并且得到他们的异常概率；</p><p>分类部分，检测到的异常细胞的最大概率为图像的异常概率。</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205806176.png"></p><p>Attention module</p><p>低层特征通过channel attention沿着channel维度进行重构，将重构的特征送入spatial attention，再沿着spatial维度进行重构，最后，重新确定的低层次特征与高层次特征相融合。</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205822417.png" alt="Attention module"></p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>三种方法在各个网络结构上的检测性能比较</p><p>评价标准：AP(平均精度)</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205852032.png" alt="实验结果"></p><p>注意力模块可以有效地提高异常细胞的检测，因为注意力模块可以有效地重新提取特征。</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205856300.png" alt="实验结果"></p><p>模型结合了多尺度特征融合和注意力模块，注意力模块知道在哪里需要强调哪里需要抑制并重新提取特征；多尺度特征融合可以检测出各种尺寸的异常细胞。</p><p><img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205956526.png" alt="实验结果"></p><p>AttFPN所包围的区域是最大的，因此这个方法能够更准确的将异常病例和正常病例进行分类。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了一种名为AttFPN的新型深度学习方法，作为宫颈癌筛查中宫颈细胞异常的自动检测模型。该模型以临床知识和注意力机制为指导，包括一个多尺寸的特征融合结构和一个注意力模块。</p><p> 该方法的表现优于相关的先进的深度学习方法，并与具有10年经验的病理学家的表现相当。我们的方法可以作为一个可靠的助手，帮助病理学家在宫颈癌筛查中更有效和准确地确定异常的宫颈细胞。此外，它还可以为没有经验的病理学家提供有用的建议，特别是在资源匮乏的地区是很重要的。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>医学影像数据集</title>
    <link href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h2 id="医学影像数据集"><a href="#医学影像数据集" class="headerlink" title="医学影像数据集"></a>医学影像数据集</h2><h3 id="肺"><a href="#肺" class="headerlink" title="肺"></a>肺</h3><h4 id="肺-1"><a href="#肺-1" class="headerlink" title="肺"></a>肺</h4><p>MSD肺癌分割 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/10334">MSD肺脏分割数据集</a></p><p>LoLa11肺叶分割 <a href="https://zenodo.org/record/4708800#.Y_4GJV5ByUk">LoLa11肺叶分割数据集</a></p><p>肺部多病智能诊断 <a href="https://tianchi.aliyun.com/dataset?spm=5176.12282013.J_3941670930.15.7107417b5sQFpV">天池数据</a></p><p>vessel12 肺部血管分割 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/94923">VESSEL12 肺部血管分割</a></p><p>NIHChest Xray </p><ul><li>14种肺部疾病 <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf">论文</a></li><li>数据集下载 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/35660">NIH chest Xray</a></li></ul><p>QIN Lung CT QIN <a href="https://aistudio.baidu.com/aistudio/datasetdetail/35205">肺部CT数据</a></p><p>4D-Lung <a href="https://aistudio.baidu.com/aistudio/datasetdetail/37482">4D-Lung</a></p><p>NSCLC-Radiomics <a href="https://aistudio.baidu.com/aistudio/datasetdetail/63958">NSCLC-Radiomics</a></p><p>Shenzhen Hospital X-ray Set <a href="https://aistudio.baidu.com/aistudio/datasetdetail/25237">深圳肺结核胸透数据集</a></p><h4 id="肺结核"><a href="#肺结核" class="headerlink" title="肺结核"></a>肺结核</h4><p>Montgomery County X-ray Set <a href="https://aistudio.baidu.com/aistudio/datasetdetail/34229">蒙哥马利肺结核数据集</a></p><h4 id="肺炎"><a href="#肺炎" class="headerlink" title="肺炎"></a>肺炎</h4><p>Ieee8023</p><ul><li>covid19-ct-scans <a href="https://aistudio.baidu.com/aistudio/datasetdetail/34221">新冠肺炎CT扫描+分割标注</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/34221">新冠肺炎CT扫描+分割标注</a></li></ul><p>COVID-CT <a href="https://aistudio.baidu.com/aistudio/datasetdetail/27732">新冠肺炎CT图片数据集</a></p><p>Figure1-COVID-chestxray-dataset <a href="https://aistudio.baidu.com/aistudio/datasetdetail/34208">新冠病例CT照片</a></p><p>RSNA肺炎检测 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/34214">RSNA肺炎检测数据集</a></p><p>CovidX CovidX数据集是DarwinAI训练CovidNet做的一个数据集，本身没有新的数据，是Ieee8023，Figure1和RSNA组合成的一个数据集。</p><p>covid19-radiography-database <a href="https://aistudio.baidu.com/aistudio/datasetdetail/34241">跟CovidX一样是一个组合数据集，数据来自论文图片和RSNA</a>。</p><p>Flyai Covid Flyai <a href="https://aistudio.baidu.com/aistudio/datasetdetail/34230">新冠分类数据集</a></p><p>COVID-19-AR <a href="https://aistudio.baidu.com/aistudio/datasetdetail/63553">来自农村地区的新冠确诊病例CT</a></p><p>CT Images in COVID-19 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/63794">共包含771组新冠患者的胸腹部CT平扫</a></p><h4 id="肺结节"><a href="#肺结节" class="headerlink" title="肺结节"></a>肺结节</h4><p>LIDC-IDRI <a href="https://aistudio.baidu.com/aistudio/datasetdetail/63957">肺部肿瘤</a></p><p>LUNA16 据来自LIDC&#x2F;IDIR数据集，包括888组CT扫描。<a href="https://aistudio.baidu.com/aistudio/datasetdetail/1860">标注了结节类型和中心位置</a></p><p>LNDB <a href="https://aistudio.baidu.com/aistudio/datasetdetail/23909">LNDB肺结节数据集</a></p><p>Lung Nodule Malignancy <a href="https://aistudio.baidu.com/aistudio/datasetdetail/28474">肺结节良恶性分类</a></p><p>Data Science Bowl 17 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/25423">DSB 肺癌预测数据集 stage-1</a></p><h4 id="气胸"><a href="#气胸" class="headerlink" title="气胸"></a>气胸</h4><p>SIIM-ACR Pneumothorax Segmentation <a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation">SIIM-ACR 气胸细分</a></p><h3 id="胸"><a href="#胸" class="headerlink" title="胸"></a>胸</h3><p>CBIS-DDSM <a href="https://aistudio.baidu.com/aistudio/datasetdetail/37567">CBIS-DDSM</a></p><p>breast cancer </p><ul><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/68630">breast cancer</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/22532">breast_40X</a></li></ul><p>Rider Breast MRI <a href="https://wiki.cancerimagingarchive.net/display/Public/RIDER+Breast+MRI">骑士乳房核磁共振成像</a></p><p>ACRIN 6688 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/37565">腺素-FLT-乳房</a> （ACRIN 6688）</p><p>BraTS2015 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/26367">BraTS2015</a></p><h3 id="脑"><a href="#脑" class="headerlink" title="脑"></a>脑</h3><p>MSD脑瘤分割 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/10277">MSD脑瘤数据集</a></p><p>MSD海马体分割 MSD-4，<a href="https://aistudio.baidu.com/aistudio/datasetdetail/23862">海马体分割数据集</a></p><p>Iseg2019 <a href="https://iseg2019.web.unc.edu/data/">MICCAI</a>对多位点6个月婴儿脑MRI分割的大挑战</p><p>ABIDE <a href="http://preprocessed-connectomes-project.org/abide/download.html">自闭症患者的头部MRI扫描</a>，包含539例自闭症患者和573个正常扫描对照组</p><p>ADNI </p><ul><li><a href="https://n.neurology.org/content/74/3/201.short">阿尔茨海默病神经影像</a></li><li><a href="https://arxiv.org/abs/1803.05854">开发和验证用于检测头部CT扫描中关键发现的深度学习算法</a></li></ul><p>CQ500 </p><p>脑出血 RSNA </p><ul><li><a href="https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection">颅内出血检测 RSNA</a> </li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/35741">颅内出血检测 kaggle</a></li></ul><p>脑肿瘤 MRI <a href="https://www.cvmart.net/dataSets/detail/452?utm_campaign=zywang&utm_source=social&utm_medium=gongzhonghao&utm_content=datasets">数据集</a></p><h3 id="肠"><a href="#肠" class="headerlink" title="肠"></a>肠</h3><p>CT COLONOGRAPHY <a href="https://wiki.cancerimagingarchive.net/display/Public/CT+COLONOGRAPHY#dc149b9170f54aa29e88f1119e25ba3e">CT 结肠造影</a></p><p>MSD肠道分割数据集 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/10332">MSD肠道分割数据集</a></p><p>UW-Madison <a href="https://aistudio.baidu.com/aistudio/datasetdetail/145482">胃肠道图像分割 RI 扫描来自实际的癌症患者，放射治疗期间的不同日子 1-5 次 MRI 扫描</a>。</p><p>直肠息肉<a href="https://aistudio.baidu.com/aistudio/datasetdetail/37521">数据集</a></p><h3 id="心脏"><a href="#心脏" class="headerlink" title="心脏"></a>心脏</h3><p>EchoNet</p><ul><li><a href="https://echonet.github.io/dynamic/NeuroIPS_2019_ML4H%20Workshop_Paper.pdf">介绍论文</a></li><li><a href="https://echonet.github.io/dynamic/index.html">EchoNet-D</a>数据库包括 10030 个标记的超声心动图视频和人类专家注释</li></ul><p>MMWHS <a href="https://aistudio.baidu.com/aistudio/datasetdetail/38799">mmwhs是心脏分割数据集</a></p><p>MSD心脏分割 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/23911">MSD心脏分割数据集</a></p><p>主动脉 <a href="https://asoca.grand-challenge.org/">冠状动脉分割</a></p><p>心脏病发作分析和<a href="http://m6z.cn/6ikH8v">预测数据集</a></p><h3 id="眼睛"><a href="#眼睛" class="headerlink" title="眼睛"></a>眼睛</h3><p>DRIVE <a href="https://aistudio.baidu.com/aistudio/datasetdetail/27737">DRIVE糖尿病人眼底血管分割</a></p><p>ODIR-5k <a href="https://odir2019.grand-challenge.org/">ODIR-5K包括5000名患者的年龄</a>，双眼的彩色眼底照片和医生的诊断关键词</p><p>FIRE 视网膜图像数据 <a href="https://projects.ics.forth.gr/cvrl/fire/">FIRE</a> 是一个视网膜眼底图像数据集，包含 129张 眼底视网膜图像，由不同特征组合成 134对 图像组合</p><p>STARE <a href="https://aistudio.baidu.com/aistudio/datasetdetail/81241">STARE 眼底多种诊断</a></p><p>CHASE_DB1 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/81247">Kinston大学公开的一个小规模眼底分割数据集，包含28张眼底照片及对应的分割标签</a>。</p><p>IDRiD</p><ul><li><a href="https://idrid.grand-challenge.org/">印度糖尿病视网膜病变图像数据集（IDRiD）网站</a></li><li><a href="http://m6z.cn/5yth3m">眼病深度学习数据集</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/91860/0">IDRiD</a></li></ul><h3 id="肾脏"><a href="#肾脏" class="headerlink" title="肾脏"></a>肾脏</h3><p>Kits19 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/24582">Kits19肾脏肿瘤分割</a></p><p><a href="https://aistudio.baidu.com/aistudio/datasetdetail/178466">入侵肾脏</a></p><p><a href="https://aistudio.baidu.com/aistudio/datasetdetail/157138">肾脏CT</a></p><h3 id="肝脏"><a href="#肝脏" class="headerlink" title="肝脏"></a>肝脏</h3><p>LiTS</p><ul><li>数据集论文：The Liver Tumor Segmentation Benchmark (<a href="https://arxiv.org/abs/1901.04056">LiTS</a>)</li><li>数据集下载 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/10273">LiTS肝脏&#x2F;肝肿瘤分割</a></li></ul><p>Sliver07 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/19906">Sliver-07肝脏分割数据集</a></p><p>3D-IRCADB</p><ul><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/10293">3D-IRCADB脏器分割数据集</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/129670">肝脏CT薄层分割数据集，肝脏1，肿瘤2</a></li><li>CHAOS <a href="https://aistudio.baidu.com/aistudio/datasetdetail/23864">CHAOS多脏器分割数据集</a></li></ul><p>TCGA-LIHC 肝脏CT  <a href="https://aistudio.baidu.com/aistudio/datasetdetail/37439">TCGA-LIHC</a></p><p>MSD肝脏血管分割 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/10333">MSD肝脏血管数据集</a></p><h3 id="细胞"><a href="#细胞" class="headerlink" title="细胞"></a>细胞</h3><p>Data Science Bowl 18</p><ul><li><a href="https://www.kaggle.com/competitions">kaggle</a></li><li><a href="https://pubmed.ncbi.nlm.nih.gov/31636459/">论文</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/10292">DSB18 细胞核分割</a></li></ul><p>血细胞涂片分类 ISBI细胞跟踪</p><ul><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/10278">血细胞分类数据集</a></li><li><a href="https://www.kaggle.com/datasets/paultimothymooney/blood-cells">血细胞图像kaggle</a></li><li><a href="http://celltrackingchallenge.net/">细胞追踪挑战</a></li></ul><p><a href="https://www.cvmart.net/dataSets/detail/413">PanNuke癌组织细胞数据集</a></p><p><a href="https://www.cvmart.net/dataSets/detail/449">血细胞图像数据集</a></p><h3 id="骨骼"><a href="#骨骼" class="headerlink" title="骨骼"></a>骨骼</h3><p>MURA-1.1</p><ul><li><a href="https://stanfordmlgroup.github.io/competitions/mura/">骨X射线深度学习竞赛</a></li><li><a href="https://arxiv.org/abs/1712.06957">介绍论文</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/20010">MURA-1.1</a></li></ul><p>RSNA Bone Age</p><ul><li><a href="https://www.kaggle.com/datasets/kmader/rsna-bone-age">RSNA骨龄</a></li><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/36300">RSNA Bone Age</a></li></ul><p><a href="https://aistudio.baidu.com/aistudio/datasetdetail/81211">磁共振图像脊柱结构多类别三维自动分割</a></p><p>膝盖</p><ul><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/24584">MRNet</a> 斯坦福MRNet膝关节MRI数据集</li><li><a href="https://www.cvmart.net/dataSets/detail/457?utm_campaign=zywang&utm_source=social&utm_medium=gongzhonghao&utm_content=datasets">膝关节 X 射线图像数据集</a></li></ul><p>脊椎 <a href="https://aistudio.baidu.com/aistudio/datasetdetail/86496">Verse大规模脊椎分割数据集</a></p><p>身体部位<a href="https://www.cvmart.net/dataSets/detail/454?utm_campaign=zywang&utm_source=social&utm_medium=gongzhonghao&utm_content=datasets">X射线图像数据集</a></p><h3 id="前列腺"><a href="#前列腺" class="headerlink" title="前列腺"></a>前列腺</h3><p>PANDA 前列腺<a href="https://www.kaggle.com/competitions/prostate-cancer-grade-assessment/data">cANcer graDe评估（PANDA）挑战</a></p><p>MSD<a href="https://aistudio.baidu.com/aistudio/datasetdetail/23912">前列腺分割</a></p><p>QIN-PROSTATE-<a href="https://aistudio.baidu.com/aistudio/datasetdetail/63950">Repeatability</a></p><h3 id="胰腺"><a href="#胰腺" class="headerlink" title="胰腺"></a>胰腺</h3><p><a href="https://aistudio.baidu.com/aistudio/datasetdetail/23914">MSD胰腺分割</a></p><p><a href="https://aistudio.baidu.com/aistudio/datasetdetail/64052">PDMR-833975-119-R</a>胰腺腺癌患者来源异种移植模型的成像组织表征</p><h3 id="皮肤"><a href="#皮肤" class="headerlink" title="皮肤"></a>皮肤</h3><p><a href="https://www.kaggle.com/c/siim-isic-melanoma-classification/data">SIIM-ISIC 黑色素瘤分类</a></p><p><a href="https://www.cvmart.net/dataSets/detail/450?utm_campaign=zywang&utm_source=social&utm_medium=gongzhonghao&utm_content=datasets">皮肤病数据集</a></p><h3 id="VQA"><a href="#VQA" class="headerlink" title="VQA"></a>VQA</h3><p>PathVQA </p><ul><li><a href="https://aistudio.baidu.com/aistudio/datasetdetail/25239">病理视觉回答</a></li><li><a href="https://arxiv.org/abs/2003.10286">论文</a></li></ul><h3 id="内窥镜"><a href="#内窥镜" class="headerlink" title="内窥镜"></a>内窥镜</h3><p>SARAS-MESAD <a href="https://saras-mesad.grand-challenge.org/">SARAS对多域内窥镜外科医生动作检测24</a></p><p>SARAS-MESAD <a href="https://saras-esad.grand-challenge.org/">SARAS内窥镜视力挑战外科医生动作检测21</a></p><h3 id="医学影像数据库"><a href="#医学影像数据库" class="headerlink" title="医学影像数据库"></a>医学影像数据库</h3><p><a href="https://www.cancerimagingarchive.net/">TCIA:The Cancer Imaging Archive</a></p><p><a href="https://ida.loni.usc.edu/login.jsp">LONI 神经相关医学影像</a></p><p><a href="https://medpix.nlm.nih.gov/home">MedPix 包含超过12000名患者和59000张影像</a></p><p><a href="https://aistudio.baidu.com/aistudio/projectdetail/431782">胸部\肺部ct数据集</a></p><p><a href="https://grand-challenge.org/">Grand Challenges</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>医学影像分割挑战<a href="http://medicaldecathlon.com/">http://medicaldecathlon.com/</a></p><p>adalca<a href="https://github.com/adalca/medical-datasets">https://github.com/adalca/medical-datasets</a></p><p>beamandrew<a href="https://gitcode.net/mirrors/beamandrew/medical-data?utm_source=csdn_github_accelerator">https://gitcode.net/mirrors/beamandrew/medical-data?utm_source=csdn_github_accelerator</a></p><p>Stanford ML Group<a href="https://stanfordmlgroup.github.io/">https://stanfordmlgroup.github.io/</a></p><p>omic tools<a href="https://omictools.com/">https://omictools.com/</a></p><p>各领域公开数据集<a href="https://zhuanlan.zhihu.com/p/25138563">https://zhuanlan.zhihu.com/p/25138563</a></p><p>medical-imaging-datasets<a href="https://gitcode.net/mirrors/sfikas/medical-imaging-datasets?utm_source=csdn_github_accelerator">https://gitcode.net/mirrors/sfikas/medical-imaging-datasets?utm_source=csdn_github_accelerator</a></p><p>Open-Access Medical Image Repositories<a href="https://www.aylward.org/notes/open-access-medical-image-repositories">https://www.aylward.org/notes/open-access-medical-image-repositories</a></p><p>Medical Image Datasets Download Links<a href="https://www.aylward.org/notes/open-access-medical-image-repositories">https://www.aylward.org/notes/open-access-medical-image-repositories</a></p><p>HAM10000 dataset<a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T">https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T</a></p><p>Dermatology Image Classification<a href="https://www.kaggle.com/code/yuningalexliu/dermatology-image-classification/notebook">https://www.kaggle.com/code/yuningalexliu/dermatology-image-classification/notebook</a></p><p>havard<a href="https://library.med.utah.edu/kw/derm/">https://library.med.utah.edu/kw/derm/</a></p><p>usc<a href="https://library.med.utah.edu/kw/derm/">https://library.med.utah.edu/kw/derm/</a></p><p>burkely<a href="https://library.med.utah.edu/kw/derm/">https://library.med.utah.edu/kw/derm/</a></p><p>radiopedia<a href="https://radiopaedia.org/articles/imaging-data-sets-artificial-intelligence">https://radiopaedia.org/articles/imaging-data-sets-artificial-intelligence</a></p><p>aimi<a href="https://radiopaedia.org/articles/imaging-data-sets-artificial-intelligence">https://radiopaedia.org/articles/imaging-data-sets-artificial-intelligence</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation</title>
    <link href="/2024/09/29/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/"/>
    <url>/2024/09/29/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/</url>
    
    <content type="html"><![CDATA[<h2 id="ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation"><a href="#ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation" class="headerlink" title="ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation"></a>ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation</h2><p><img src="/../images/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/image-20240925233026212.png" alt="ESP-MedSAM"></p><blockquote><p>arXiv:2407.14153v4 [eess.IV] 18 Aug 2024 IEEE TRANSACTIONS ON MEDICAL IMAGING ESP-MedSAM： 用于通用域广义医学图像分割的高效自提示 SAM</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>SAM给医学图像分割提供了新的可能，但是SAM巨大的计算成本、对人工注释作为提示的需求以及容易发生冲突的解码过程降低了其在临床场景中的泛化性和适用性。为了解决这些问题，本文提出了一种高效的自提示 SAM，用于通用域广义医学图像分割，名为 ESP-MedSAM。首先设计了多模态解耦知识蒸馏 （MMDKD） 策略来构建一个轻量级的半参数共享图像编码器，为不同模态产生判别性视觉特征。此外引入了 Self-Patch Prompt Generator （SPPG） 来自动生成高质量的密集提示嵌入，用于指导分段解码。最后设计了查询解耦模态解码器 （QDMD），它利用一对一的策略为每种模态提供独立的解码通道。</p><ul><li>MMDKD 策略，将模态特定和模态常识从基础模型分别提炼到模态控制器和模态聚合器中。两者都构成了一个轻量级的半参数共享图像编码器，从而为不同的医疗模式生成了独特的特征</li><li>设计了 SPPG 来自动生成高质量的补丁提示，而无需手动注释。这些提示用于指导分割掩码的预测。</li><li>用于分段解码的 QDMD。它利用一对一策略为每种模式提供私有分段工作流，防止不同模式相互干扰。</li><li>提炼的轻量级半参数共享图像编码器 SPPG 和 QDMD 来构建ESP-MedSAM 具有显著的泛化-效率权衡。对各种医学成像模式进行了广泛的实验，证明的 ESP-MedSAM 在通用域广义医学图像分割方面优于最先进的技术</li></ul><p>MedSAM 和 SAMMI  收集了超过 1M 的公共医学图像，以通过框和点提示对 SAM 进行全面微调，以实现域广义通用医学图像分割。然而，这种方法会迅速增加数据和计算成本，这在临床场景中既昂贵又不切实际。为了减轻迁移学习过程中对数据大小和计算资源的依赖，SAM 中引入了参数高效的微调技术。具体来说，Adapter 已被广泛用于集成到 SAM 的图像编码器中，以改进医学成像中的特征表示。但是无论那种方法都基于巨大的ViT编码器，有着复杂的计算，本文的方法克服了挑战，并说明了各种医学成像模式中卓越的泛化-效率权衡。</p><p>本文的方法还使用了知识蒸馏，</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/image-20240926213054530.png" alt="ESP-MedSam"></p><p> ESP-MedSAM 的端到端架构，用于通用医疗图像分割。</p><p>（a） 多模态解耦知识蒸馏。</p><ul><li>教师模型</li></ul><p>多模态教师模型，该模型涉及 SAM 的自然图像编码器 FViT-SAM 和医学图像编码器 FViT-Med。在 SAM 中冻结图像编码器的权重，并额外创建一组可学习的标记。它们与多头注意力层的键和值通道连接，以学习医学图像中的新模式，从而更新注意力图。此外，将可学习的多层感知器并行到 ViT 中的前馈网络 （FFN） 中，以存储不同的模态信息。利用这个 FViT-Med 、 SPPG 和 QDMD 在医学源域 S 上实施微调。教师模型由焦点损失和骰子损失的组合进行监督，FViT-SAM 和 FViT-Med 能够分别提供模态常识和模态特异性知识。</p><ul><li>解耦知识蒸馏</li></ul><p>分割掩码的质量取决于从图像编码器中提取的特征。从分而治之算法中汲取灵感，作者提出 MMDKD 方法将 KD 过程解耦为两个子任务：模态公共特征蒸馏和模态特定特征蒸馏。在模态共同特征蒸馏过程中，目标是将知识从 FViT-SAM 转移到模态聚合器 FMA，MMDKD 策略为每种医学成像模式提供了一个私有蒸馏通道，防止不同模式相互干扰。</p><ul><li>轻量级半参数共享图像编码器</li></ul><p>为了无缝协调不同模态的特征表示，采用提炼的模态控制器和模态聚合器来构建一个轻量级的半参数共享图像编码器，总体而言，与 SAM 相比， MMDKD 方法有效地降低了图像编码器的计算成本，同时保留了生成可泛化特征图的能力。</p><p>（b） Self-Patch Prompt 生成器。</p><p>目前的医疗SAM和轻量级SAM主要利用手动提示（例如，点和框）来指导模型提供满意的分割掩码。然而，这些方法依赖于病理学家在医疗场景中的经验，这既昂贵又耗时。为了消除对手动注释的需求，作者使用包含补丁生成器和密集提示（DP）编码器的 SPPG，以自动生成一组高质量的补丁提示，以协助分割解码：</p><p><img src="/../images/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/image-20241004144116917.png" alt="Self-Patch Prompt Generator "></p><p>通过这种方式，SPPG 模块自动生成一组高质量的密集提示 p 来指导分割掩码的预测，提高了 ESP-MedSAM 在临床场景中的适用性。</p><p>（c） 查询解耦模态解码器。</p><p>SAM的掩码解码器利用与模态无关的查询标记来处理自然图像中的所有分割任务。但是，这并不是医学图像分割的最佳选择。由于各种医学成像模态存在固有的异质性，这种常见的预测通道存在解码冲突，降低了模型的泛化能力，ESP-MedSAM 框架提出了 QDMD。 QDMD 为每种模态提供了一个独立的解码过程，避免了不同模态之间相互冲突的固有异质性，提高了 ESP-MedSAM 框架的泛化能力。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/image-20241004150740526.png" alt="与通用医学图像分割（源域）中最先进的框架进行比较。"></p><p><img src="/../images/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/image-20241004150838023.png" alt="与域广义医学图像分割（看不见的域）中最先进的框架进行比较。"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通用医学图像分割的 ESP-MedSAM 框架引入了 MMDKD 策略，将基础模型中的知识提炼到模态控制器和模态控制器中，以创建一个用于判别特征生成的半参数共享图像编码器。然后，SPPG 被设计出来自动生成一组高质量的补丁提示，以协助分割解码。最后，QDMD 为每种模态定制了特定的分割工作流程。大量实验表明，ESP-MedSAM 的计算复杂度低于标准 SAM，在各种医学成像分割任务中优于 SOTA 任务特定架构和轻量级 SAM，表现出卓越的零样本泛化和通用能力。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Learnable Ophthalmology SAM</title>
    <link href="/2024/09/29/0-Learnable-Ophthalmology-SAM/"/>
    <url>/2024/09/29/0-Learnable-Ophthalmology-SAM/</url>
    
    <content type="html"><![CDATA[<h2 id="Learnable-Ophthalmology-SAM"><a href="#Learnable-Ophthalmology-SAM" class="headerlink" title="Learnable Ophthalmology SAM"></a>Learnable Ophthalmology SAM</h2><p><img src="/../images/0-Learnable-Ophthalmology-SAM/image-20240924194146172.png" alt="LOSAM"></p><blockquote><p>arXiv:2304.13425v1 [cs.CV] 26 Apr 2023 可学习的眼科 SAM</p><p>code：<a href="https://github.com/xianlin7/SAMUS">https://github.com/xianlin7/SAMUS</a></p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>针对眼科图像分析中的分割问题，由于眼科图像的多模态特性，现有的分割算法大多依赖于大量标签的训练或者泛化能力较弱，导致其应用受限。</p><p>为了解决这一问题，本研究提出了一种适用于眼科多模态图像中多目标分割的方法，即可学习的眼科“分割任何物”(SAM)。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>问题1：多模态图像导致的分割目标差异问题</p><p>解法1：采用可学习提示层</p><ul><li>由于眼科图像包括彩色眼底图、光学相干断层扫描(OCT)等多种模态，每种模态图像的分割目标（如血管、视网膜层）不同，现有单一模型难以适应。</li><li>通过引入可学习的提示层，使模型能够在不同模态图像中自动学习和识别分割目标，如在OCT图像中学习到视网膜层的特征，在彩色眼底图中学习到血管的特征，提高了模型的适应性和泛化能力。</li></ul><p>比如有一组眼科图像，包括彩色眼底图和OCT图像。</p><p>彩色眼底图主要用于观察眼底的血管分布，而OCT图像则提供视网膜各层的详细结构。</p><p>传统的分割模型可能在彩色眼底图上表现良好，能够识别出血管，但在OCT图像上却难以分辨出视网膜的不同层次。</p><p>通过引入可学习的提示层，模型在处理OCT图像时能自动调整其学习重点，识别出视网膜的各个层次，而在处理彩色眼底图时则专注于血管的识别。</p><p>这种自适应能力显著提高了模型在多模态图像上的适用性和准确性。</p><p>子问题2：现有基础视觉模型在医学图像上应用受限</p><p>子解法2：一次性训练机制的引入</p><ul><li>基于大型视觉模型如SAM或DINOv2进行医学图像分割时，直接应用这些模型往往不能有效分割医学图像中的血管或病变。</li><li>通过只对可学习的提示层和任务头进行一次性训练，而不是全模型微调，可以有效地将这些基础模型适配到医学图像分割任务上。</li><li>这种方法利用了基础视觉模型在特征提取上的优势，通过学习少量的医学先验知识来实现高效准确的分割。</li></ul><p>在使用基于Transformer的大型视觉模型（如SAM）进行医学图像的血管分割时，直接应用通常结果不理想，因为这些模型未针对复杂的医学图像特征进行优化。</p><p>通过对SAM的提示层和任务头进行一次性训练，例如在一张具有明显血管结构的彩色眼底图上进行训练，模型能够学习到如何在医学图像中识别血管，而不需要在整个大规模数据集上重新训练。</p><p>这种方法不仅节省了大量的训练时间和资源，而且使模型能够有效地适用于特定的医学图像分割任务。</p><p>子问题3：提高分割精度和泛化能力</p><p>子解法3：深度可分离卷积的应用</p><ul><li>在构建可学习提示层时，采用了1x1卷积、层归一化、GELU非线性激活函数，以及深度可分离的3x3卷积来捕获特征的局部模式。</li><li>这种结构设计帮助模型更好地理解医学图像中的细节和结构，如通过深度可分离卷积提取血管或视网膜层的局部特征，从而提高了分割的精度和模型对不同数据集的泛化能力。</li></ul><p><img src="/../images/0-Learnable-Ophthalmology-SAM/203f70665e54424086d1005e06a91ce0.png"></p><p>从输入到任务头的流程，并在变换器层之间插入了提示层。</p><p>图的部分（b）是，提示层的架构，包括1x1卷积、层归一化、GELU激活函数和3x3深度卷积层。</p><p>在处理OCT图像时，模型需要识别和分割出视网膜的多个层次。</p><p>通过在可学习提示层中使用深度可分离的3x3卷积，模型能够更有效地捕捉到视网膜层次之间的微妙差异，例如识别出神经纤维层和视网膜色素上皮层。</p><p>这种深度可分离卷积的应用不仅提高了分割的精度，而且因为其参数更少，也增强了模型在不同数据集间的泛化能力。</p><p>相比于传统的卷积层，这种方法在维持高分辨率特征图的同时，有效减少了计算复杂度和模型的参数量，使得模型在处理复杂的医学图像时更加高效和准确。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Learnable-Ophthalmology-SAM/691d326932df3c815b2b3b4da8d00eb7.png" alt="实验结果1"></p><p>LOSAM（眼科SAM）算法在分割眼底血管和病变方面与基础的计算机视觉模型相比，提供了显著改善。</p><p>特别是在处理DINOv2和SAM无法有效识别的细小血管和病变时，LOSAM算法能够更接近真实情况，这证明了其对于眼科图像具有更好的适用性和准确性。</p><p><img src="/../images/0-Learnable-Ophthalmology-SAM/c583b88717d67b3e7753658796592f2e.png" alt="实验结果2"></p><p>LOSAM 算法，在多种眼科图像分割任务上都能取得好的结果，包括血管分割、病变分割和视网膜层分割。</p><p>可视化结果展示了与真实情况相比，该算法在保留细节和结构方面的有效性。</p><p><img src="/../images/0-Learnable-Ophthalmology-SAM/86c17f0405f9c7eb0696691b61af5f6b.png" alt="实验结果3"></p><p>LOSAM 算法具有良好的泛化能力，即在一个数据集上训练后，能够在没有进一步训练的情况下，成功地应用于其他不同的数据集。</p><p>这表明了算法在处理不同成像条件下的图像时的稳健性。</p><p><img src="/../images/0-Learnable-Ophthalmology-SAM/5f88c37a89fd437d138cf1d1e8676a55.png" alt="实验结果4"></p><p>图像质量对分割算法的性能有显著影响，LOSAM在处理低质量图像时可能无法达到理想的分割效果。</p><p>这些失败的例子说明了改进算法以处理低质量图像的必要性。</p><p>低质量图像具体可能指以下情况：</p><ol><li><p>低分辨率：图像的细节不够清晰，无法准确识别或分割图像中的重要特征，如血管、病变或视网膜层。</p></li><li><p>运动模糊：由于患者移动、手抖或设备问题导致的图像模糊，这会使得分割任务变得更加困难。</p></li><li><p>照明不足：图像因为照明不当（过暗或过亮）而丢失信息，导致关键的细节无法被辨识。</p></li><li><p>噪声干扰：图像中存在的随机变化（如电子噪声、压缩伪影）可能会干扰算法识别出真正的信号。</p></li><li><p>对比度低：图像中物体之间的对比度不足，使得算法难以区分目标和背景。</p></li><li><p>伪影：由成像设备的缺陷或处理错误引入的非真实结构，这些伪影可能会误导分割算法。</p></li><li><p>成像设备的差异：不同的成像设备可能会因为硬件的差异而产生不同质量的图像。</p></li><li><p>压缩损失：为了减少存储空间，图像可能被压缩，导致重要的细节信息丢失。</p></li></ol><p>通常需要通过预处理步骤（如图像增强、去噪、对比度调整）来改善图像质量，或者通过改进算法使其对低质量图像更加鲁棒。<br><img src="/../images/0-Learnable-Ophthalmology-SAM/28b1b9586224b97a01777a0bd4d236b5.png" alt="实验结果6"></p><p>LOSAM算法在识别和分割图像中的小目标上存在局限性，尤其是当目标尺寸非常小或与背景对比不明显时。</p><p>所以，在应用中需要进一步提升算法在处理微小目标上的能力。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>问题1：多模态图像的分割不一致性</p><p>解法1：可学习提示层（Learnable Prompt Layer）</p><p>原因： 多模态图像（如彩色眼底和OCTA图像）具有不同的成像特征，标准模型可能在一个模态上表现良好，在另一个模态上表现不足。可学习提示层允许模型在每个模态上捕捉和学习特定的特征，从而提高分割的一致性和准确性。</p><p>例子： 在彩色眼底图像中，可学习提示层帮助模型区分了主要血管和次要血管，尽管分割微小血管仍然具有挑战性。</p><p>问题2：OCT图像中的视网膜层精确分割</p><p>解法2：体数据增强（Volume Data Augmentation）</p><p>原因： OCT图像通常以三维数据形式存在，需要模型能够理解和处理这种体数据。体数据增强通过提供更丰富的三维信息来训练模型，从而提高分割视网膜层的精度。</p><p>例子： 对于ARoI数据集的OCT层分割任务，体数据增强使得LOSAM在Dice评分上显著提高。</p><p>问题3：小目标物的分割困难</p><p>解法3：目标大小感知分割（Size-Aware Segmentation）</p><p>原因： 小目标物，如微动脉瘤，可能在图像的预处理阶段被丢失或在分割过程中难以辨认。目标大小感知分割专注于改进模型对于不同大小目标物的识别能力，特别是提高小目标的检测率。</p><p>例子： 在iDRiD数据集上，LOSAM通过目标大小感知分割在大的病变（出血和硬渗出）上取得了成功，但对于小的病变（微动脉瘤和软渗出）的分割仍然是一个挑战。</p><p>问题4：算法泛化到新的、未见过的数据集</p><p>解法4：零次学习泛化（Zero-Shot Learning Generalization）</p><p>原因： 算法需要在训练时未见过的新数据集上仍然表现良好，这要求算法具有良好的泛化能力。零次学习泛化是在算法没有直接从特定数据集学习的情况下，验证其在新数据集上的表现。</p><p>例子： 经过在FIVES数据集上的训练，LOSAM在HRF和CHASEDB数据集上的血管分割表现出了优秀的泛化能力，证明了其不依赖于特定数据集的训练就能够实现有效的分割。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation</title>
    <link href="/2024/09/29/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/"/>
    <url>/2024/09/29/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/</url>
    
    <content type="html"><![CDATA[<h2 id="MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation"><a href="#MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation" class="headerlink" title="MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation"></a>MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation</h2><p><img src="/../images/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/image-20240913215501362.png" alt="TITLE"></p><blockquote><p>MA-SAM：用于 3D 医学图像分割的模态不可知的 SAM 自适应 2024年8月</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>SAM模型已经在很多分割任务中取得很好的zero-shot性能，但在医学图像上仍有欠缺，本文提出了一种与模态无关的 SAM 适应框架（MA-SAM)，通过将一系列 3D 适配器注入图像编码器的 transformer 块中，让模型有2D-3D的分割能力，在没有任何提示的情况下优于各种最先进的方法，并且还有很强的泛化性。将3D适配器集成到图像编码器的transformer块中，提取有价值的三维信息。</p><ul><li>提出了一种参数高效的微调方法，以使 SAM 适应体积和视频医疗数据。通过创新一系列 3D 适配器，方法有效地将医学图像中的基本三维信息整合到 SAM 的 2D 网络骨干中</li><li>证明本文的 SAM 适应可以应用于各种医学成像模式，包括 CT、MRI 和手术视频数据，用于解剖学、手术场景和肿瘤分割。无需使用任何提示，自动分割始终优于竞争对手的 SOTA 方法</li><li>验证了在对医学图像进行微调后，获得的模型表现出出色的泛化能力，表现出比 SOTA 域泛化方法更优越的性能。</li><li>通过进一步利用提示，本文的方法在具有挑战性的肿瘤分割任务中取得了令人印象深刻的结果，Dice 分数超过了 nnU-Net 38.7%。</li></ul><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法<img src="/../images/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/image-20240918234708949.png" alt="MA-SAM框架"></h3><p>1.图像编码器的参数高效微调</p><p>图像编码器通过使用 FacT 的 parameter-efficient 微调策略进行更新。体积或时间信息通过一组 3D 适配器有效地合并。掩码解码器经过完全微调和修改，以恢复预测分辨率。Reshape 操作用于使 3D 操作与 2D 主干兼容。</p><p>2.合并体积或时间信息</p><p>SAM是为了2D设计的，所以对CT和MRI数据中的解剖结构和3D空间信息不支持，作者将3D适配器集成到SAM中的2D模块中，使其能够有效地处理多维医疗数据。</p><p>如上图所示，每个 3D 适配器由一个归一化层、一个线性下投影层、一个 3D 卷积层和一个激活层和一个线性上投影层组成。体积或时间信息的核心提取主要位于 3D 卷积层内。下投影层的目的是将原始 d 维特征的维数降低为更紧凑的 c 维表示，从而控制新引入参数的数量。相反，向上投影层将恢复特征尺寸。对于每个transformer块，在注意力层之前和之后都加入了两个 3D 适配器，因为这种设计可以获得经验上优越的性能。</p><p>3.适配掩码解码器</p><p>原始 SAM 中的掩码解码器仅包含两个 transformer 层、两个转置卷积层和一个多层感知层，构成了轻量级的架构，SAM对输入的16 x 16的下采样和连续的转置卷积等使生成的最终预测图像分辨率比原始低4倍，然而医学图像的细节非常小，需要更高的分辨率。本文使用了两种方法，一种是“渐进式上采样”，通过集成两个额外的转置卷积操作，对 SAM 解码器进行了适度的调整。每层将特征图上采样 2 倍，四个转置卷积层逐渐将特征图恢复到其原始输入分辨率。第二种方法被称为“多尺度融合”，需要创建一个类似于“U 形”网络的设计。这涉及使用跳过连接将图像编码器的多尺度特征图与掩码解码器的相应阶段连接起来，这一概念类似于 U-Net框架。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>作者在 5 个医学图像分割任务上广泛评估了我们的方法，涵盖了 11 个数据集的三种医学成像模式，即 CT 中的腹部多器官或肿瘤分割、MRI 中的前列腺分割和手术视频中的手术场景分割<img src="/../images/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/image-20240920155438617-1728357318283-34.png" alt=" MA-SAM 方法与 BTCV 数据集上其他最先进方法之间的自动腹部多器官分割的比较。"><img src="/../images/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/image-20240920155511685.png" alt=" MA-SAM 方法与其他最先进的方法在六个前列腺 MRI 数据集上的自动前列腺分割的比较。"> </p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文作者提出了植根于参数高效的微调策略的方法，并在微调过程中成功整合了医学图像的体积或时间信息。在不使用任何提示的情况下，自动分割方法大大优于各种 SOTA 3D 医学图像分割方法,模型还展示了出色的泛化能力，以及在使用提示时在特别具有挑战性的肿瘤分割方面的显着优势。本文的方法可为通用分割框架具有重要的前景，可以应用于各种医学成像模式，以实现全自动和可提示的分割。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-MEDICAL SAM 2: SEGMENT MEDICAL IMAGES AS VIDEO VIA SEGMENT ANYTHING MODEL 2</title>
    <link href="/2024/09/29/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/"/>
    <url>/2024/09/29/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/</url>
    
    <content type="html"><![CDATA[<h2 id="MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2"><a href="#MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2" class="headerlink" title="MEDICAL SAM 2: SEGMENT MEDICAL IMAGES AS VIDEO VIA SEGMENT ANYTHING MODEL 2"></a>MEDICAL SAM 2: SEGMENT MEDICAL IMAGES AS VIDEO VIA SEGMENT ANYTHING MODEL 2</h2><p><img src="/../images/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/image-20240911094929813.png" alt="TITLE"></p><blockquote><p>MEDSAM2  arXiv:2408.00874v1 2024年8月</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Meat公司在23年发表了SAM（segment anyting），有一定颠覆传统CV任务的趋势，在24年4月Meat公司继续发表了SAM2模型，基于SAM模型良好的zero-shot能力、实时检测能力、适应管理复杂场景下的物体遮挡问题，MedSAM2将连续的医学图像看作视频进行分割，取得了非常好的效果。</p><p>医学图像分割的一个重大挑战是模型泛化。具体来说，在特定目标上训练的模型无法轻松适应其他目标。MedSam2模型实现了One-Prompt功能，允许在模型处理数据时随时随地在任何帧上优化分割目标，极大提高了临床医学的便捷性，这是之前的模型难以处理的。</p><ol><li>采用了一种新颖的医学图像即视频理念，这激发了我们设计一种独特的管道，以解锁 MedSAM-2 中的一键分割功能，这是以前的方法几乎无法实现的功能。</li><li>开发了独特的模块和管道，结合了置信度内存库和加权拾取，以在技术上促进这一能力。</li><li>根据 15 个不同的基准（包括 26 个不同的任务）评估了 MedSAM-2，在这些基准测试中，该模型实现了卓越的性能。</li></ol><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h5 id="3D图像"><a href="#3D图像" class="headerlink" title="3D图像"></a>3D图像</h5><p>将连续的2D医学图像视为一个序列来提供上下文信息，以减小在拍摄病人时因患者的移动或者设备的晃动产生的影响。</p><h5 id="iVOS的单点提示分割"><a href="#iVOS的单点提示分割" class="headerlink" title="iVOS的单点提示分割"></a>iVOS的单点提示分割</h5><p>iVOS 的目标是让模型在视频中对任意目标进行交互式分割，而不需要预先知道目标类别。</p><p>假设数据集S，图片标签对$&lt;!–swig￼0–&gt;$，学习函数$y_s&#x3D;f_{\theta}^d(x_s)$ ,其中输入图像$y_s$分割图$x_s$ ，在iVOS任务<br>$$<br>y^k&#x3D;f_{\theta}(x_u^k,P_u)<br>$$<br>$x_u^k$ 表示图像包含看不见的对象 u，而 $P_u$ 是目标看不见的对象 u 上的一组提示，以提示模型对包含该对象的任何可能的 x 进行泛化，这样看来iVOS和 One-Prompt Segmentation 在某些任务上是十分相似的。</p><h5 id="将3D图像视为视频分割"><a href="#将3D图像视为视频分割" class="headerlink" title="将3D图像视为视频分割"></a>将3D图像视为视频分割</h5><p>核心概念包括使用过去预测和提示帧的记忆来调节帧嵌入、图像后编码器。为了让用户单点分割时的信息能传递到其他的输入图像流中，作者还使用了独特的内存机制，</p><p>与 SAM 2 中使用的临时先进先出队列不同，引入了一个“置信度优先”内存库来存储模型的模板。此方法可确保内存库中的模板是模型识别的最准确样本，从而最大限度地减少嘈杂模板的影响。在将图像添加到 SoundBank 时，我们还实现了图像多样性约束，确保内存包含各种图像，以更好地匹配传入的输入图像。</p><p><img src="/../images/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/image-20240911152514202.png" alt="MedSAM2框架"></p><h5 id="MedSAM2d的架构"><a href="#MedSAM2d的架构" class="headerlink" title="MedSAM2d的架构"></a>MedSAM2d的架构</h5><p>Med-SAM2 具有一个将输入抽象为嵌入的图像编码器、一个抽象预测帧嵌入的内存编码器，以及一个使用存储在内存库中的内存来调节输入嵌入的内存注意机制。编码器由一个分层视觉转换器组成，解码器由一个轻量级双向转换器组成，该转换器将提示嵌入与图像嵌入集成在一起。提示嵌入由提示编码器生成，该编码器处理用户的提示以抽象相应的嵌入，记忆注意力组件由一系列堆叠的注意力块组成，每个注意力块都包含自我注意力块，后跟交叉注意力机制，因为内存注意力机制结合了用户提供的中间提示来优化分割结果。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>在实验中，MedSAM-2 在包括腹部器官、视神经、脑肿瘤和皮肤病变在内的15个不同医学数据集上表现出色。特别是在3D腹部器官分割中，MedSAM-2 达到了 88.6% 的 Dice 分数，比之前的最佳模型高出 0.7 个百分点。此外，该模型在视神经、脑肿瘤和甲状腺结节等2D图像分割中，也分别提高了2到3个百分点，并与最先进的SOTA进行比较。实验结果参考<a href="https://mp.weixin.qq.com/s/eu3pWjJzhT4vjbma9AkW0w">link</a>。</p><img src="../images/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/image-20240911155126351.png" alt=" MedSAM、MedSAM-2 连续 3D 医学图像分割比较。"  /><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>MedSAM-2 鼓励进一步的发展和在临床实践中的应用。这种模型不仅提升了医学图像分析的精度，也显著减少了手动标注的工作量，为未来的医学成像工作流带来了变革性的潜力。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>医学影像与SAM</title>
    <link href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%8ESAM/"/>
    <url>/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%8ESAM/</url>
    
    <content type="html"><![CDATA[<h2 id="SAM与医学影像"><a href="#SAM与医学影像" class="headerlink" title="SAM与医学影像"></a>SAM与医学影像</h2><p>SAM</p><p>SAM 是一种可提示的分割架构，由三个主要组件组成，即图像编码器、提示编码器和掩码解码器。图像编码器采用视觉转换器 （ViT） （Dosovitskiy et al.， 2020） 作为支柱，用一组变压器块提取图像的基本特征。提示编码器接受各种类型的提示，包括点、框或文本，并将这些输入编码到提示嵌入中，以促进分割任务。掩码解码器设计为轻量级，它计算图像嵌入和提示之间的交叉注意力，并利用转置卷积层和多层感知来生成分割掩码。当应用于医学图像时，模型的性能会大大下降，因为医学图像呈现的纹理和对象与自然图像不同。这凸显了对 SAM 进行特定于任务的微调以应对此类挑战的必要性。</p><p>为什么倾向于将 SAM 用于医学影像任务呢？这可以归因于与 SAM 相关的三个潜在优势。首先，SAM 的训练数据集由广泛的图像集合组成。在医疗应用的背景下获取类似的大规模训练数据集极具挑战性。尽管 SAM 的训练数据仅包含自然图像，但它并不局限于任何特定的医学成像模式。如果 SAM 微调被证明对一种类型的医学成像有效，那么同样的方法也很有可能也适用于其他模式。其次，经过微调后，SAM 作为预训练的大型模型可能具有稳健泛化的潜力，这对于在关键医疗应用中有效部署智能模型非常重要。第三，SAM 的提示设计为处理肿瘤分割等困难任务的半自动分割提供了一种方便的解决方案。在这些方面，SAM 提供了一个通用的基础模型，有可能适应不同的医学成像模式，为全自动和半自动分割提供良好的泛化能力。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-SAM-UNet: Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images</title>
    <link href="/2024/09/29/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/"/>
    <url>/2024/09/29/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/</url>
    
    <content type="html"><![CDATA[<h2 id="SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images"><a href="#SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images" class="headerlink" title="SAM-UNet: Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images"></a>SAM-UNet: Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images</h2><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20240926191429854.png" alt="SAM-UNet"></p><blockquote><p>arXiv:2408.09886v1 [cs.CV] 19 Aug 2024 </p><p>SAM-UNet：增强通用医学图像的 SAM 零样本分割</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>初始SAM在医学图像上并不适配，本文作者受到 U-Net 的模型在医学图像分割中的卓越性能的启发，提出了 SAM-UNet，这是一种将 U-Net 整合到原始 SAM 的新基础模型，以充分利用卷积强大的上下文建模能力。在图像编码器中并行了一个卷积分支，该分支是用 vision Transformer 分支冻结独立训练的。此外，在掩码解码器中采用了多尺度融合，以促进对不同尺度目标的准确分割。 SA-Med2D-16M 上训练 SAM-UNet，产生了一个通用的医学图像预训练模型。在零镜头分割实验中，模型不仅在所有模态中都明显优于以前的大型医用 SAM 模型，而且还大大减轻了在看不见的模态上看到的性能下降。SAM-UNet 是一种高效且可扩展的基础模型，可以针对医学界的其他下游任务进一步微调。</p><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20241004194345499.png" alt="SAM-UNet-50与现有的SAM模型在训练集中有大量样本的模态"></p><ul><li>具体来说，作者分别介绍了图像编码器和掩码解码器中的两种架构设计。首先，在图像编码器中加入一个并行卷积神经网络 （CNN） 分支，原始的 Vision Transformer （ViT） 分支完全冻结，以保留 SAM 的自然图像编码能力，利用多尺度融合策略来实现多尺度目标的准确分割，并进一步采用了输出令牌设计，使掩码解码器更专门用于医疗领域。</li><li>介绍了架构创新，包括在图像编码器中集成并行 CNN 分支，在掩码解码器中集成多尺度融合设计，这构成了部分参数的新方法SAM 的微调，这两者都已被证明可以有效提高分段性能。</li><li>提出了 SAM-UNet，这是一个在 SA-Med2D-16M 上训练的强大基础模型，增强了 SAM 在通用医学图像上的零镜头分割能力。SAM-UNet 在各种医学影像模态中均具有卓越的性能（SA-Med2D-16M 测试集的 DSC 评分为 0.883）。</li><li>开发了两个版本的 SAM-UNet，即 SAM-UNet-34 和 SAM-UNet-50，其中 SAM-UNet-50 具有更大的参数规模，表现出特别强的性能。</li><li>在 7 个外部数据集上进行了零镜头分割实验，证明 SAM-UNet 的性能明显优于现有的基于 SAM 的模型。SAM-UNet 在训练集中充分代表的模态（如 CT 和 MR）中表现出卓越的性能，并在不太常见的模态中保持稳健的性能而不会显着退化。</li></ul><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20241004200950682.png" alt="SAM-UNet"></p><p>SAM-UNet。该模型由一个双分支图像编码器和一个多尺度融合掩码解码器组成。它是在包含图中所示的八种模态的大型数据集上使用边界框作为提示进行训练的，并在所有十种模态上进行了测试。该图还说明了图像编码器中每个阶段的详细信息。</p><p>SAM：SAM 由三个组件组成：大规模图像编码器、提示编码器和轻量级掩码解码器。图像编码器利用 ViT  来处理高分辨率图像，并以原始图像的 1&#x2F;16 比例生成特征图。提示编码器接受稀疏和密集提示，包括点、边界框或掩码，将它们转换为 256 维向量。然后，掩码解码器采用轻量级交叉注意力机制来集成来自图像和提示编码器的嵌入，从而允许 SAM 根据不同的提示为同一图像生成不同的掩码。</p><p>双分支图像编码器：将 CNN 分支合并到原始 ViT 分支中。在训练阶段只训练参数明显较少的 CNN 分支，而 ViT 分支被冻结。需要注意的是，所有版本的 SAM 中的图像编码器都由四个阶段组成，每个阶段由几个窗口注意力 Transformer 模块和一个全局注意力 Transformer 模块组成。为了优化内存使用并加速推理过程，SAM-UNet 使用 SAM 的 ViT-B 版本作为初始模型。为了匹配 ViT 的四级设计，集成的并行 CNN 也由四个级组成。</p><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20241004211406984.png" alt=" Two-Branch Image Encoder in SAM-UNet"></p><p>提示编码器：SAM-UNet 中的提示编码器与 SAM 保持一致。对于每个边界框，提示编码器使用位置编码对“左上角”和“右下角”像素的中心位置进行编码，生成两个 256 维向量。</p><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20241004211600360.png" alt="改进SAM掩码解码器的架构"></p><p>具有多尺度特征融合的掩码解码器：</p><ol><li>Med-Output 令牌。受 SAM-HQ 的启发，引入了 Med-Output Token（大小为 1×256），并丢弃了原始 SAM 中使用的 IoU 预测令牌和多个掩码令牌。SAM 采用 IoU 预测令牌和多个掩码令牌的原因是，基于点的提示可能会在自然图像中产生歧义。因此，生成多个掩码并根据 IoU 预测分数选择最合适的掩码是合理的。然而，在以边界框作为提示的医学图像分割场景中，这种歧义很少见，因此无需输出预测的 IoU 分数和多个掩码。消融研究也证明了这种变化的有效性。</li><li>多尺度融合分支。在编码器特征图中添加了一个类似 U-Net 的多尺度融合分支，与 CNN 类似，ViT 在早期的 Transformer 块中保留了更多的边缘信息，这可以提高分割精度——这也是类似 U-Net 的网络在分割任务中如此有效的原因。更新后的 Med-Output Token 已获取全局图像上下文和提示令牌信息，通过三层 MLP 进行处理，掩码解码器根据提示 成功生成掩码。</li></ol><p>SAM-UNet 训练：训练数据集是 SA-Med2D-16M。</p><p>损失函数是：<br>$$<br>L &#x3D; 20 × L_{Dice} + L_{Focal}<br>$$</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20241004212025323.png" alt="实验结果"></p><p>SAM-UNet-50、SAM-UNet-34、SAM-Med2D、MedSAM 和 SAM 在大规模测试集上各种模态的性能比较</p><p><img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20241004212056968.png" alt="实验结果"></p><p>SAM-UNet-50、SAM-Med2D、MedSAM 和 SAM 在看不见的模态和数据集上的零镜头分割实验中的性能比较。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文介绍了一种新颖有效的 SAM 部分参数微调架构，并提出了一个基础模型 SAM-UNet，该模型在最大的可用医学图像分割数据集上进行了训练。架构创新包括一个双分支图像编码器和一个具有多尺度融合的掩码解码器。模型在测试集上实现了 SOTA 性能，并在 7 个外部数据集的零镜头分割中表现出更稳定和卓越的性能。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation</title>
    <link href="/2024/09/29/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/"/>
    <url>/2024/09/29/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/</url>
    
    <content type="html"><![CDATA[<h2 id="SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation"><a href="#SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation" class="headerlink" title="SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation"></a>SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation</h2><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/image-20240924192212703.png" alt="SAMUS"></p><blockquote><p>arXiv:2309.06824v1 [cs.CV] 13 Sep 2023</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>SAM是一种杰出的通用图像分割模型，在医学图像分割领域近来引起了相当大的关注。尽管SAM在自然图像上表现出色，但在处理医学图像，特别是涉及低对比度、模糊边界、复杂形状和小尺寸目标的医学图像时，其性能明显下降且泛化能力有限。</p><p>在本文中，作者提出了SAMUS，这是一种专为超声图像分割定制的通用模型。与以前基于SAM的通用模型不同，SAMUS不仅追求更好的泛化性能，还降低了部署成本，使其更适用于临床应用。</p><p>具体而言，基于SAM，引入了一个并行的CNN分支，通过跨分支的注意力将局部特征注入ViT编码器，以实现更好的医学图像分割。然后，开发了Position Adapter和Feature Adapter，将SAM从自然领域适应到医学领域，并从需要大尺寸输入（1024×1024）适应到小尺寸输入（256×256），以更适合临床应用。</p><p>作者收集了一个包括约30,000张图像和69,000个Mask，涵盖6个目标类别的全面超声数据集进行验证。广泛的比较实验在任务特定评估和泛化评估下展示了SAMUS相对于最先进的任务特定模型和通用基础模型的优越性。此外，SAMUS可以部署在入门级GPU上，因为它已经摆脱了长序列编码的限制。</p><p>医学图像分割是一项关键技术，用于识别和突出显示医学图像中的特定器官、组织和病变，是计算机辅助诊断系统的重要组成部分。已经提出了许多深度学习模型，用于自动医学图像分割，展示出巨大的潜力。然而，这些模型都是为特定目标量身定制的，应用于其他目标时需要重新训练，给临床使用带来了很大的不便。</p><p>SAM作为视觉分割的通用基础模型，因其在各种目标上出色的分割能力和强大的零样本泛化能力而广受好评。根据用户提示，包括点、边界框和粗略Mask，SAM能够分割相应的目标。因此，通过简单的提示，SAM可以轻松地适应各种分割应用。这一范 paradigm 使多个个体医学图像分割任务集成到一个统一的框架中（即通用模型），极大地促进了临床部署。</p><p>尽管构建了迄今为止最大的数据集（即SA-1B），但由于可靠临床注释的稀缺性，SAM在医学领域遭遇了快速的性能下降。一些基础模型已经提出，通过在医学数据集上调整SAM，将其适应医学图像分割。然而，与SAM一样，它们在进行特征建模之前在输入图像上执行无重叠的16×Tokenization，这破坏了用于识别小目标和边界的局部信息，使其难以分割具有复杂&#x2F;丝状形状、弱边界、小尺寸或低对比度的临床目标。此外，它们中的大多数需要尺寸为1024×1024的输入，导致GPU消耗巨大，因为生成了长输入序列。</p><p>在本文中，作者提出了SAMUS，旨在将SAM的出色分割性能和强大的泛化能力转移到医学图像分割领域，同时降低计算复杂性。SAMUS继承了SAM的ViT图像编码器、提示编码器和Mask解码器，具有针对图像编码器的定制设计。首先，作者通过减小输入尺寸来缩短ViT分支的序列长度，以降低计算复杂性。然后，作者开发了一个Feature Adapter和一个Position Adapter，用于将ViT图像编码器从自然领域微调到医学领域。</p><p>为了补充ViT图像编码器中的局部（低级）信息，作者引入了一个并行的CNN分支图像编码器，与ViT分支并行运行，并提出了一个跨分支注意力模块，使ViT分支中的每个块可以从CNN分支 assimilate 局部信息。此外，作者构建了一个名为US30K的大型超声数据集，包括30,106张图像和68,570个Mask，以全面评估SAMUS的有效性。实验结果表明，SAMUS在任务特定和通用医学图像分割方面均优于最先进的方法。更重要的是，与SAM相比，SAMUS具有显着的泛化能力，同时大大降低了培训成本。</p><p>贡献总结如下：</p><ul><li>一种基础模型SAMUS，专为通用超声图像分割而设计，与SAM相比，需要更少的GPU资源。</li><li>一种CNN分支图像编码器和跨分支注意力模块，可以有效补充ViT图像编码器中的局部信息。</li><li>一种Feature Adapter和Position Adapter，用于微调ViT分支图像编码器，进一步优化SAM以适应医学领域。</li><li>一个包含30,106张图像和68,570个Mask的大型超声数据集，用于全面评估SAMUS的有效性。</li></ul><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h4 id="1-视觉调优"><a href="#1-视觉调优" class="headerlink" title="1 视觉调优"></a>1 视觉调优</h4><p>随着计算机视觉中基础模型的惊人发展，提出了一系列视觉调优方法，以将这些基础模型适应下游任务。通常，最近的视觉调优方法可以分为五大类，包括微调、参数调优、重新映射调优、提示调优和自适应调优。</p><p>具体来说，微调方法涉及调整预训练模型的整个参数集或有选择地微调预训练模型的特定部分。参数调优方法直接修改模型参数的权重或偏差。重新映射方法通过知识蒸馏、基于权重的重新映射或基于架构的重新映射将从预训练模型中学到的信息传递给下游模型。提示调优通过将一组可学习参数与输入进行结合或设计一个子网络来生成视觉提示的方式，引入了下游任务的知识。Adapter调优是最广泛采用的策略，通过将额外的可学习参数与冻结的预训练模型相结合，促进了下游任务的学习。</p><h4 id="2-将SAM适应到医学图像分割"><a href="#2-将SAM适应到医学图像分割" class="headerlink" title="2 将SAM适应到医学图像分割"></a>2 将SAM适应到医学图像分割</h4><p>SAM在自然图像中表现出色，但在某些医学图像分割任务中遇到困难，尤其是在具有复杂形状、模糊边界、小尺寸或低对比度的目标上。</p><p>为了弥补这一差距，使SAM能够有效地适应医学图像领域，已经提出了几种方法，使用有限的下游医学数据集来调整SAM。MedSAM通过冻结图像编码器和提示编码器，重点调整SAM的Mask解码器，以可接受的成本在医学图像上进行训练。SAMed采用低秩（LoRA）策略对图像编码器进行调优，以更低的计算成本调整SAM，使其更适用于医学图像分割。MSA在ViT图像编码器的每个变换层上采用两个downReLU-upAdapter来引入任务特定信息。</p><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIc" alt="image.png"></p><p>如图1所示，与当前基于SAM的基础模型相比，提出的SAMUS更注重补充局部特征并减少GPU消耗，这对于在临床场景中进行准确且易于部署的医学图像分割至关重要。</p><h4 id="3-方法概述"><a href="#3-方法概述" class="headerlink" title="3 方法概述"></a>3 方法概述</h4><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXId" alt="image.png"></p><p>如图2所示，SAMUS的总体架构继承自SAM，保留了提示编码器和Mask解码器的结构和参数，没有进行任何调整。相比之下，图像编码器经过精心修改，以解决局部特征不足和计算内存消耗过多的挑战，使其更适合于临床友好的分割。主要修改包括减小输入尺寸，重叠的Patch嵌入，向ViT分支引入Adapter，添加CNN分支以及引入跨分支注意力（CBA）。</p><p>具体来说，输入的空间分辨率从1024×1024像素缩小到256×256像素，由于Transformer中较短的输入序列，GPU内存成本大幅降低。重叠的Patch嵌入使用与SAM中的Patch嵌入相同的参数，但其Patch跨度减半，与原始跨度保持良好的信息一致性。</p><p>ViT分支中的Adapter包括Position Adapter和5个Feature Adapter。Position Adapter用于适应较短序列中的全局位置嵌入，因为输入尺寸较小。第一个Feature Adapter遵循了重叠的Patch嵌入，以使输入特征与预训练的ViT图像编码器所需的特征分布相一致。其余的Feature Adapter附加到全局Transformer中的前馈网络的残差连接上，以微调预训练图像编码器。</p><p>在CNN分支方面，它与ViT分支并行，通过CBA模块向后者提供互补的局部信息，该模块以ViT分支特征作为Query，并与CNN分支的特征建立全局依赖性。值得注意的是，CBA仅集成到每个全局Transformer中。最后，两个分支的输出被合并为SAMUS的最终图像特征嵌入。</p><h4 id="4-ViT分支中的Adapter"><a href="#4-ViT分支中的Adapter" class="headerlink" title="4 ViT分支中的Adapter"></a>4 ViT分支中的Adapter</h4><p>为了促进SAM的训练图像编码器（即ViT分支）在更小的输入尺寸和医学图像领域的泛化，作者引入了一个Position Adapter和5个Feature Adapter。这些Adapter可以有效地调整ViT分支，同时只需要更少的参数。</p><p>具体来说，Position Adapter负责调整位置嵌入以匹配嵌入序列的分辨率。它首先通过Stride和Kernel-Size为2的最大池化对位置嵌入进行降采样，实现与嵌入序列相同的分辨率。随后，应用Kernel-Size为3×3的卷积操作来调整位置嵌入，进一步帮助ViT分支更好地处理较小的输入。</p><p>所有Feature Adapter具有相同的结构，包括下投影、激活函数和上投影3个组成部分。每个Feature Adapter的过程可以表示为：<br>$$<br>A(x)&#x3D;g(xE_d)Eu<br>$$<br>其中g代表GELU激活函数，$E_D\in R^{d<em>d&#x2F;4}$ 和 $E_u \in R^{d&#x2F;4</em>d}$ 是投影矩阵，d是特征嵌入的维度，通过这些简单的操作，Feature Adapter使ViT分支更好的适应医学图像领域的特征分布</p><h4 id="5-CNN分支"><a href="#5-CNN分支" class="headerlink" title="5 CNN分支"></a>5 CNN分支</h4><p>CNN分支由顺序连接的卷积-池化块组成。具体来说，输入首先通过一个单一的卷积块，然后通过3个卷积-池化块进行处理。</p><p>然后，CNN分支中的特征映射与ViT分支的特征映射具有相同的空间分辨率。在CNN分支的其余部分，这种单一的卷积块被连续重复4次。CNN分支的这种简约和轻量级设计是为了防止训练过程中的过拟合。</p><h4 id="6-跨分支注意力"><a href="#6-跨分支注意力" class="headerlink" title="6 跨分支注意力"></a>6 跨分支注意力</h4><p>跨分支注意力（CBA）模块在CNN分支和ViT分支之间建立了一个桥梁，以进一步通过ViT分支补充缺失的局部特征。</p><p>对于来自ViT分支Fv和CNN分支的特征映射对，单一Head的跨分支注意力可以表示为：<br>$$<br>F(F_v,F_c)&#x3D;(S(\frac{F_vE_q(F_cE_k)^T}{\sqrt{d_m}})+R)(F_cE_v)<br>$$<br>其中S代表Softmax函数，$E_q \in R^{d<em>d_m} , E_k \in R^{d</em>d_m} 和 E_v \in R^{d<em>d_m}$是用于将$F_c$和$F_v$投影到不同特征子空间的可学习权重矩阵。$R \in R^{hw</em>hw}$是相对位置嵌入，$d_m$是CBA的维度，CBA的最终输出是这种单头注意力的线性组合。 </p><h4 id="7-训练策略"><a href="#7-训练策略" class="headerlink" title="7 训练策略"></a>7 训练策略</h4><p>在训练之前，SAMUS使用在SA-1B上训练的权重来初始化从SAM继承的参数。其余参数被随机初始化。在训练过程中，只有Adapter、CNN分支和CBA模块的参数会被更新，而其他参数将保持冻结。训练过程通过组合损失函数进行监督，包括Dice损失和二元交叉熵损失。</p><p>为了方便使用，SAMUS只使用最简单的正点提示。作者通过在标签的前景区域中随机采样一个点来模拟专家提供提示的过程。SAMUS使用Adam优化器进行训练，初始学习率为0.0001，批大小为8，共进行200个epochs的训练。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="1-与SOTA任务特定方法的比较"><a href="#1-与SOTA任务特定方法的比较" class="headerlink" title="1 与SOTA任务特定方法的比较"></a>1 与SOTA任务特定方法的比较</h4><p>比较方法：选择了12种SOTA任务特定方法进行比较，涵盖了基于CNN、基于Transformer和CNN-Transformer混合方法。</p><ul><li>基于CNN的方法包括U-Net、CPFNet、CA-Net、CE-Net和AAU-Net</li><li>基于Transformer的方法包括SwinUnet、SETR和MISSFormer</li><li>CNN-Transformer混合方法包括TransUNet、TransFuse、FAT-Net和H2Former</li></ul><h5 id="定量结果："><a href="#定量结果：" class="headerlink" title="定量结果："></a>定量结果：</h5><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIg" alt="image.png"></p><p>在TN3K、BUSI、CAMUS-LV、CAMUS-MYO和CAMUS-LA上，不同任务特定方法的定量结果总结在表7中。</p><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIh" alt="image.png"></p><p>在这些最先进的方法中，H2Former在TN3K和CAMUS-MYO上取得了最佳性能，分别获得了82.48%和87.31%的平均Dice分数。TransUnet、CA-Net和FATNet在BUSI、CAMUS-LV和CAMUS-LA上取得了最佳性能，平均Dice分数分别为82.22%、93.59%和91.55%。</p><p>相比之下，SAMUS在包括TN3K、BUSI、CAMUS-LV、CAMUS-MYO和CAMUS-LA在内的所有5个任务上都取得了更好的性能，平均Dice分数分别为84.45%、85.77%、93.73%、87.46%和91.58%。这验证了SAMUS将SAM适应医学图像领域的有效性。</p><h5 id="定性结果："><a href="#定性结果：" class="headerlink" title="定性结果："></a>定性结果：</h5><p>不同方法的定性分割结果，包括U-Net、AAU-Net、MISSFormer、H2Former和SAMUS，如图4所示。</p><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIi" alt="image.png"></p><p>从视觉上看，超声图像的分割因其低对比度、不均匀特征和模糊的物体边界而具有挑战性。现有方法难以准确区分目标和背景，导致了大量的假阴性和&#x2F;或假阳性。</p><p>相比之下，SAMUS在保持目标区域的完整性和减少假阳性方面表现出优越性。这归功于SAM框架的固有优势，以及SAMUS引入的具体调整和设计。</p><h5 id="泛化能力："><a href="#泛化能力：" class="headerlink" title="泛化能力："></a>泛化能力：</h5><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIp" alt="image.png"></p><p>不同任务特定方法的泛化性能定量比较如图3所示。在比较方法中，H2Former、TransUnet和TransFuse分别在DDTI、UDIAT和HMC-QU上取得了最佳性能。</p><p>相比之下，SAMUS在每个数据集上都超过了最佳比较方法，并分别提高了Dice分数，平均增加了7.06%、12.22%和7.42%。在可见和不可见数据集之间的性能比较中，与其他比较方法相比，SAMUS在3个不同的分割任务中都遇到了最小的性能下降。</p><p>一个有趣的观察是，在乳腺癌分割任务上，SAMUS在不可见数据集（即UDIAT）上的性能甚至优于可见数据集（即BUSI）上最佳比较方法。这显示了SAMUS在处理未知领域方面的出色泛化能力，展示了它在各种医学图像分割场景中的稳健性和适应性。</p><h4 id="2-与SOTA基础模型的比较"><a href="#2-与SOTA基础模型的比较" class="headerlink" title="2 与SOTA基础模型的比较"></a>2 与SOTA基础模型的比较</h4><h5 id="比较方法："><a href="#比较方法：" class="headerlink" title="比较方法："></a>比较方法：</h5><p>选择了4种SOTA基础模型进行比较，包括原始的SAM、MedSAM、SAMed和MSA。</p><h5 id="定量结果：-1"><a href="#定量结果：-1" class="headerlink" title="定量结果："></a>定量结果：</h5><p>为了验证SAMUS作为一个基础模型在各种下游任务上的通用性能，作者在US30K数据集上进行了基础模型的比较。</p><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIq" alt="image.png"></p><p>如表8所示，SAM，即在SA-1B上训练的模型，在未经调整的情况下在医学图像分割上表现出显著的性能下降。通过在US30K数据集上简单调整SAM的Mask解码器，MedSAM显著改善了SAM的性能。</p><p>在比较的基础模型中，MAS是表现最佳的模型，有效提高了SAM在TN3K、BUSI、CAMUS-LV、CAMUS-MYO和CAMUS-LA上的分割性能，平均Dice分数分别增加了53.08%、27.65%、62.77%、53.05%和74.52%。</p><p>与MSA相比，SAMUS在上述5个数据集中始终取得了显著的改进，Dice分数分别为83.05%、84.54%、91.13%、83.11%和92%。这验证了SAMUS中的CNN分支和CBA模块的有效性，特别是在补充对于医学图像分割至关重要的局部信息方面。</p><h5 id="定性结果：-1"><a href="#定性结果：-1" class="headerlink" title="定性结果："></a>定性结果：</h5><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIr" alt="image.png"></p><p>图5展示了不同基础模型的定性分割结果，包括SAM、MedSAM、SAMed、MSA和SAMUS。在医学图像中没有经过调整的情况下，SAM完全失去了分割一切的能力。通过将调整方法应用于SAM，MedSAM、SAMed和MSA可以在一定程度上恢复SAM的分割能力。</p><p>然而，它们仍然难以在超声图像中准确勾画分割边界，导致大量的假阴性和假阳性。相比之下，SAMUS表现出卓越的性能，能够准确地定位分割边界，即使是低对比度的分割。这与使用图像编码器补充局部信息对于医学图像分割中的边界&#x2F;形状保持特别有帮助的分析是一致的。</p><h5 id="泛化能力：-1"><a href="#泛化能力：-1" class="headerlink" title="泛化能力："></a>泛化能力：</h5><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIs" alt="image.png"></p><p>不同基础模型在未知领域上的比较总结在图6中。总的来说，在US30K上训练的基础模型在医学图像分割任务中的泛化性能要远远优于原始的SAM。在三对分割任务中，即甲状腺结节分割、乳腺癌分割和心肌分割，所有基础模型在心肌分割上都遇到了严重的性能下降，并且在乳腺癌分割上有很好的泛化性能。</p><p>SAMUS在所有三个未知数据集上始终表现出最佳性能，分别为甲状腺结节、乳腺癌和心肌分割的Dice分数为66.78%、78.06%和56.77%。这强调了SAMUS在未知领域的卓越泛化能力，始终明显优于其他基础模型。</p><h5 id="部署成本："><a href="#部署成本：" class="headerlink" title="部署成本："></a>部署成本：</h5><p>作者对SAMUS和其他基础模型在部署效率方面进行了全面评估，包括GPU内存成本、模型参数、计算复杂性、推理速度、分割性能和泛化性能。</p><p>为了便于比较，GPU内存在训练期间将批处理大小设置为1时进行测试，并以千兆字节（即G）为单位进行测量。计算复杂性和推理速度以每秒浮点运算（即GFLOPs）和每秒帧数（即FPS）来衡量。分割性能以在所有可见数据集上的平均Dice分数来衡量，泛化性能则基于在所有未知数据集上的平均Dice分数进行评估。所有上述指标都经过归一化，并在雷达图中呈现，如图7所示。</p><p><img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/bVbXIu" alt="image.png"></p><p>在比较模型中，SAMed的GPU内存成本、模型参数、计算复杂性和推理速度都最低。然而，它的分割和泛化性能都不如MSA和SAMUS。尽管SAMUS拥有比其他模型更多的参数，但其GPU内存成本和计算复杂性仍然是第二低的，而推理速度是第二快的，表明SAMUS是一个更适合临床的模型。</p><p>此外，SAMUS的部署性能与最易于部署的方法（即SAMed）非常接近，并且在分割和泛化性能方面要好得多。</p><h4 id="3-消融实验"><a href="#3-消融实验" class="headerlink" title="3 消融实验"></a>3 消融实验</h4><h5 id="SAMUS中每个组件的有效性："><a href="#SAMUS中每个组件的有效性：" class="headerlink" title="SAMUS中每个组件的有效性："></a>SAMUS中每个组件的有效性：</h5><p>SAMUS中的4个组件，包括CNN分支、CBA、Feature Adapter和Position Adapter，依次引入原始SAM并在TN3K和BUSI数据集上进行评估。</p><p><img src="C:/Users/Wuyueyu/Desktop/1/SAM/image/SAMUS%2520Adapting%2520Segment%2520Anything%2520Model%2520for%2520Clinically-Friendly%2520and%2520Generalizable%2520Ultrasound%2520Image%2520Segmentation/bVbXIv" alt="image.png"></p><p>如表9所总结的，SAMUS的任何一个组件都能有效提高SAM在医学任务上的分割性能和泛化能力。即使是一个简单的Position Adapter也可以在TN3K、DDTI、BUSI和UDIAT上分别提高SAM的Dice分数分别为50.6%、38.1%、26.77%和30.54%。通过引入局部特征，CNN分支的性能提升明显高于Position Adapter。</p><p>此外，仅仅将CNN分支和ViT分支的输出进行融合并不是最佳选择。引入CBA可以进一步促进对局部特征的探索，从而在Dice上相对于CNN分支实现平均增长1.48%和2.11%。</p><p>通过结合所有四个组件，SAMUS实现了最佳的分割性能和泛化性能。</p><h5 id="不同提示对SAMUS的影响："><a href="#不同提示对SAMUS的影响：" class="headerlink" title="不同提示对SAMUS的影响："></a>不同提示对SAMUS的影响：</h5><p>为了分析提示的效果，作者评估了在不同点提示下在US30K上训练的SAMUS的性能。总的来说，SAMUS对点的位置和数量具有很强的鲁棒性。对于具有大的类内表征变化的目标（例如甲状腺结节、左心室和心肌），在不同位置的单点提示下，Dice分数的性能变化在1%范围内。</p><p>此外，通过引入多点提示，性能可以得到很大的提升。相比之下，对于具有均匀特征的目标（例如乳腺癌和左心房），在不同单点提示下的性能变化在±0.3%的范围内，引入多点提示未必会带来性能提升。一个可能的原因是使用更多的点可能会产生信息冗余或排除。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Segment Anything in Medical Images</title>
    <link href="/2024/09/29/0-Segment-Anything-in-Medical-Images/"/>
    <url>/2024/09/29/0-Segment-Anything-in-Medical-Images/</url>
    
    <content type="html"><![CDATA[<h2 id="Segment-Anything-in-Medical-Images"><a href="#Segment-Anything-in-Medical-Images" class="headerlink" title="Segment Anything in Medical Images"></a>Segment Anything in Medical Images</h2><p><img src="/../images/0-Segment-Anything-in-Medical-Images/image-20240921104718830.png" alt="MEDSAM"></p><blockquote><p>arXiv:2304.12306v3 [eess.IV] 1 Apr 2024</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>本文介绍MedSAM这个基础模型，旨在让SAM弥补在医学图像分割领的不足，在大量的图像掩码上开发，涵盖多种病灶类型，证明了比模态专业模型更好的准确性和稳健性。在广泛的任务中提供准确高效的细分。</p><p>分割是医学成像分析中的一项基本任务，它涉及识别和描绘各种医学图像中的感兴趣区域 （ROI），例如器官、病变和组织。准确分割对于许多临床应用至关重要，包括疾病诊断、治疗计划和疾病进展监测 。长期以来，手动分割一直是描绘解剖结构和病理区域的黄金标准，但这个过程耗时、劳动密集，并且通常需要高度的专业知识。所以基于深度学习的方法具有很大的研究价值，本文使用分割基础模型SAM，SAM 具有很好的泛化能力， MedSAM是一个改进的基础模型，可显著提高 SAM 在医学图像上的分割性能。MedSAM 通过在具有超过 100 万对医学图像-掩模对的前所未有的数据集上微调 SAM 来实现这一目标。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-Segment-Anything-in-Medical-Images/image-20240921111617581.png" alt="MedSAM"></p><p>MedSAM 在可以处理各种分割任务的大规模数据集上进行训练。该数据集涵盖了各种解剖结构、病理状况和医学成像模式。洋红色轮廓和掩码叠加层分别表示专家注释和 MedSAM 分割结果。</p><p>Computed Tomography (CT), Magnetic Resonance Imaging (MRI), 和 endoscopy是最主要的医学数据，CT 和 MRI 图像提供 3D 身体结构的详细横截面视图，其他的还有ultrasound（超声）, pathology（病理学）, fundus（眼底）, dermoscopy（皮肤镜检查）, mammography（乳腺X线摄影）, 和Optical Coherence Tomography (OCT 光学相干断层扫描)，这些模态及其相应的细分目标的多样性强调了通用且有效的细分模型的必要性，该模型能够处理与每种模态相关的独特特征。</p><p><img src="/../images/0-Segment-Anything-in-Medical-Images/image-20240921131805670.png" alt="a,b"></p><p>a : 每种模态中的医学图像掩码对数。</p><p>b : MedSAM 是一种可提示的分割方法，用户可以使用边界框来指定分割目标。源数据作为 源数据 文件提供。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>定量和定性评估结果。</p><p><img src="/../images/0-Segment-Anything-in-Medical-Images/image-20240921132241403.png" alt="内部数据实验结果"></p><p>a : 86 个内部验证任务的绩效分布，根据骰子相似系数 （DSC） 分数的中位数。框内的中心线表示中值，框的下边界和上边界分别描绘第 25 个和第 75 个百分位数。选择须线以显示四分位距的 1.5。向上三角形表示最小值，向下三角形表示最大值。</p><p>b : 用于可视化 86 个内部验证任务的性能对应关系的 Podium 图。上半部分：每个彩色点表示使用相应方法在一项任务上实现的 DSC 中位数。对应于相同任务的点由一条线连接。下半部分：条形图表示每种方法获得排名的频率。MedSAM 在大多数任务中排名第一。</p><p>c : 内部验证集上的可视化分割示例。这四个例子分别是计算机断层扫描 （CT）、（磁共振成像）MRI、超声和内窥镜检查图像中的肝癌、脑癌、乳腺癌和息肉。蓝色：边界框提示;黄色：分割结果。Magenta：专家注释。源数据作为源数据文件提供。</p><p><img src="/../images/0-Segment-Anything-in-Medical-Images/image-20240921132414523.png" alt="外部数据实验结果"></p><p>a ：60 个外部验证任务的中位数骰子相似系数 （DSC） 分数的性能分布。框内的中心线表示中值，框的下边界和上边界分别描绘第 25 个和第 75 个百分位数。选择须线以显示四分位距的 1.5。向上三角形表示最小值，向下三角形表示最大值。</p><p>b ：用于可视化 60 个外部验证任务的性能对应关系的 Podium 图。上半部分：每个彩色点表示使用相应方法在一项任务上实现的 DSC 中位数。对应于相同任务的点由一条线连接。下半部分：条形图表示每种方法获得排名的频率。MedSAM 在大多数任务中排名第一。</p><p>c ：在外部验证集上可视化的分割示例。这四个例子分别是 CT、MR、超声和内窥镜图像中的淋巴结、宫颈癌、胎头和息肉。源数据作为 源数据 文件提供。</p><p>框架：</p><p>在分割性能和计算效率之间取得平衡，采用基本 ViT 模型作为图像编码器，因为广泛的评估表明，较大的 ViT 模型，如 ViT Large 和 ViT Huge，在准确性方面仅提供边际改进 ，同时显着增加了计算需求。</p><p>具体来说，基本ViT模型由12个transformer层组成，每个模块包括一个多头自注意力模块和一个包含层归一化的多层感知器（MLP）模块。使用掩蔽的自动编码器建模进行预训练，然后在 SAM 数据集上进行完全监督训练。输入图像（1024 × 1024 × 3）被重塑为一系列大小为 16 × 16 × 3 的扁平化 2D 块，在通过图像编码器后，图像嵌入中的特征尺寸为 64 × 64，缩小了 16×。提示编码器将边界框提示的角点映射到 256 维矢量嵌入。特别是，每个边界框都由左上角点和右下角点的嵌入对表示。为了在计算图像嵌入后促进实时用户交互，采用了轻量级掩码解码器架构。它由两个用于融合图像嵌入和提示编码的转换器层和两个转置卷积层组成，用于将嵌入分辨率提高到256×256。随后，嵌入经历 sigmoid 激活，然后进行双线性插值以匹配输入大小。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>应用：在肿瘤学领域，MedSAM 可以在加速 3D 肿瘤注释过程方面发挥关键作用，从而能够随后计算肿瘤体积，这是评估疾病进展和治疗反应的关键生物标志物 。MedSAM 为使自然图像基础模型适应新领域提供了一种成功的范式，可以进一步扩展到生物图像分割，例如光学显微镜图像中的细胞分割和电子显微镜图像中的细胞器分割。</p><p>局限：训练集中的模态不平衡，CT、MRI 和内窥镜图像在数据集中占主导地位。这可能会影响模型在代表性较少的模式（例如乳房 X 光检查）上的性能。另一个限制是它难以分割血管状分支结构，因为在此设置中边界框提示可能不明确。例如，动脉和静脉在眼底图像中共享相同的边界框。</p><p>本文的研究构建能够管理大量分割任务的单一基础模型的可行性，从而消除了对特定任务模型的需求。MedSAM 作为医学图像分割的首个基础模型，在加速新诊断和治疗工具的发展方面具有巨大潜力，并最终有助于改善患者护理</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Segment Anything Model for Medical Images</title>
    <link href="/2024/09/29/0-Segment-Anything-Model-for-Medical-Images/"/>
    <url>/2024/09/29/0-Segment-Anything-Model-for-Medical-Images/</url>
    
    <content type="html"><![CDATA[<h2 id="Segment-Anything-Model-for-Medical-Images？"><a href="#Segment-Anything-Model-for-Medical-Images？" class="headerlink" title="Segment Anything Model for Medical Images？"></a>Segment Anything Model for Medical Images？</h2><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20240921133338408.png" alt="TITLE"></p><blockquote><p>分割所有医学图像模型？ arXiv:2304.14660v5 [eess.IV] 12 Dec 2023 </p><p>MED SAM</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Segment Anything Model （SAM） 是第一个用于常规图像分割的基础模型。它在各种自然图像分割任务上取得了令人印象深刻的成果。然而，由于模态复杂、解剖结构精细、对象边界不确定且复杂以及对象尺度宽，医学图像分割 （MIS） 更具挑战性。为了充分验证 SAM 在医疗数据上的性能，本文收集并分类了 53 个开源数据集，并构建了一个大型医疗分割数据集，其中包含 18 种模态、84 个对象、125 个对象-模态配对目标、1050K 2D 图像和 6033K 掩码。在所谓的 COSMOS 1050K 数据集上全面分析了不同的模型和策略。发现主要包括以下几点：</p><ol><li>SAM 在某些特定目标上表现出优异的性能，但在其他情况下不稳定、不完美甚至完全失效。</li><li>使用大型 ViT-H 的 SAM 比使用小型 ViTB 的 SAM 表现出更好的整体性能。</li><li>SAM 在手动提示（尤其是框）下的表现优于 Everything 模式。</li><li>SAM 可以帮助人工注释，提高标记质量和减少时间。</li><li>SAM 对中心点的随机性和紧凑的框提示很敏感，可能会出现严重的性能下降。</li><li>SAM 的表现优于具有 1 个或几个点的交互式方法，但随着点数的增加，SAM 的性能会超过。</li><li>SAM 的性能与不同因素相关，包括边界复杂性、强度差异等。</li><li>在特定医疗任务上微调 SAM 可以使其 ViT-B 和 ViT-H 的平均 DICE 性能分别提高 4.39% 和 6.68%。</li></ol><p>ChatGPT和GPT-4等大型语言模型的出现引发了自然语言处理 （NLP） 的新时代，其特点是其卓越的零样本和少样本泛化能力。这一进展激发了研究人员为计算机视觉 （CV） 开发类似的大规模基础模型。第一个提出的基础 CV 模型主要基于 CLIP  和 ALIGN  等预训练方法。CLIP 可以通过将视觉概念和细节（如对象形状、纹理和颜色）与相应的文本描述相关联来识别和理解它们。这使得 CLIP 能够执行广泛的任务，包括图像分类、对象检测，甚至视觉问答。ALIGN 可以生成图像区域的自然语言描述，提供比传统图像字幕方法更详细、更易解释的结果。DALL·E  的开发是为了从文本描述中生成图像。该模型是在文本-图像对的大型数据集上训练的，该数据集可以创建各种图像，从逼真的对象到结合多个概念的超现实场景。但是，这些模型尚未针对图像分割进行明确优化，尤其是医学图像分割 （MIS）。</p><p>最近，SAM 被提议作为图像分割的创新基础模型。SAM 基于视觉转换器 （ViT） 模型，并在一个包含 10 亿个蒙版的 1100 万张图像的大型数据集上进行训练。SAM 最大的亮点是它对看不见的数据集和任务具有良好的零镜头分割性能。这个过程由不同的提示（例如点和框）驱动，用于指示目标对象的像素级语义和区域级位置。它已被证明具有高度的通用性，能够处理广泛的分割任务。基于SAM的预训练模型，几篇论文进一步研究了它在不同的零镜头分割场景中的性能。大致将它们分为两类：1） 非医疗和 2） 医疗应用</p><ul><li>非医学图像应用中的 SAM</li></ul><p>研究侧重于测试 SAM 在 Everything 模式下分割伪装对象的性能。结果表明，它在这些场景中的表现很差，例如，视觉上隐藏在自然环境中的伪装动物。作者发现，SAM 未能检测到工业场景中的隐藏缺陷。探索了三种测试用于各种应用程序的 SAM 方法（点、框和所有内容）。具体来说，他们的任务涵盖自然图像（突出&#x2F;伪装&#x2F;透明对象分割和阴影检测）、农业（作物分割和病虫害和树叶病害监测）、制造（异常和表面缺陷检测）和遥感（建筑和道路开采）。他们得出的结论是，尽管 SAM 可以在某些情况下实现良好的性能，例如突出对象分割和农业分析，但在其他应用中产生的结果很差。他们还验证，与自动 Everything 方法相比，人工提示可以有效地优化细分结果。</p><ul><li>医学影像分析中的 SAM</li></ul><p>J评估了 Everything 模式下在各种解剖结构（例如，大脑、肺和肝脏）和模式（计算机断层扫描 （CT） 和磁共振成像 （MRI））中分割病变区域时的 SAM。实验结果表明，SAM 相对擅长分割边界清晰的器官区域，但可能难以准确识别无定形病变区域。然后，另一项研究使用自动 Everything 和两种手动提示（点和框）策略（Ji et al.， ）评估了 SAM 在一些医疗保健子领域（视神经检查和眼底、息肉和皮肤病变分割）的性能。作者发现，SAM 需要大量的人类先验知识（即提示点）才能在这些任务上获得相对准确的结果。否则，SAM 会导致错误的分段，尤其是在未给出提示的情况下。在使用 MRI 的大脑提取任务中，M等人将 SAM 与 FMRIB 软件库的大脑提取工具 （BET） 进行了比较。定量结果表明，SAM 的分割结果优于 BET，证明了 SAM 在脑提取任务中的应用潜力。邓评估了 SAM 在数字病理分割任务中的性能，包括全玻片成像上的肿瘤、非肿瘤组织和细胞核分割。结果表明，SAM 为大型连接对象提供了出色的分割结果。</p><p>但是，对于密集实例对象分割，它可能无法始终如一地实现令人满意的性能，即使提示所有目标框或每个图像 20 个点也是如此。周在 Everything 设置下使用五个基准数据集将 SAM 应用于息肉分割任务。结果表明，尽管 SAM 在某些情况下可以准确分割息肉，但 SAM 与最先进的方法之间存在很大差距。此外，Liu为 3D Slicer 软件 配备了 SAM，以协助在医学图像上开发、评估和利用 SAM。最近，几项研究在 ≥10 个公共 MIS 数据集或任务上测试了 SAM，一组研究员得出的结论是，SAM 的零镜头分割性能远不如传统的基于深度学习的方法。另一种的作者使用不同数量的点提示评估了 SAM 的性能，他们观察到，随着点的增加则 SAM 的性能会收敛。他们还注意到，SAM 的性能 1） 总体中等，2） 在不同数据集和案例中极不稳定。马和Wang验证了原始 SAM 在许多医学数据集上可能会失败，平均 DICE 评分为 58.52%。然后，他们使用医学图像对 SAM 进行了微调，发现与 SAM 相比，拟议的 MedSAM 在 DICE 上实现了 22.51% 的改进。Wu 等人采用 Adapter 技术对 SAM 进行微调并增强其医疗能力。实验验证了他们提出的医用 SAM适配器可以胜过最先进的 （SOTA） MIS 方法（例如，nnUnet ）。虽然上述工作调查了 SAM 在 MIS 中的表现，但它们至少存在以下限制之一：</p><ol><li>小数据集。以前的研究仅评估了 SAM 在 MRI、CT 和数字病理学等模式中的表现。它们包含有限数量的分段对象。然而，医学图像包含多种模态和许多解剖结构或其他需要分割的物体。这限制了上述研究在 MIS 领域的综合分析等人，</li><li>单一 SAM 测试策略。大多数以前的研究用有限甚至只有一种类型的测试模式&#x2F;策略评估了 SAM。然而，不同的医疗对象通常表现出不同的特性，因此可能有自己合适的测试模式。有限的测试策略可能导致对 SAM 的分析不准确和不完整。</li><li>缺乏全面和深入的评估。一些现有工作仅通过在线演示提供的可视化结果评估了 SAM。此外，一些研究仅关注有限的指标（例如 DICE 或 IOU）来评估 SAM 的性能。大多数研究没有调查 SAM 对医疗对象的感知。因此，SAM 的分割性能与医疗对象属性之间的相关性没有得到仔细进行。</li></ol><p>对医疗物体感知的分析至关重要。它可以帮助社区更好地了解影响 SAM 分割性能的因素（即感知医疗对象的能力），从而更好地开发新一代通用医疗分割模型。在本报告中，构建了一个名为 COSMOS 1050K 的大型医学图像数据集，包括 1050K 图像，具有 18 种不同的模态（见图 1）和 84 个对象（例如，解剖结构、病变、细胞、工具等），以覆盖整个身体（见图 2）。这可以帮助我们全面分析和评估 SAM 在医学图像上的性能。然后，我们充分探索了 SAM 的不同测试策略，并提供了丰富的定量和定性实验结果，以展示 SAM 对医疗对象的感知。最后，我们深入评估了 SAM 的性能与对象的特性（例如，复杂性、对比度和大小）之间的相关性。我们希望这份全面的报告可以为社区提供一些关于医疗 SAM 未来发展的见解。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006163847704.png" alt="图1 "></p><p>COSMOS 1050K 数据集包含各种模式，涉及 （a） CT，（b） MRI，（c） T1 加权 （T1W） MRI，（d） T2 加权 （T2W） MRI，（e） ADC MRI，（f） 电影 MRI，（g） CMR，（h） 弥散加权 （DW） MRI，（i） 造影剂后 T1 加权 （T1-GD） MRI，（j） T2 液体衰减反转恢复 （T2- FLAIR） MRI，（k） 组织病理学，（l） 电子显微镜，（m） 超声 （US），（n） X 射线，（o） 眼底， （p） 结肠镜检查，（q） 皮肤镜检查和 （r） 显微镜检查。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006163925591.png" alt="图2"></p><p>COSMOS 1050K 数据集涵盖了大多数生物医学对象，例如脑肿瘤、眼底脉管系统、甲状腺结节、脊柱、肺、心脏、腹部器官和肿瘤、细胞、息肉和仪器。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>医学影像有多种模式，例如 CT、MRI、超声 （US） 和 X 射线。不同模态之间存在较大的域差距，各种模态在可视化特定对象（包括解剖结构和病变）方面有其优势。为了全面评估 SAM 在 MIS 中的泛化性能，作者收集了 53 个公共数据集并对其进行标准化以构建大型 COSMOS 1050K 数据集。对于 COSMOS 1050K 的分类系统（例如，模态分类），参考了每个公共数据集的官方介绍和最近发表的研究（表1）。图 1 和图 2 分别说明了数据集中涵盖的各种成像模式和大多数临床分割对象。作者从以下两个方面对 COSMOS 1050K 进行了详细介绍，包括图像采集和预处理规范。</p><h4 id="1-数据集合"><a href="#1-数据集合" class="headerlink" title="1.数据集合"></a>1.数据集合</h4><p>医学图像涵盖广泛的对象类型，例如脑器官和肿瘤、肺和心脏、腹部、脊柱、细胞和息肉。表 1 列出了收集的 MIS 数据集的详细列表，图 3 （a） 显示了预处理后每个数据集的数量。为了与评估 SAM 的不同模式兼容，采用了以下排除标准：</p><p>1） 排除极小的物体，例如图 4 （a） 所示的耳蜗和输尿管。这是因为在极小的对象上自动生成点或框提示很困难。</p><p>2） 排除 3D 体积中随着切片顺序提取而其整体目标明显分离的物体，例如肠道（如图 4 （b） 所示）、下颌骨和甲状腺。我们的目标是避免混淆主对象并为每个对象生成唯一的框。</p><p>3） 排除整体结构相对离散的物体，例如乳腺癌的组织病理学图像（见图 4 （c））、肺气管树切片（见图 4 （d））、肾动脉和静脉。</p><p>这些对象中的大多数在 2D 切片中分散为多个项目，并嵌入到其他对象中，导致无法合理地对这些对象使用 SAM 的提示模式进行验证。根据上述标准，COSMOS 1050K 现在总共包含 84 个对象，它们的数量如图 3 （b） 所示。这些对象在一张图像中仅分类一次，没有区分位置或详细划分（例如，“左肺”和“右肺”被归类为“肺”，各种器械被视为“工具”）。更多细节可以在图 3 的图例中找到。模态和图像分辨率的直方图分布分别显示在图 3 （c） 和图 3 （d） 中。鉴于同一对象在不同模态中的显著变化，包括灰度分布和纹理特征的差异，我们进一步将它们分为 125 个对象-模态配对目标。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006164317466.png" alt="图3"></p><p>COSMOS 1050K 数据集的统计数据。</p><p>（a） 预处理后的数据集数量。</p><p>（b） 84 个对象数量的直方图分布，如图例中提供的缩写映射所示。</p><p>（c） 模态数量。</p><p>（d） 图像分辨率的直方图分布。在 （d） 中，每个条形代表一个区域间隔分布，例如 128 ∗ 128 代表图像区域间隔 （0， 128 ∗ 128）;256 ∗ 256 表示图像区域间隔（128 ∗ 128、256 ∗ 256）。</p><h4 id="2-数据集预处理规范"><a href="#2-数据集预处理规范" class="headerlink" title="2.数据集预处理规范"></a>2.数据集预处理规范</h4><p>COSMOS 1050K 包含不同的标签、模态、格式和形状。此外，原始版本的 SAM 仅支持 2D 输入，而 2D 格式是 3D&#x2F;4D 格式的基础，甚至是基本组件。为了标准化不同数据集中的数据，对每个收集的公共数据集应用了以下预处理步骤。对于 3D 体积，整个过程可以总结如下：</p><p>1） 由于其分辨率更高，沿主观察平面提取切片。在 CT 中，它通常是横向的平面，而在 MRI 中，它可能是横向平面，例如前列腺、脑肿瘤，或矢状面，例如脊柱和心脏。</p><p>2） 保留标签像素值之和较大的切片,对于任何 3D 图像和标签体积，都大于 50。这可确保每个切片都有相应的正确标签。</p><p>3） 通过最小-最大归一化对提取的图像强度进行归一化：</p><p>$I_n &#x3D; 255 ∗ （I − I_{min}）&#x2F;（I_{max} − I_{min}）$，将范围限制为 （0， 255）。$I$ 表示原始提取的图像，$I_n$ 表示标准化的图像。$Imin$ 和 $Imax$ 是 $I$ 的最小和最大强度值。同时，我们根据对象的类别或位置重置蒙版的像素值（例如，左肾和右肾具有不同的像素值）。这是因为医学图像的体素或像素值可能差异很大。示例包括强度范围为 （0， 800） 的 MRI 和强度范围为 （-2000， 2000） 的 CT，而其他模式可能已经在 （0， 255） 范围内。</p><p>4） 以 PNG 格式保存图像和标签。对于 4D 数据 （N、W、H、D），我们将数据转换为 N 组 3D 体积，然后遵循 3D 体积处理流程。其中， N 表示 4D 数据中成对的体积数。对于 2D 图像，预处理如下：</p><ul><li>保留标签像素值之和大于 50 的图像。</li><li>根据对象类别或位置在 1 到 255 的范围内重置标签的像素值。对于 CellSeg 挑战-NeurIPS 2022，由于原始标签值的范围很广 （1-1600），我们将每个图像和标签重建为几个子图形，以确保标签范围一致。</li><li>将图像和标签的格式从 BMP、JPG、TIF 等转换为 PNG，以实现一致的数据加载。COSMOS 1050K 总共由 1,050,311 个 2D 图像或切片组成，其中 1,003,809 个切片来自 8,653 个 3D 体积，46,502 个是独立的 2D 图像。此外，该数据集包含 6,033,198 个掩码。</li></ul><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h4 id="1-SAM-简介"><a href="#1-SAM-简介" class="headerlink" title="1.SAM 简介"></a>1.SAM 简介</h4><p>SAM 与传统的分割框架不同，引入了一种新的可提示分割任务，该任务由灵活的支持提示的模型架构和大量多样的训练数据源提供支持。提出了一个数据引擎来构建一个循环过程，该过程利用该模型来促进数据收集，并随后利用新的收集的数据以增强模型的性能。最后，SAM 在一个庞大的数据集上进行了训练，该数据集包含来自 1100 万张许可 2D 图像的超过 10 亿个掩码。如图 5 所示，SAM 主要包含三个组件：图像编码器、提示编码器和掩码解码器。图像编码器以 ViT 为支柱，由掩蔽自动编码器 （MAE） 技术进行预训练。它采用一张图像作为输入，并输出图像嵌入，以便与后续的提示编码组合。提示编码器由密集 （掩码） 和稀疏 （点、框和文本） 分支组成。密集分支通过卷积神经网络 （CNN） 对掩码提示进行编码。对于稀疏的，点和框可以用位置编码来表示，而文本则用 CLIP 嵌入。最后，掩码解码器解码所有嵌入并预测掩码。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006181834883.png" alt="图5 SAM的pipeline"></p><p>在测试期间，SAM 支持自动 Everything 模式和手动 Prompt 模式。对于前者，用户只需将图像输入到 SAM，然后所有预测的掩码都会自动生成。对于后者，用户手动向 SAM 提供一些额外的提示，包括掩码、框、点和文本，以便 SAM 提供有关分割对象的更多信息。这两种模式的详细信息将在以下小节中介绍。值得注意的是，SAM 只能在图像中找到多个目标，而不会输出它们的详细类别 （即 single-label： object 与否）。在官方 GitHub 存储库中，作者提供了三种具有不同主干大小的预训练模型，分别是 ViTB、ViT-L 和 ViT-H。它们的模型参数范围从小到大。K等人中，ViT-H 显示出比 ViT-B 有显着的性能改进。但是，由于复杂性增加，前者需要成倍的测试时间。</p><p>在评估医学图像中的 SAM 时，一项研究使用了六个医学数据集，发现 ViT-B、ViT-L 和 ViT-H 中没有明显的赢家。在本文的研究中，我们选择了最小的 ViT-B（具有 12 个transformer层和 91M 参数）和最大的 ViT-H（具有 32 个transformer层和 636M 参数）作为编码器来运行所有测试模式。作者希望在大型 COSMOS 1050K 上对不同大小的模型进行综合评估，可以为研究人员提供更多的启发。</p><h4 id="2-AUTOMATIC-EVERYTHING-自动）模式"><a href="#2-AUTOMATIC-EVERYTHING-自动）模式" class="headerlink" title="2.AUTOMATIC EVERYTHING (自动）模式"></a>2.AUTOMATIC EVERYTHING (自动）模式</h4><p> 在一切模式 （$S_1$） 中，SAM 为整个图像中的所有潜在对象生成分割蒙版，无需任何手动先验。该过程的初始步骤涉及生成覆盖整个图像的点提示网格（即网格采样）。根据均匀采样的网格点，提示编码器将生成点嵌入并将其与图像嵌入相结合。然后，掩码解码器将组合作为输入，并为整个图像输出几个可能的掩码。随后，应用过滤机制，使用置信度分数、基于阈值抖动的稳定性评估和非极大值抑制 （NMS） 技术去除重复和低质量的掩码。</p><h4 id="3-手动提示模式"><a href="#3-手动提示模式" class="headerlink" title="3.手动提示模式"></a>3.手动提示模式</h4><p> 在提示模式下，SAM 提供了不同类型的提示，包括点、框和文本。点提示包括正点和负点，分别表示一个对象的前景和背景。框提示表示需要分段的对象的空间区域。此外，文本提示指示一个句子（即位置、颜色、大小等基本信息）来描述对象。值得注意的是，文本提示尚未在官方 GitHub 存储库上发布。如图 5 所示，本文的提示模式包含五个策略，包括 1 个正点 （$S_2$）、5 个正点 （$S_3$）、5 个正点和 5 个负点 （$S_4$）、1 个框 （$S_6$） 和 1 个框带 1 个正点 （$S_6$）。作者进一步建立了统一的点选择规则，以确保随机性、可重复性和准确性。对于正点选择，</p><p>a） 首先计算了真实 （GT） 掩码的质心（图 5 中的红点）。</p><p>b） 如果质心在 GT 掩码内，我们将质心作为第一个正点。</p><p>c） 然后，我们直接将 GT 掩码展平为一维向量，并通过采用 uniform 获得其他正点采样方法（图 5 中的绿点）。</p><p>d） 如果质心在 GT 掩码之外，则通过执行步骤 c 将获得所有需要的正点。</p><p>对于负点选择，目标是避免选择离目标区域太远的点。具体来说，首先将 GT 的边界框放大了两倍。负点是通过在非 GT 区域进行均匀采样生成的（图 5 中的黄点）。最后，对于框的选择，直接采用了 GT 掩码的边界框，无需任何额外的操作。上述策略可以保证实验的可重复性。此外，倾向于通过选择质心和紧密箱来测试 SAM 的理论最佳性能。因为它们可能包括目标最具代表性的特征。需要注意的是，SAM 允许将多个提示一次输入到网络中。因此，为了公平地进行比较，测试了上述五种提示策略 （$S_2-S_6$） 下 SAM 的单轮交互性能。</p><h4 id="4-推理效率"><a href="#4-推理效率" class="headerlink" title="4.推理效率"></a>4.推理效率</h4><p>使用不同的策略对图像进行了多次测试 （n） 以获得最终评估（见图 5）。在 SAM 的原始代码逻辑和设计中，需要对一张图像进行 n 次相同的编码操作，这导致多策略测试场景的运行效率不佳。当使用高分辨率输入时，情况会变得更糟。基于这一观察，提前计算了所有输入图像的嵌入特征，并将它们保存为中间文件。因此，可以重复使用图像嵌入以减轻推理管道的计算负担。因此，SAM 测试的整体效率可以提高近 n 倍。SAM 中的测试策略越多，可以节省的时间就越多。这可以简单地扩展到 SAM 的其他多策略测试场景。</p><h4 id="用于分割评估的掩码匹配机制"><a href="#用于分割评估的掩码匹配机制" class="headerlink" title="用于分割评估的掩码匹配机制"></a>用于分割评估的掩码匹配机制</h4><p> SAM 为每个输入图像生成了多个二进制掩码，但并非所有掩码都包含相应的对象。因此，提出了一种掩码匹配机制，在每种模式下使用 SAM 评估分割性能。具体来说，对于给定图像中的对象（前景之一），我们计算了一组骰子分数 ${DICE_n}^N_{n&#x3D;1} $在 N 个二进制预测掩码$ {P_n}^N_{n&#x3D;1}$ 和 GT $G$ 之间。然后，选择集合中骰子分数最高的那个作为匹配的预测掩码 P，用于后续的分割评估。这个获取 P 的过程可以表示如下：<br>$$<br>P &#x3D; max{(P1 · G), (P2 · G), . . . ,(PN · G)},<br>$$<br>其中 N 是一张图像中某个对象的预测二进制掩码的总数。运算 （·） 和 max{} 表示计算一个预测掩码和 GT 之间的骰子分数，而 max 表示获取具有最高骰子分数的预测掩码。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><p>为了全面评估 SAM 的细分性能，使用了三个常见指标，如下所示：</p><ol><li>DICE 系数 （DICE， %）：一种相似性度量，用于评估预测与 GT 之间的重叠。从 [0， 1] 开始，值越高表示模型的性能越好。</li><li>杰卡德相似系数 （JAC， %）：也称为 IOU，用于衡量两个掩码之间的相似性。它与 DICE 类似，但计算方法不同。具体而言，对于预测掩码和 GT 掩码 A 和 B，JAC 会计算交集 （|A ∩ B|）over union （|A ∪ B|）。JAC 的范围介于 0 到 1 之间，值越高表示性能越好。</li><li>豪斯多夫距离（HD，像素）：一种评估两组点之间相似程度的度量，可以反映预测中每个点与 GT 中点之间的距离。它比 DICE 对边界更敏感。</li></ol><h4 id="不同模型下的分割性能"><a href="#不同模型下的分割性能" class="headerlink" title="不同模型下的分割性能"></a>不同模型下的分割性能</h4><p>在本节中，倾向于比较两种模型（ViT-B 和 ViT-H）在不同策略下的分割性能。从图 6 中可以观察到，在全模式（$S_1$）下，ViT-H 在 DICE 上以 7.47% 的比 ViT-B 高出 10.61 像素，在高清模式下比 ViT-B 低 10.61 像素。对于单点提示 （$S_2$），ViT-H 的平均性能略高于 ViT-B。随着点提示数量的增加，ViT-H 的优势将变得更加明显。而对于静止策略（没有&#x2F;有 1 个点的盒子，$S_5-S_6$），它们的表现非常接近（DICE 的差异：0.37% 和 0.06%）。与点提示相比，框提示包含有关对象的更多区域信息。因此，它可以更好地引导不同模型的 SAM 实现更好的分割性能。特定对象的 DICE 和 HD 性能可在表 2 和表 3 中找到。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006184728915.png" alt="图6 ViT-B 和 ViT-H 在不同策略下的平均性能比较。"></p><h4 id="不同测试模式下的分割性能"><a href="#不同测试模式下的分割性能" class="headerlink" title="不同测试模式下的分割性能"></a>不同测试模式下的分割性能</h4><p>在本节中，倾向于比较使用不同模型（ViT-B 和 ViT-H）的不同策略之间的分割性能。如图 6 所示，我们显示了 ViT-B 和 ViT-H 在不同策略下的平均 DICE 和 HD 性能。对于 ViT-B 和 ViT-H，不同策略的性能趋势基本一致。所有内容 （$S_1$） 的性能最差。对于点提示（$S_2-S_4$），增加更多的点数会带来稳定的性能提升（ViTB： DICE 从 56.02% 降低到 63.81%，ViT-H： DICE 从 56.78% 提高到 71.61%）。带有框提示符的 SAM 效果最好，而在框内增加 1 个点不会带来明显的变化（ViT-B： DICE 0.49%↓， ViT-H： DICE 0.06%↓）。根据实验，得出结论，与点提示相比，框提示包含更多重要信息。因为这个框实际上告诉了目标的确切位置，以及给定有限区域的潜在强度特征。但是，点仅表示目标的零件特征，这可能会导致混淆。图 7、图 8、表 2 和表 3 显示了 6 种测试策略下部分目标的特定分割精度结果。图 9 显示了 5 种手动提示模式（$S_2-S_6$）的预测可视化。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006184919651.png" alt="图7 ViT-B 下不同检测策略下选择性常见医疗对象的 DICE 性能比较"></p><h4 id="SAM-的推理时间分析"><a href="#SAM-的推理时间分析" class="headerlink" title="SAM 的推理时间分析"></a>SAM 的推理时间分析</h4><p>推理时间是评估模型的一个重要因素。在表 4 中，用嵌入生成、提示编码和掩码解码。所有测试均在一台具有 24G 内存的 NVIDIA GTX 3090 GPU 上执行。测试时间可能受多种因素影响，包括图像大小（预处理时间的微小差异，即将不同大小的图像上采样到 1024×1024）和目标数量（按顺序处理每个目标的提示）。因此，通过将图像大小限制为 256×256 并将目标数量设置为 1 进行了公平的比较。可以观察到，ViT-H 的包埋时间几乎是 ViT-B 的四倍。Everything （$S_1$） 的提示编码和掩码解码非常耗时，因为它需要处理从整个图像中采样的数百个点，包括使用 NMS 的大量后处理等。而对于手动提示编码和掩码解码（$S_2-S_6$），不同模型和策略的参考时间相似，均小于 0.01s。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006192028760.png" alt="图9"></p><p>SAM 的典型好案例 。r1、r2：CT、r3、r7：T2W MRI，r4、r6：T1W MRI，r5：CMR，r8：US，r9：X 射线，r10、r11：结肠镜检查，r12：皮肤镜检查，r13：显微镜检查。绿色和蓝色星号分别表示正点提示和负点提示。绿色框表示框提示符。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006192114067.png" alt="图10"></p><p>18 种不同模态的 DICE 性能。绿色三角形和箱形图中每个框上方的值表示平均值。</p><h4 id="分析“一切”模式中的点数"><a href="#分析“一切”模式中的点数" class="headerlink" title="分析“一切”模式中的点数"></a>分析“一切”模式中的点数</h4><p>如上所述，在 Everything 模式下，将生成点提示网格 （m×m）。默认情况下，m 设置为 32。点数将对最终分段性能产生影响。特别是对于具有多个不同大小目标的图像，参数设计不当会导致分割不完美，部分对象出现无提示。如表 5 所示，在一张图像上测试了四个包含多个对象的数据集。结果表明，在这四个数据集中，随着点数从 82 增加到 2562，DICE 也逐渐增加。图 11 还显示，更多的点将带来更多的潜在对象（以不同的颜色显示）。此外，过多的点会使 SAM 将对象拆分为多个部分，从而破坏对象的完整性。增加点数也会导致测试时间显着增加。因此，这是分段性能和测试效率之间的权衡。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006192551961.png" alt="表5 Everything 模式下点数的消融研究"></p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006192712036.png" alt="图11 腺癌、线粒体 和 神经结构 的不同病例在 S_1H 中具有不同的点数。"></p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006192142244.png" alt="表2"></p><p>根据 DICE 评分 （%） 在不同模式的选择性常见医疗对象上的表现。ViT-B 和 ViT-H 代表 SAM 的小型和大型编码器。$S_1-S_6$ 代表不同的测试策略，分别包括一切、1 点、5 点、10 点、方框和 1 点方框。</p><h4 id="与分割结果相关的因素分析"><a href="#与分割结果相关的因素分析" class="headerlink" title="与分割结果相关的因素分析"></a>与分割结果相关的因素分析</h4><p>为了验证影响 SAM 分割性能的因素，记录了 191,779 个解剖结构的大小、纵横比、前景和背景之间的强度差异、模态和边界复杂性。通过分析这些因素，我们旨在更好地了解解剖结构特征与 SAM 的分离之间的相关性能，并进一步为医疗 SAM 的发展提供一些有用的见解。解剖结构的大小被计算为相应掩码的像素级面积。要确定蒙版的纵横比，需要计算其边界框的短边和长边之间的比率（范围从 0 到 1）。强度差异被定义为结构与扩大的边界框内周围区域之间平均强度值的变化，不包括结构本身。具体来说，为了适应目标的不同尺寸，以 0.1 的预设比例动态地向外扩展框，而不是使用固定的像素值（例如，扩展 10 个像素）。此外，每个解剖结构的模态都映射到数值。此外，引入了椭圆傅里叶描述符 （EFD） 来描述边界复杂性。EFD 将模板的轮廓编码为表示不同频率分量的傅里叶级数。随着傅里叶阶数 （FO） 的增加，从傅里叶级数解码的轮廓越来越接近原始轮廓（见图 12），解码过程可以描述为如下方程。<br>$$<br>x_N(t) &#x3D; L_x +\sum_{n&#x3D;1}^N( a_n sin (\frac{T}{2nπt}+ b_n cos (\frac{T}{2nπt}))  \<br>y_N(t) &#x3D;L_y +\sum_{n&#x3D;1}^N( c_n sin (\frac{T}{2nπt}+ d_n cos (\frac{T}{2nπt}))<br>$$<br>其中 （xN（t）， yN（t）） 是等值线上任意点的坐标，N 是傅里叶级数展开的数量，t ∈ [0， T] 表示不同的采样位置。（Lx， Ly） 表示等值线中心点的坐标，（an， bn） 表示 x 坐标的傅里叶编码得到的参数，（cn， dn） 表示 y 轴的编码结果方向。可以根据 FO 粗略估计对象边界的复杂度。具体来说，阶数定义为当解码后的傅里叶级数的轮廓与原始轮廓达到一定程度的重叠（使用 DICE 表示重叠）时所需的累积次数。但是，当使用此方法作为定量度量时，设置适当的 DICE 阈值尤为重要。低阈值无法准确区分各种对象边界之间的复杂度差异。如果阈值太高，EFD 可能无法根据需要拟合复杂的轮廓，并进入无限计算。因此，我们优化了 FO 的表示，以避免 EFD 程序陷入无休止的累积（参见方程 2 中的累积项）。对于不同的结构，将 FO 从 1 增加到 1，并计算每一步解码轮廓和原始轮廓之间的 DICE。然后我们设置两种结束过程的方法：1） DICE &gt; 97.0%;2） DICE 之间的差异或 F（a−1） 和阶数 F（a） 小于 0.1%。因此，在终止后记录 FO （F（a）） 和 DICE。最后，取 $F_{final} &#x3D; F_a + n × 100 × （1 − DICE）$， n &#x3D; 2 作为最终优化的 FO。</p><p>在不同测试策略下，使用 Spearman 秩偏相关系数对上述目标对象的五个属性与 DICE 评分之间的偏相关进行了分析。统计结果显示在表 6 中，而图 13 说明了$ S_5$ 策略的散点图。在大多数测试策略中，我们观察到 DICE 分数与 FO 和强度差异表现出中等相关性 （0.4 ≤ ρ &lt; 0.7），与大小呈弱相关性 （0.2 ≤ ρ &lt; 0.4），与模态和纵横比没有相关性。因此，SAM 可以始终如一地分割具有不同模态和纵横比的医疗目标。SAM 在框提示下的性能可能会受到解剖结构大小的影响。</p><p>此外，在处理以复杂边界或低对比度为特征的对象时，SAM 的性能在所有测试策略下都趋于不佳。为了证实这些发现，们将 S_5B 下计算的 DICE 平均分为十个水平（例如，1 级表示 DICE （%） 属于 （0,10），并在图 14 中可视化了不同 DICE 水平的 FO 箱线图。该图表明，随着 DICE 水平的增加，结构的 FO 分布逐渐转移到值较小的范围。此外，在图 15 中，展示了具有各种 FO 范围的解剖结构的可视化。这些可视化显示，解剖结构的 DICE 评分随着 FO 的增加而趋于降低。进一步意味着形状和边界复杂性可能会对 SAM 的分段性能产生影响.</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006193506239.png" alt="图13 在 S_5 策略下使用 DICE 的不同对象属性的散点图。"></p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006193534261.png" alt="图14 不同 DICE 范围的 FO 箱线图。"></p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006193552209.png" alt="图15 DICE 和 FO 之间的关系。从左到右，FO 逐渐增加。黄色框表示框提示，红色掩码是预测，绿色掩码是 GT，黄色掩码是预测和 GT 的重叠，蓝色等值线是从傅里叶级数解码而来的。"></p><h4 id="注释时间和质量分析"><a href="#注释时间和质量分析" class="headerlink" title="注释时间和质量分析"></a>注释时间和质量分析</h4><p>在本节中，将讨论 SAM 是否可以帮助医生改善注释时间和质量。从 COSMOS 1050K 中随机采样了 100 张具有平均 DICE 性能的图像，以构建一个评估子集，其中包含 9 种模态的 55 个对象和 620 个蒙版，包括不同模态中同一对象的实例。然后，邀请了三位具有 10 年经验的医生来评估 SAM 在框提示下的预测是否可以提高注释速度和质量。他们被分配的任务包括 </p><p>1） 从头开始注释评估子集中的所有对象，</p><p>2） 根据 SAM 的预测调整对象标签，</p><p>3） 记录两项任务的时间。</p><p>为了评估注释质量，我们利用人工校正工作 （HCE） 指数 ，该指数估计了纠正不准确预测以满足实际应用中特定准确性（即 GT 掩码）要求所需的人工努力。较低的 HCE 指数表示掩码 （有&#x2F;无 SAM 的人类注释） 更接近 GT，即注释质量更高。如表 7 所示，在 SAM 的帮助下，它可以获得更高的注释质量 （HCE： 0.27↓） 并将注释速度提高约 25%。具体来说，注释一张图像可以节省 ∼1.31 分钟，为一个对象节省 ∼0.2 分钟（因为在上述任务中，一张图像包含 ∼6.2 个对象）。需要标记的解剖结构数量越多，SAM 效率的优势就越明显</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006193707566.png" alt="表7 无论是否有 SAM 帮助，人工的注释速度和质量。S：秒，m：分钟"></p><h4 id="不同提示随机性对性能的影响"><a href="#不同提示随机性对性能的影响" class="headerlink" title="不同提示随机性对性能的影响"></a>不同提示随机性对性能的影响</h4><p>在之前的实验中，修复了实验可重复性的框和点选择策略。通过选择质心和紧箱来测试 SAM 的理论最佳性能，因为它们可能包括目标最具代表性的特征。然而单击每个对象的精确中心或绘制确切的框来评估 SAM 是不切实际的。因此，为中心和盒子添加了不同级别的随机性，以模拟现实生活中的人类操作。</p><p>此外，相信这可以帮助我们更好地讨论 SAM 的稳健性。具体来说，以 0-10、10-20 和 20-30 像素随机放大&#x2F;移动框&#x2F;点。在表 8 中，随机实验（随机 1-3） 进行 3 次，并计算平均结果 （Mean）。DICE drop 表示与原始结果相比，DICE 值平均下降，没有偏移。对于 S_2（单点），随着移位级别的增加，DICE 性能下降了 2.67%、7.38% 和 14.62%。随着点提示数量（S 3 和 S 4）的增加，可以缓解 DICE 的下降，并提高模型的稳定性。SAM 受到方框偏移的严重影响（S 5，偏移 20-30 像素时性能下降 24.11%），而当向方框添加一个点时，这种影响更为明显（S 6，下降了 29.93%）。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006193847488.png" alt="表8 不同换档水平和测试策略下 DICE 下降的比较"></p><h4 id="SAM-和交互式方法之间的比较"><a href="#SAM-和交互式方法之间的比较" class="headerlink" title="SAM 和交互式方法之间的比较"></a>SAM 和交互式方法之间的比较</h4><p>在前面的部分中，将所有提示输入到 SAM 的提示编码器中一次，以便公平地比较其一轮性能。为了模拟现实生活中的交互式分割程序，执行了多轮 SAM。点选择策略与常见的交互方法类似。具体来说，SAM 首先点击目标的中心，然后其余点击基于假阴性 （FN） 和假阳性 （FP） 区域。然后，将 SAM 与两个不同的强交互分割方法，即 FocalClick 和 SimpleClick。它们都使用与 SAM 相同数量的图像进行预训练。选择了 10 个典型的器官&#x2F;肿瘤，涵盖各种形态、形状、大小和强度分布。实验结果如图 16 所示。根据 DICE 结果，我们得出的结论是：</p><p>1） SAM 在与单个点的第一次交互中优于 FocalClick 和 SimpleClick;</p><p>2） 随着迭代的进行，SAM 的性能增长缓慢，甚至下降，而交互方法的性能可以稳步提高;</p><p>3） 使用 10 个点，SAM 的表现比交互式方法差。类似的结果可以在最近发表的 MedIA 论文中找到。</p><p>认为当前 SAM 基于点的多轮迭代能力在医学图像上较弱。未来的工作应该在训练 SAM 时优化迭代训练策略，或对其进行微调以增强其迭代多轮的能力。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006194100272.png" alt="图16 三种不同方法的平均性能随点提示的数量而变化。"></p><h4 id="针对-SAM-的任务特定细化"><a href="#针对-SAM-的任务特定细化" class="headerlink" title="针对 SAM 的任务特定细化"></a>针对 SAM 的任务特定细化</h4><p>SAM 对大多数医学图像&#x2F;任务的能力感知较弱主要是由于缺乏训练数据。SAM 的训练数据集，即 SA-1B5，包含 1100 万张照片，包括自然位置、物体和场景，但没有任何医学图像。自然图像通常与医学图像不同，因为它们具有颜色编码、相对清晰的对象定义和边界、更容易区分前景（对象）和背景（非对象）以及相对平衡的大小。然而，大多数医学图像都是灰度的，物体边界不清晰复杂，前后相似，图像尺寸范围广（尤其是包含一些非常小的物体）。因此，使用 COSMOS 1050K 的一部分对 SAM 进行了微调，以改善 SAM 对医疗对象的感知。具体来说，考虑了 45 个常见和典型对象来微调 SAM。受马和 Wang 的启发，只考虑使用框提示对 SAM 进行微调。修复了图像编码器以最大限度地降低计算成本，并且还保持了提示编码器的冻结状态，因为它具有强大的编码框位置信息的能力。因此，在微调过程中，仅调整了掩码解码器中的参数。将总 epoch 设置为 20，学习率和批量大小为 1e-4 和 2。</p><p>结果表明，在 ViT-B 和 ViT-H 模型进行微调后，分割性能普遍提高，如图 17 和图 18 所示。图 17 显示了不同相关因子向更高 DICE 值的转变，表明整体性能有所提高。具体来说，对于 ViT-B，45 个对象中有 32 个表现出性能增强，而 ViT-H 在 45 个对象中有 37 个表现出改进。这可以证明 ViT-H 强大的学习能力，因为它的参数几乎是 ViT-B 的 7 倍（636M 对 91M）。具有较小数字、RGB 颜色编码等的对象的性能会降低。这提醒可能需要为特定于任务的微调进行更仔细的设计。</p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006194356144.png" alt="图17 不同属性下 DICE 的趋势分析 （ViT-B 和 ViT-H 带框提示符，S 5）。蓝色圆圈显示最明显的更改。"></p><p><img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20241006194425816.png" alt="图18 微调后的 DICE 改进，包括 ViT-B 和 ViT-H 的 SAM。"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在这项研究中，全面评估了用于大型医学图像数据集分割的 SAM。基于上述实证分析，我们的结论如下：</p><p>1） SAM 在某些特定目标上表现出显著的性能，但在其他情况下不稳定、不完美甚至完全失效。</p><p>2） 使用大 ViT-H 的 SAM 显示出比使用小 ViT-B 更好的整体性能。</p><p>3） SAM 使用手动提示（尤其是 box）时的性能优于 Everything 模式。</p><p>4） SAM 可以帮助人工注释，提高标记质量和减少时间。</p><p>5） SAM 对中心点的随机性和紧凑的框提示很敏感，可能会出现严重的性能下降。</p><p>6） SAM 的表现优于具有 1 个或几个点的交互式方法，但随着点数的增加，SAM 的性能会超过。</p><p>7） SAM 的性能与不同的因素相关，包括边界复杂性等。</p><p>8） 在特定医疗任务上微调 SAM 可以将其 ViT-B 和 ViT-H 的平均 DICE 性能分别提高 4.39% 和 6.68%。</p><p>最后认为，虽然SAM有潜力成为一个通用的MIS模型，但目前它在MIS任务中的表现并不稳定。希望这份报告能帮助读者和社区更好地了解 SAM 在医学影像中的分割性能，并最终促进新一代 MIS 基础模型的开发。</p><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>将重点讨论 SAM 未来的潜在方向，希望这些能在一定程度上启发读者。当没有 GT 时，如何从 SAM 获得语义？当前的 SAM 仅具有感知对象的能力，而无法分析特定类别的对象。最近，有几项研究探索了解决这个问题，其中一项为 SAM 配备了 CLIP 型号。具体来说，SAM 将首先提供区域建议，区域补丁将从原始图像中裁剪出来。然后，裁剪后的补丁将被输入到 CLIP 以进行对象分类。另一种解决方案是将 SAM 与 Open-Vocabulary Object Detection 结合使用（OVOD） 模型，例如，带 SAM 的接地 DINO （GroundedSAM7）。在这个pipeline中，OVOD 模型可以检测边界具有分类结果的对象框。然后，SAM 会将 box 区域作为 input 并输出 Segmentation 结果。最近，语义 SAM 被提出用于分割和识别自然图像中的任何事物。之前的所有探索都是基于自然图像的。因此开发具有语义感知的医疗 SAM 可能会很有趣。然而，这具有挑战性，因为开放场景中的医疗对象具有多种多样和复杂的形状、多种类型以及许多相似的亚类（不同级别的肿瘤等）。</p><h4 id="SAM-与传统的分割方法？"><a href="#SAM-与传统的分割方法？" class="headerlink" title="SAM 与传统的分割方法？"></a>SAM 与传统的分割方法？</h4><p>使用有限的医疗数据微调 SAM 可以胜过特定于任务的传统分割方法。这在最近发表的几项研究中得到了验证。Med-SAM 已经证明，在大多数情况下，微调 2D SAM 可以实现优于专业 Unet 模型的性能。3D 模态不可知的 SAM （MA-SAM） 已经验证，即使没有任何提示，使用 3D 适配器微调 SAM 也可以胜过传统的 SOTA 3D nn-Unet。它还对医学图像分割社区有所了解，表明微调基本分割模型可能比从头开始训练传统分割模型表现得更好。然而，SAM 仍然存在一些问题，包括模型对不同提示噪声的鲁棒性和多轮交互能力。</p><h4 id="2D-还是-3D-SAM？"><a href="#2D-还是-3D-SAM？" class="headerlink" title="2D 还是 3D SAM？"></a>2D 还是 3D SAM？</h4><p>对于医疗数据，成像模式（2D&#x2F;视频&#x2F;3D&#x2F;4D）的可变性可能会使一般模型的设计变得复杂。与视频&#x2F;3D&#x2F;4D 图像（CT&#x2F;MRI 等）相比，2D 在医疗数据中更为基础和常见。因此，构建一个可以一致处理所有类型数据的 2D 模型更实用，因为视频&#x2F;3D&#x2F;4D 数据可以传输到一系列 2D 切片。有限的 3D 数据量（SAM：11M 图像和 1B 掩码，而我们的：&lt;10K 卷和 &lt;45K 掩码）可能会限制 3D 基本分割模型的构建，尤其是在需要从头开始训练的情况下。为了打破数据的局限性，将探索如何合成更多高保真 3D 数据，并为医学图像分割构建强大的基础模型。</p><h4 id="SAM-推动大规模医学注释？"><a href="#SAM-推动大规模医学注释？" class="headerlink" title="SAM 推动大规模医学注释？"></a>SAM 推动大规模医学注释？</h4><p>开发强大而有效的基于深度学习的医疗分割模型非常需要大规模和完全标记的数据集。对于当前基于专家手动注释的方案来说，这是非常具有挑战性的。正如Q中介绍的那样，一位经验丰富的专家大约需要 30.8 年才能注释 8,448 个 CT 体积、9 个解剖结构和 320 万个切片。他们借助多个预先训练的分割模型来生成伪标签和其他有用的策略，将注释时间缩短到三周。然而，获得性能良好的预训练模型，尤其是假阳性率低的模型，仍然非常困难。此外，基于传统深度学习的分割网络无法很好地支持人机交互，限制了其灵活性。具有可及时分割的 SAM 的出现为解决挑战带来了希望。研究还初步验证了 SAM 可以大大缩短注释时间并提高注释质量。需要标记的解剖结构数量越多，SAM 的效率优势就越明显。值得注意的是，SAM 范例的设计有可能实现通用分割。这意味着可以使用单个 SAM 网络来实现大规模多模态、多类医学数据集的标注，而不是使用多个特定于任务的模型，这个对于在标记软件中轻量级和高效部署模型非常重要，例如 MONAI Label和配对注释软件包L。</p><p>[仓库地址]:<a href="https://github.com/yuhoo0302/Segment-Anything-Model-for-Medical-Images/blob/main/Supplementary_Materials.pdf">https://github.com/yuhoo0302/Segment-Anything-Model-for-Medical-Images/blob/main/Supplementary_Materials.pdf</a>“GITHUB仓库”</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-3DSAM-adapter: Holistic adaptation of SAM from 2D to 3D for promptable tumor segmentation</title>
    <link href="/2024/09/29/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/"/>
    <url>/2024/09/29/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/</url>
    
    <content type="html"><![CDATA[<h2 id="3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation"><a href="#3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation" class="headerlink" title="3DSAM-adapter: Holistic adaptation of SAM from 2D to 3D for promptable tumor segmentation"></a>3DSAM-adapter: Holistic adaptation of SAM from 2D to 3D for promptable tumor segmentation</h2><p><img src="/../images/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/image-20240911160429772.png" alt="TITLE"></p><blockquote><p>3DSAM 适配器：SAM 从 2D 到 3D 的整体适应，用于及时的肿瘤分割 2024年8月</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>SAM框架对于日常的图像已经有良好的分割性能，但是在医学图像分割上表现出的性能不太精确且不稳定，尤其是在处理涉及小尺寸、不规则形状和低对比度物体的肿瘤分割任务时。最初的SAM是为了自然界2D图像而设计的，无法有效的获取医学图像中3D空间信息，所以在本文中作者提出了一种新的适应方法，用于将 SAM 从 2D 转移到 3D 以进行可提示的医学图像分割。</p><p>本文提出了一种新的参数高效自适应方法，以全面将 SAM 从 2D 适应 3D 以进行医学图像分割。修改了图像编码器以支持体积输入，同时重用预先训练的权重。在提示编码器级别，引入了用于点提示的视觉采样器，并使用全局查询来过滤掉噪声，解决了过度平滑问题，并提高了模型的稳健性。对于掩码解码器，优先考虑具有多层聚合的轻量级设计。结果表明，本文的方法可以大大优于现有方法。该方法还显示了提示符的数量和位置的稳健性。例如，肿瘤边缘的单个点也可以作为准确分割的提示。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/image-20240913205057950.png" alt="3DSAM"></p><p>1.SAM框架：<a herf="#">LINK</a></p><p>2.体积输入编码器：使用2DViT编码器适应3D图像信息，通过补丁嵌入、位置编码、注意块、瓶颈机制将2DViT修改到支持3DViT，同时保持大部分参数可重用。</p><p>![(C:&#x2F;Users&#x2F;Wuyueyu&#x2F;Desktop&#x2F;1&#x2F;SAM&#x2F;image&#x2F;3DSAM-adapter%2520Holistic%2520adaptation%2520of%2520SAM%2520from%25202D%2520to%25203D%2520for%2520promptable&#x2F;image-20240913205743398.png)空间适配器 (b)视觉采样器](image&#x2F;3DSAM-adapter Holistic adaptation of SAM from 2D to 3D for promptable&#x2F;image-20240913205743398.png)</p><p>a）在下投影层之后附加了一个深度 3D 卷积，以便适配器可以更好地利用 3D 空间信息。将空间适配器放置在两个相邻的注意力块之间。在每个注意力块之后，得到了大小为 [B， DHW， c] 的潜在特征图。然后，此特征图被重塑为 [B， c， D， H， W] 并通过空间适配器，从而产生相同大小的自适应特征图。然后，调整后的特征图被重塑回大小 [B， DHW， c] 并插入到随后的注意力块中。通过冻结方案让训练时有良好的内存效率，和对之前信息的记忆力。</p><p>3.提示编码器</p><p>b)视觉采样器<br>$$<br>P_s&#x3D;VisualSampler(s,Z)<br>$$<br>其中 s 是从提示点的坐标，Z 是从图像中提取的特征图，Ps 是提示的嵌入。给定特征图 Z，每个网格对应于一个长度为 c 的潜在向量。通过三线性插值，也可以从特征图中采样非整数位置的视觉特征。这种设计可以更好地利用空间信息，根据点提示的坐标直接从图像特征图中采样，从而在保证图像嵌入和提示嵌入之间的对齐的同时，避免了每个标记的权重计算。通过双向注意力机制将提示嵌入与图像嵌入融合（a）-&gt;</p><p><img src="/../images/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/image-20240913213048917.png" alt="（a） 通过交叉注意力进行提示嵌入和图像嵌入融合的图示。（b） 具有多层聚合的轻量级掩码解码器的结构图"></p><p>由于点和提示词的全局查询的数量都非常小，缓解了过度平滑的问题，提高对干扰点的容忍度。从背景中随机采样10个点提高模型对嘈杂提示的鲁棒性，在One-Prompt表现也很好。</p><p>4.解码器-轻量级</p><p>将2D卷积替换为3D卷积，生成3D掩码，医学图像需要更加精细的像素划分，作者在保持轻量级的同时使用了多层聚合机制（b)，</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>实验集中在肿瘤分割上。</p><p><img src="/../images/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/image-20240913214011374.png" alt="肿瘤分割"></p><p>与公认的和最新的最先进的域分割方法比较。</p><p><img src="/../images/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/image-20240913214109207.png" alt="3D 透视图可视化预测的分割掩码"></p><p>从 3D 透视图可视化预测的分割掩码。与基线相比，我们的方法可以生成具有更多切片间平滑度和连贯性的蒙版</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文提出了一种新的参数高效适应方法，将 SAM 从 2D 整体适应 3D 以进行可及时的肿瘤分割。对图像编码器的修改是专门为支持体积输入而设计的，同时重用预先训练的权重。该文提出视觉采样器与全局查询一起，在提示编码器层面取代原来的交叉注意力机制，可以过滤掉提示中的噪声，缓解随着维度上升而过度平滑的问题。掩码解码器中使用了多层聚合，以更好地利用编码器的中间功能。在几个公共肿瘤分割数据集上的实验表明，本文的方法优于最先进的医学图像分割模型和现有的参数高效微调方法。</p><p>目前存在的问题：一个观察结果是，尽管许多基于 transformer 的方法在多类分割方面可以优于 nnU-Net，但对于纯肿瘤分割，总体趋势是基于 CNN 的方法具有更好的性能并且更容易训练。这可能是因为肿瘤的大小非常小，肿瘤检测更多地依赖于局部纹理信息。因此，全局信息，即transformer 的强度不再有用。因为 SAM 基于 ViT，在第一次降采样操作期间可能会丢失大量详细的纹理信息。未来的方向可能需要如何调整架构以恢复这些纹理细节，以便性能能够以全自动的方式实现 SOTA。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>医学图像处理</title>
    <link href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    <url>/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="医学图像处理"><a href="#医学图像处理" class="headerlink" title="医学图像处理"></a>医学图像处理</h1><h2 id="1-常见的医学图像"><a href="#1-常见的医学图像" class="headerlink" title="1.常见的医学图像"></a>1.常见的医学图像</h2><ul><li>MRI</li></ul><p>核磁共振图像（MRI），该图像是人体组织器官和病灶中的氢原子核在外部强磁场作用下产生的磁共振信号大小的度量，并通过计算机对体外核磁共振信号探测器接收到的信息数据进行3D图像重建。它能够提供非常清晰的人体软组织解剖结构和病灶影像。</p><ul><li>CT</li></ul><p>计算机断层扫描(CT)利用精确准直的X射线束对人体某部位一定厚度的断面进行照射扫描，并由与射线线束一起旋转的探测器接收透射穿过该断面的X射线，最后，计算机根据探测器接收到的X射线信号数据重建相应人体断面的3D图像。它具有亚毫米级的空间分辨率，能够提供清晰的人体骨性组织解剖结构和病灶影像，已广泛应用于多种临床疾病检查和辅助诊断。</p><ul><li>X射线图像</li></ul><p>医学X射线图像是人体不同组织器官和病灶的电子密度度量影像。基于X射线的成像包括2D的计算机放射成像、数字化 X 射线摄影术、数字减影血管造影术和乳房X线摄影术，以及3D的螺旋计算机断层扫描术等，已广泛地应用于骨科、肺部、乳腺和心血管等临床疾病检测和辅助诊断，但2DX射线图像不能提供人体组织器官和病灶的三维立体信息。</p><ul><li>超声图像</li></ul><p>利用超声束扫描人体，通过对反射信号的接收、处理，以获得体内器官的图像。近年来，超声成像技术不断发展，出现了 3D 彩超、超声全息摄影、体腔内超声成像、彩色多普勒成像及超声生物显微镜等新的超声成像技术。</p><ul><li>PET图像</li></ul><p>正电子发射断层扫描(PET)利用F18等放射性元素标记的示踪剂衰变时发射的正电子信息成像，因此，PET图像是相应示踪剂放射性活度的度量， 能提供肿瘤生物学特性(如葡萄糖代谢、乏氧、增殖等)信息，其标准摄入值大小可用于临床辅助判别肿瘤良&#x2F;恶性。PET能提供比CT、MRI更直观、更精确的可视化生物学与放射生物学特性信息。</p><ul><li>病理学图像</li></ul><p>是指切取一定大小的病变组织，采用苏木精和伊红等染色方法将切片组织做成病理玻片，然后用显微镜成像技术对微观的细胞和腺体成像。通过对病理图像进行分析，可探讨病变产生的原因、发病机理、病变的发生发展过程，从而做出病理诊断。</p><h2 id="2-影像医学发展现状"><a href="#2-影像医学发展现状" class="headerlink" title="2.影像医学发展现状"></a>2.影像医学发展现状</h2><p>影像学诊断人才资源紧缺。医疗机构普遍缺乏高水平的影像医师，在疾病诊断时往往会发生同病异影，异病同影等情况。</p><p>传统定性分析存在诊断误差。医生普遍擅长定性分析，很多微小的定量变化无法通过肉眼判断，很难做到定量分析。</p><p>医生阅片时间长。目前的影像呈现方式为数据和图像，而不是最有效的信息，很大程度上限制了医生的人工阅片速度。</p><h2 id="3-医学图像处理方向"><a href="#3-医学图像处理方向" class="headerlink" title="3.医学图像处理方向"></a>3.医学图像处理方向</h2><p>（1）医学图像增强</p><ul><li>对数变换</li><li>幂次变换</li><li>指数变换</li><li>直方图均衡化</li><li>拉普拉斯图像锐化</li></ul><p>（2）医学图像分类</p><ul><li>判断是否有病灶，并对病灶的轻重程度进行量化分级<ul><li>图像筛查：指将一个或多个检查图像作为输入, 通过训练好的模型对其预测, 输出一个表示是否患某种疾病或严重程度分级的诊断变量<ul><li>神经影像诊断<ul><li>老年痴呆症</li><li>轻度认识障碍</li></ul></li><li>乳腺影像诊断<ul><li>乳腺癌</li></ul></li><li>骨科影像诊断<ul><li>骨骼骨龄评估</li></ul></li><li>眼科影像诊断<ul><li>白内障</li></ul></li></ul></li><li>病灶分类：辅助医生对疾病进行诊断<ul><li>乳腺病灶良恶性分类</li><li>皮肤病灶分类</li><li>肺结节良恶性分类</li></ul></li></ul></li></ul><p>（3）医学图像检测</p><ul><li>定位病灶位置并对像素分类，准确地在医学图像中定位特定生物标记或解剖结构在临床治疗中具有非常重要的意义，直接关系到治疗效果的好坏。<ul><li>股骨定位</li><li>心脏定位</li><li>主动脉定位</li></ul></li></ul><p>（4）医学图像分割</p><ul><li>医学图像分割处理的对象主要是各种细胞、组织、器官的图像，医学图像分割的过程是：根据区域间的相似或不同，把图像分割成若干区域。<ul><li>组织病理学图像和显微镜图像分割</li><li>脑组织结构分割</li><li>心脏心室分割</li></ul></li></ul><p>（5）医学图像配准</p><ul><li><p>why？ 在临床诊断中，单一模态的单张图像往往不能提供医生所需要的足够信息，因此，医生经常需要将多种模式或同一模式的多次成像配准融合，从而实现感兴趣区域的信息互补。根据患者多方面的综合信息，医生才能做出更加准确的诊断或制定出更加合适患者的治疗方法。</p></li><li><p>医学图像配准是指对于一幅医学图像寻求一种 (或一系列 )空间变换 ,使它与另一幅医学图像上的对应点达到空间上的一致。 这种一致是指人体上的同一解剖点在两张匹配图像上有相同的空间位置。 配准的结果应使两幅图像上所有的解剖点 ,或至少是所有具有诊断意义的点及手术感兴趣的点都达到匹配。</p><p><img src="/../images/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/image-20240829204759915.png"></p></li></ul><p>（6）医学图像融合</p><ul><li>通过对多幅图像间的冗余数据的处理来提高图像的可读性，对多幅图像间的互补信息的处理来提高图像的清晰度。多模态医学图像的融合把有价值的生理功能信息与精确的解剖结构结合在一起，可以为临床提供更加全面和准确的资料。在图像融合处理中，图像配准是图像融合的第一步，也是实现图像融合的先决条件。<ul><li>被融合图像的成像方式<ul><li>单模融合</li><li>多摸融合</li></ul></li><li>融合对象的不同<ul><li>单样本时间融合</li><li>单样本空间融合</li><li>模板融合</li></ul></li><li>图像处理方法<ul><li>数值融合法</li><li>智能融合法</li></ul></li></ul></li></ul><p>（7）医学图像检索</p><h2 id="4-dataset"><a href="#4-dataset" class="headerlink" title="4.dataset"></a>4.dataset</h2><ul><li>医学影像数据集集锦 - 飞桨AI Studio<ul><li>包含肝脏、肺、乳腺癌、脑、肾脏、肠、心脏、眼睛、细胞、骨骼、前列腺、胰腺、皮肤和VQA等大量数据集</li></ul></li><li>medical-data<ul><li>哈佛大学机器学习和医学影像研究者贡献的数据集，包括了医学影像数据、竞赛数据、电子健康记录、医疗数据、UCI数据集、生物医学文献等</li></ul></li></ul><h2 id="5-SoTA"><a href="#5-SoTA" class="headerlink" title="5.SoTA"></a>5.SoTA</h2><ul><li>Papers with Code - Medical<ul><li>网站收纳了医学领域最新的paper和code，医学标签下有非常详细的子标签</li></ul></li></ul><h2 id="6-AI-医学影像助力疾病诊断"><a href="#6-AI-医学影像助力疾病诊断" class="headerlink" title="6.AI + 医学影像助力疾病诊断"></a>6.AI + 医学影像助力疾病诊断</h2><ul><li>影像设备的图像重建<ul><li>AI 可以通过算法的图像映射技术，将采集的少量信号恢复出与全采样图像同样质量的图像，而且使用图像重建技术，可以由低剂量的CT和PET图像重建得到高剂量质量图像。这样在满足临床诊断需求的同时，还能够降低辐射的风险。</li></ul></li><li>智能辅助诊断疾病<ul><li>智能辅助诊断肺部疾病<ul><li>国内应用 AI + CT 影像最为成熟的领域在肺结节的识别上。AI 能够有效识别易漏诊结节比如6mm以下实性结节和磨玻璃结节，且准确率在90%左右，同时能提供结节位置、大小、密度和性质等。除此之外，能对肺结核、气胸、肺癌等肺部疾病进行筛查。</li></ul></li><li>智能辅助诊断眼底疾病<ul><li>目前应用最为广泛的是筛查糖网病。糖网病是常见的视网膜血管病变，也是糖尿病患者的制药致盲眼病，早期往往没有任何临床症状，一旦有症状已错过最佳治疗时机。 我国糖网病患者约2700万，随着人们对糖网病筛查的重视，眼底读片需求增加，但从事眼底医疗服务和研究人员仅800～1000人，医疗资源严重匮乏，误诊、漏诊情况较多。将人工智能应用到眼底读片中，进行初步筛查，可大大改善目前糖网病筛查效率。 AI 通过对眼底图像的深度学习，可实现对部分眼底疾病，除了糖网病，还有青光眼、老年性黄斑变性、白内障和黄斑裂孔的诊断。</li></ul></li><li>智能辅助诊断脑部疾病<ul><li>目前脑部疾病的智能诊断包括脑出血、内动脉粥样硬化诊断、颅内动脉瘤诊断和颈动脉易损斑块评估等。 其中，脑出血是神经内外科中高致死致残率的一种难治性疾病。AI + 头部CT，基于机器视觉与深度学习技术，可以迅速定位脑出血区域，精确量化出血体积，判断是否存在脑疝，同时，能以秒级速度完成专业要求高、耗费时间长的影像评估，协助医生准确判断，让患者第一时间获得最优治疗方案。</li></ul></li><li>智能辅助诊断神经系统疾病<ul><li>AI 在神经系统疾病里的应用主要包括癫痫、阿尔兹海默症、帕金森病。AI 可以将患者的影像数据进行处理分析，并与正常人群组做统计比对，从而计算得到代谢异常的病灶大小、位置等信息，通过认知技术，给出治疗方案的建议以及治疗效果的预测。</li></ul></li><li>智能辅助诊断心血管疾病<ul><li>AI 可以在胸部 CT 数据基础上，利用深度学习技术和图像处理技术，设计特定算法后评估冠状动脉易损斑块，进行冠心病智能辅助诊断，规划支架手术置入方案等。同时还可以智能诊断主动脉疾病类型、主动脉瘤等复杂疾病。</li></ul></li></ul></li><li>智能勾画靶区<ul><li>目前，放疗是肿瘤病人的主要治疗方式之一，而病变器官的正确定位及精准勾画是放疗的基础和关键技术。因此，在放疗之前首先需要对CT图像上的器官、肿瘤位置进行标注，按照传统方法，一般需要耗费医生3～5个小时。 通过应用AI技术可大幅提升效率，AI智能勾画靶区的高准确率能够很大程度避免由于靶区勾画的不准确导致的无效治疗。目前，AI+靶区勾画已经成功运用在肺癌、乳腺癌、鼻咽癌、肝癌、前列腺癌、食管癌和皮肤癌上。</li></ul></li><li>智能判断病理切片<ul><li>病理切片的判断是一项复杂的工作，往往需要医生具有非常丰富的专业知识和经验，而且即使具有专业经验的医生，也容易忽略不易察觉的细节从而导致诊断的偏差。而将人工智能引入病理病理切片的研究，通过学习病理切片细胞层面的特征，不断完善病理诊断的知识体系是解决读片效率以及诊断准确值的最好的办法。</li></ul></li><li>其他智能辅助诊断方案<ul><li>人工智能在医学影像中的应用还包括脏器的三维成像、超声辅助甲状腺结节、骨龄分析、骨折智能诊断等。</li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>C-Vision Transformer (ViT)</title>
    <link href="/2024/09/28/C-Vision-Transformer-ViT/"/>
    <url>/2024/09/28/C-Vision-Transformer-ViT/</url>
    
    <content type="html"><![CDATA[<h2 id="AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE"><a href="#AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE" class="headerlink" title="AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"></a>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</h2><p><img src="/../images/C-Vision-Transformer-ViT/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240928154923206.png" alt="TITLE"></p><blockquote><p><strong>[v2]</strong> Thu, 3 Jun 2021 13:08:56 UTC Vision Transformer (ViT)</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>虽然Transformer架构已经成为自然语言处理任务的事实上的标准，但它在计算机视觉上的应用仍然有限。在视觉方面，注意力要么与卷积网络结合使用，要么用于替换卷积网络的某些组件，同时保持其整体结构不变。本文证明这种对cnn的依赖是不必要的，直接应用于图像补丁序列的纯Transformer可以很好地完成图像分类任务。当对大量数据进行预训练并传输到多个中型或小型图像识别基准(ImageNet, CIFAR-100, VTAB等)时，Vision Transformer (ViT)与最先进的卷积网络相比获得了出色的结果，同时需要更少的计算资源进行训练。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/C-Vision-Transformer-ViT/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240928161421240.png" alt="ViT"></p><p>将图像分割成固定大小的补丁，线性嵌入每个补丁，添加位置嵌入，并将结果向量序列馈送到标准Transformer编码器。为了执行分类，使用标准方法向序列中添加一个额外的可学习的“分类令牌”。</p><h4 id="多头自注意力机制："><a href="#多头自注意力机制：" class="headerlink" title="多头自注意力机制："></a>多头自注意力机制：</h4><p>标准qkv自注意是神经架构的流行构建块。对于输入序列$z∈R^{N×D}$中的每个元素，我们计算序列中所有值v的加权和。注意权$A_{ij}$基于序列中两个元素的成对相似度及其各自的查询$q_i$和键$k_j$表示。<br>$$<br>[q,k,v]&#x3D;zU_{qkv} \ \ \ \ \ \ \ \ \  U_{qkv}\in R^{D\times3D_h},\<br>A&#x3D;softmax(\frac{qk^T}{\sqrt{D_h}}) \ \ \ \ \ \<br>A\in R^{N\times N},\<br>SA(z)&#x3D;A_v<br>$$<br>多头自注意(MSA)是自注意的扩展，其中并行运行k个自注意操作，称为“头”，并投影它们的连接输出。为了在改变k时保持计算量和参数数量不变，通常将$D_h$ 设为D&#x2F;k。<br>$$<br>MSA(z) &#x3D; [SA_1(z); SA_2(z); · · · ; SA_k(z)]U_{msa}\ \ \ \ \ \ \ \<br>U_{msa} ∈ R^{k·D_h×D}<br>$$</p><h3 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h3><p>Vision transformer 将纯 transformer 应用于图像，无需任何卷积层。它们将图像分割成块，并将 transformer 应用于块嵌入。通过对块的扁平像素值应用简单的线性变换来生成块嵌入。然后，将块嵌入以及分类 token 馈送到标准 transformer 编码器 。token 上的编码 用于使用 MLP 对图像进行分类。</p><p>在将补丁输入到 Transformer 时，学习到的位置嵌入会添加到补丁嵌入中，因为补丁嵌入不包含有关该补丁来自何处的任何信息。位置嵌入是每个补丁位置的一组向量，使用梯度下降法和其他参数进行训练。</p><p>ViT 在大型数据集上进行预训练时表现良好。本文建议使用 MLP 分类头对它们进行预训练，然后在微调时使用单个线性层。本文使用在 3 亿个图像数据集上进行预训练的 ViT 击败了 SOTA。他们还在推理过程中使用更高分辨率的图像，同时保持补丁大小不变。新补丁位置的位置嵌入是通过插值学习位置嵌入来计算的。</p><p>这是在 CIFAR-10 上训练 ViT 的实验。由于是在小型数据集上训练的，因此效果不佳。这是一个简单的实验，任何人都可以运行和使用 ViT。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">from</span> labml_helpers.module <span class="hljs-keyword">import</span> Module<br><span class="hljs-keyword">from</span> labml_nn.transformers <span class="hljs-keyword">import</span> TransformerLayer<br><span class="hljs-keyword">from</span> labml_nn.utils <span class="hljs-keyword">import</span> clone_module_list<br></code></pre></td></tr></table></figure><p>获取补丁嵌入</p><p>本文将图像分割成大小相同的块，并对每个块的扁平像素进行线性变换。</p><p>通过卷积层实现同样的事情，因为它实现起来更简单。</p><ul><li><code>d_model</code> 是 transformer 嵌入的大小</li><li><code>patch_size</code> 是补丁的大小</li><li><code>in_channels</code> 是输入图像的通道数（RGB 为 3）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PatchEmbeddings</span>(<span class="hljs-title class_ inherited__">Module</span>):<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model: <span class="hljs-built_in">int</span>, patch_size: <span class="hljs-built_in">int</span>, in_channels: <span class="hljs-built_in">int</span></span>):<br></code></pre></td></tr></table></figure><p>我们创建一个卷积层，其核大小和步长等于块大小。这相当于将图像分割成块并对每个块进行线性变换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">super</span>().__init__()<br>self.conv = nn.Conv2d(in_channels, d_model, patch_size, stride=patch_size)<br></code></pre></td></tr></table></figure><ul><li><code>x</code> 是形状为<code>[batch_size, channels, height, width]</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor</span>):<br></code></pre></td></tr></table></figure><p>应用卷积层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.conv(x)<br></code></pre></td></tr></table></figure><p>获取形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">bs, c, h, w = x.shape<br></code></pre></td></tr></table></figure><p>重新排列形状<code>[patches, batch_size, d_model]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">x = x.permute(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>      x = x.view(h * w, bs, c)<br></code></pre></td></tr></table></figure><p>返回补丁嵌入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>添加参数化位置编码,</p><p>这会将学习到的位置嵌入添加到补丁嵌入中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LearnedPositionalEmbeddings</span>(<span class="hljs-title class_ inherited__">Module</span>):<br></code></pre></td></tr></table></figure><ul><li><code>d_model</code> 是 transformer 嵌入的大小</li><li><code>max_len</code> 是最大补丁数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model: <span class="hljs-built_in">int</span>, max_len: <span class="hljs-built_in">int</span> = <span class="hljs-number">5_000</span></span>):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">super</span>().__init__()<br></code></pre></td></tr></table></figure><p>每个位置的位置嵌入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.positional_encodings = nn.Parameter(torch.zeros(max_len, <span class="hljs-number">1</span>, d_model), requires_grad=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><ul><li><code>x</code> 是形状为<code>[patches, batch_size, d_model]</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor</span>):<br></code></pre></td></tr></table></figure><p>获取给定补丁的位置嵌入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pe = self.positional_encodings[:x.shape[<span class="hljs-number">0</span>]]<br></code></pre></td></tr></table></figure><p>添加到补丁嵌入并返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">return</span> x + pe<br></code></pre></td></tr></table></figure><p>MLP 分类主管</p><p>这是基于标记嵌入对图像进行分类的两层 MLP 头 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ClassificationHead</span>(<span class="hljs-title class_ inherited__">Module</span>):<br></code></pre></td></tr></table></figure><ul><li><code>d_model</code> 是 transformer 嵌入大小</li><li><code>n_hidden</code> 是隐藏层的大小</li><li><code>n_classes</code> 是分类任务中的类别数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model: <span class="hljs-built_in">int</span>, n_hidden: <span class="hljs-built_in">int</span>, n_classes: <span class="hljs-built_in">int</span></span>):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">super</span>().__init__()<br></code></pre></td></tr></table></figure><p>第一层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.linear1 = nn.Linear(d_model, n_hidden)<br></code></pre></td></tr></table></figure><p>激活</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.act = nn.ReLU()<br></code></pre></td></tr></table></figure><p>第二层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.linear2 = nn.Linear(n_hidden, n_classes)<br></code></pre></td></tr></table></figure><p><code>x</code> 是token 的 transformer 编码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor</span>):<br></code></pre></td></tr></table></figure><p>第一层和激活。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.act(self.linear1(x))<br></code></pre></td></tr></table></figure><p>第二层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.linear2(x)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>VisionTransformer 这结合了补丁嵌入、位置嵌入、Transformer和分类头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VisionTransformer</span>(<span class="hljs-title class_ inherited__">Module</span>):<br></code></pre></td></tr></table></figure><ul><li><code>transformer_layer</code>是单个Transformer层的副本。我们复制它以制作Transformer 。<code>n_layers</code></li><li><code>n_layers</code>是Transformer层的数量。</li><li><code>patch_emb</code> 是补丁嵌入层。</li><li><code>pos_emb</code> 是位置嵌入层。</li><li><code>classification</code> 是分类主管。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, transformer_layer: TransformerLayer, n_layers: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">             patch_emb: PatchEmbeddings, pos_emb: LearnedPositionalEmbeddings,</span><br><span class="hljs-params">             classification: ClassificationHead</span>):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">super</span>().__init__()<br></code></pre></td></tr></table></figure><p>补丁嵌入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">self.patch_emb = patch_emb<br>self.pos_emb = pos_emb<br></code></pre></td></tr></table></figure><p>分类头</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.classification = classification<br></code></pre></td></tr></table></figure><p>复制transformer</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.transformer_layers = clone_module_list(transformer_layer, n_layers)<br></code></pre></td></tr></table></figure><p>标记嵌入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.cls_token_emb = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, transformer_layer.size), requires_grad=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>最终规范化层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.ln = nn.LayerNorm([transformer_layer.size])<br></code></pre></td></tr></table></figure><ul><li><code>x</code> 是形状为<code>[batch_size, channels, height, width]</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor</span>):<br></code></pre></td></tr></table></figure><p>获取补丁嵌入。这给出了形状为<code>[patches, batch_size, d_model]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.patch_emb(x)<br></code></pre></td></tr></table></figure><p>在输入转换器之前连接 token嵌入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">cls_token_emb = self.cls_token_emb.expand(-<span class="hljs-number">1</span>, x.shape[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>)<br>x = torch.cat([cls_token_emb, x])<br></code></pre></td></tr></table></figure><p>添加位置嵌入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.pos_emb(x)<br></code></pre></td></tr></table></figure><p>无需注意掩蔽即可通过 Transformer 层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.transformer_layers:<br>    x = layer(x=x, mask=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p>获取令牌的转换器输出 （序列中的第一个）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = x[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><p>层规范化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.ln(x)<br></code></pre></td></tr></table></figure><p>分类头，得到logits</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.classification(x)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Diffusion Models Beat GANs on Image Synthesis</title>
    <link href="/2024/07/05/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/"/>
    <url>/2024/07/05/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/</url>
    
    <content type="html"><![CDATA[<h2 id="Diffusion-Models-Beat-GANs-on-Image-Synthesis"><a href="#Diffusion-Models-Beat-GANs-on-Image-Synthesis" class="headerlink" title="Diffusion Models Beat GANs on Image Synthesis"></a>Diffusion Models Beat GANs on Image Synthesis</h2><p><img src="/../images/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240705130419512.png" alt="TITLE"></p><blockquote><p>发表在2021年的NeurIPS会议上</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>GANs(生成对抗网络)一直是广泛使用的方法之一，在图片生成领域效果很好，但也有着训练过程不稳定，模式崩溃等问题。Diffusion Models(扩散模型)是一类基于概率生成过程的模型，一开始用于密度建模和生成任务，此研究旨在评估扩散模型在图像生成任务中的表现，与GANs进行对比。扩散模型有着分布覆盖广，使用静态训练目标和易于扩展的有点，但是其生成效果与GANs仍然有差距，所以作者改进了现有的Diffusion模型架构，同时提出了可以平衡图像生成多样性和逼真度的方案。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>论文提出了一种改进的扩散模型，该模型通过多步去噪过程生成高质量的图像。扩散过程包括两个阶段：</p><ul><li><strong>前向过程</strong>：逐渐向图像中添加噪声，直到图像变成纯噪声。</li><li><strong>反向过程</strong>：从纯噪声开始，逐步去噪重建图像。</li></ul><p>研究中使用了特定的网络结构和训练策略来优化扩散模型的性能，包括了U-Net架构、阶梯式噪声调度策略等，经过改进后，模型取得了明显的效果。</p><p><img src="/../images/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240708172941523.png" alt="模型改进"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>论文在多个数据集上对扩散模型和GANs进行了实验对比，包括CIFAR-10、LSUN、ImageNet等。实验结果表明，扩散模型在图像生成的质量和多样性上优于GANs。具体表现为：</p><ul><li>在CIFAR-10上，扩散模型生成的图像质量（FID值）优于当前最好的GAN模型。</li><li>在更大规模的ImageNet数据集上，扩散模型也展示了优异的生成能力。</li></ul><p><img src="/../images/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240708173615704.png" alt="实验结果"></p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>论文的主要贡献在于提出并验证了扩散模型在图像生成任务中的优越性，表明这种模型在图像质量和生成稳定性上都超过了传统的GANs。未来的发展方向可能包括进一步优化扩散模型的效率，探索其在更大规模数据集和更复杂图像生成任务中的应用。</p><h4 id="Reference-Link-https-sunlin-ai-github-io-2022-05-30-guided-diffusion-html"><a href="#Reference-Link-https-sunlin-ai-github-io-2022-05-30-guided-diffusion-html" class="headerlink" title="Reference Link:https://sunlin-ai.github.io/2022/05/30/guided-diffusion.html"></a>Reference Link:<a href="https://sunlin-ai.github.io/2022/05/30/guided-diffusion.html">https://sunlin-ai.github.io/2022/05/30/guided-diffusion.html</a></h4>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Why Should I Trust You Explaining the Predictions of Any Classifier</title>
    <link href="/2024/07/03/0-Why-Should-I-Trust-You-Explaining-the-Predictions-of-Any-Classifier/"/>
    <url>/2024/07/03/0-Why-Should-I-Trust-You-Explaining-the-Predictions-of-Any-Classifier/</url>
    
    <content type="html"><![CDATA[<h2 id="“Why-Should-I-Trust-You”Explaining-the-Predictions-of-Any-Classifier"><a href="#“Why-Should-I-Trust-You”Explaining-the-Predictions-of-Any-Classifier" class="headerlink" title="“Why Should I Trust You”Explaining the Predictions of Any Classifier"></a>“Why Should I Trust You”Explaining the Predictions of Any Classifier</h2><p><img src="/../images/%E5%A6%82%E4%BD%95%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240703151226459.png" alt="TITLE"></p><blockquote><p>LIME 这篇论文发表在2016年的KDD会议上</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>机器模型虽然被广泛采用，但是其对人们来说，还是一个黑匣子。然而，了解机器学习背后的原理对于其评估非常重要，因此一种称为“LIME（Local Interpretable Model-agnostic Explanations）”的技术被提出，通过可解释和忠实的方式解释任何分类器的预测，以非冗余的方式呈现代表性的个体预测及其解释。人类对模型行为的理解程度，而不是将其视为黑匣子。</p><p>当模型用于决策时，确定对个人预测的信任是很重要的，例如，当使用机器学习进行医疗诊断、恐怖主义检测时，如果盲目的相信预测，可能会带来灾难性的后果。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>LIME 是一种模型无关的方法，可以解释任何机器学习模型的预测结果。它的基本思路是通过扰动输入数据并观察模型输出的变化，来构建一个局部线性模型，从而解释模型在某个特定数据点附近的行为。LIME 的具体步骤如下：</p><ol><li><strong>扰动输入数据</strong>：生成与原始数据点相似的一组扰动数据。</li><li><strong>模型预测</strong>：使用原始模型对这些扰动数据进行预测。</li><li><strong>加权线性回归</strong>：根据扰动数据与原始数据点的相似度，对扰动数据的预测结果进行加权线性回归，从而得到一个局部的线性模型。</li><li><strong>解释结果</strong>：利用线性模型的系数解释原始模型的预测。</li></ol><p><img src="/../images/%E5%A6%82%E4%BD%95%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240703154637601.png" alt="解释个体症状"></p><p>LIME的主要流程，通过对数据对可能的症状进行高亮标记，通过这个模型就会对于结果有可信的预测。</p><p><img src="/../images/%E5%A6%82%E4%BD%95%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240703155111570.png" alt="LIME工作流程"></p><p>在模型中选取需要预测的点，对其周围的点按照weight进行标记，然后将weight大的点放入模型中重新标记，选择一个解释模型来表示原来的模型，也就是在用一个可解释的新模型代替不可解释的原模型。</p><p>假设我们有一个训练好的图像分类模型，可以将医学图像分类为正常或异常。我们使用LIME来解释模型对某个具体图像的预测：</p><ol><li><strong>输入扰动</strong>：对该医学图像进行小幅度扰动，如改变某些像素值或添加噪声，生成一组相似的图像。</li><li><strong>模型预测</strong>：使用原始模型对这些扰动图像进行预测，记录每个扰动图像的预测结果。</li><li><strong>加权回归</strong>：根据扰动图像与原始图像的相似度，对这些扰动图像的预测结果进行加权线性回归，构建局部线性模型。</li><li><strong>解释结果</strong>：分析线性模型的系数，解释哪些像素或图像区域对原始模型的预测影响最大，从而理解模型是如何做出预测的。</li></ol><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>论文在多个数据集上进行了实验，包括文本分类和图像分类。实验结果表明，LIME能够有效地解释复杂模型的预测结果，并且在保持高解释性的同时，对原始模型的预测结果有较高的近似度。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过这种方法，我们可以更好地理解深度学习模型在医学图像处理中的决策过程，提升模型的透明度和可信度。</p><p>事实上还有一种方法SHAP（SHapley Additive exPlanations）是一种基于合作博弈论的解释方法，用于解释机器学习模型的预测结果。SHAP 结合了Shapley值的理论基础和加性特征重要性的思想，是目前广泛应用的一种解释工具。相比于 LIME，SHAP 更加严格和全面，但计算复杂度也较高。在实际应用中，SHAP 被广泛用于解释各种机器学习和深度学习模型的预测结果，提升模型的可解释性和透明度。在本文中不再介绍。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
    <link href="/2024/06/22/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/"/>
    <url>/2024/06/22/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/</url>
    
    <content type="html"><![CDATA[<h2 id="Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting"><a href="#Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting" class="headerlink" title="Dropout: A Simple Way to Prevent Neural Networks from Overfitting"></a>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</h2><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624205657449.png" alt="Dropout"></p><blockquote><p>Journal of Machine Learning Research 15 (2014)</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><a href="https://cnwuyueyu.github.io/2024/05/25/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/">“Improving neural networks by preventing co-adaptation of feature detectors”</a>这篇文章与本文有很大的关联，实际上，前者可以被认为是后者的早期工作或相关研究，前者讨论了防止特征检测器协同适应(co-adaptation)的方法，这就是Dropout技术的核心思想，本文是作者在同一年稍晚时候发表的进一步研究成果，更详细地描述了Dropout技术并提供了更多实验结果。</p><h3 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h3><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624211159119.png" alt="网络模型"></p><p>左边是训练集神经元，右边是测试集神经元。左边训练集的神经元以P概率被保留。右边测试集不做丢弃，但参数乘以p。 这⾥的意义就是保证训练集和测试集 的输出期望⼀致。</p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624211321053.png" alt="期望"></p><p>也就是Dropout说数目要在相应的分母中减去，以保证结果不会偏差。</p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212030741.png" alt="模型描述"></p><p>Dropout神经网络模型描述。Dropout通过减少神经元之间的相互依赖，迫使网络学习到更加鲁棒的特征。这不仅有效防止了过拟合，还可以看作是对多个不同结构网络的集成，提升了模型的泛化能力。</p><p>深入研究：</p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212409263.png" alt="对特征的影响"></p><p>其中，图(a)是没有Dropout的神经网络提取的特征，图(b)是丢失率 p&#x3D;0.5 时的带Dropout的神经网络提取的特征。由上图可知，Dropout破坏了隐藏层单元之间的协同适应性，使得带Dropout的神经网络提取的特征更明确，增加了模型的泛化能力。</p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212438607.png" alt="稀疏性的影响"></p><p>其中，图(a)是没有Dropout的神经网络提取的特征，图(b)是丢失率 p&#x3D;0.5 时的带Dropout的神经网络提取的特征。由上图可知，Dropout使得网络中只有极少数单位具有较高的激活能力。</p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212525202.png" alt="对丢失率的影响"></p><p>其中，图(a)是第一种情况，在第一种情况下，使用不同数量的辍学来训练相同的网络架构。网络结构为784-2048-2048-2048-10。没有在输入时使用Dropout。由图可知，随着p的增加，测试误差先降后升，在 p∈[0.4,0.8] 时效果最好。 图(b)是第二种情况，此时 pn 保持不变，因此p越大，n越小，反之亦然。由该图可知，随着p的增加，测试误差先降后升，在 p&#x3D;0.6 时效果最好。</p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212619091.png" alt="对数据集大小的影响"></p><p>其中，实验从MNIST训练集中随机选取100、500、1K、5K、10K和50K的数据集。所有数据集的网络结构皆为784-1024-1024-2048-10。Dropout的丢失率为0.5。由上图可知，在小数据集(100,500)上，Dropout并没有改善性能，数据量变大时，Dropout就有了明显的改善网络的效果，但数据量过大是Dropout对网络的改进并不明显。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>所用的数据集有：</p><ul><li>MNIST：一组手写体数字的标准数据集。</li><li>Timit：用于语音清洗识别的标准语音基准。</li><li>CIAR-10和CIFAR-100：微小的自然图像。</li><li>街景房屋编号数据集(Street View House Numbers data set，SVHN)：谷歌街景收集的房屋号码图片。</li><li>ImageNet：大量自然图像的集合。</li><li>Reuters-RCV1：路透社新闻报道集。</li><li>替代剪接数据集(Alternative Splicing data set)：预测替代基因剪接的RNA特征。</li></ul><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212802707.png" alt="MNIST"></p><p><img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624212824659.png" alt="CIAR-10和CIFAR-100"></p><p>可以看出都有不错的结果，其他数据集的结果不在次赘述。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>“Improving neural networks by preventing co-adaptation of feature detectors”提出了防止神经网络中过拟合的基本思想，而“Dropout: A Simple Way to Prevent Neural Networks from Overfitting”详细描述并验证了这一思想，形成了Dropout技术。两篇论文共同推进了深度学习领域的发展，为后续研究和应用奠定了基础。Dropout的基本思想是，在每次训练迭代中，随机忽略（“丢弃”）网络中的一些神经元，包括它们的连接。具体做法是在前向传播时，以一定的概率p将某些神经元的输出设为零，而在反向传播时只对剩下的神经元进行权重更新。这篇论文的主要贡献在于提供了一种简单而有效的防止过拟合的方法，极大地推动了神经网络的发展和应用。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1</title>
    <link href="/2024/06/22/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/"/>
    <url>/2024/06/22/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/</url>
    
    <content type="html"><![CDATA[<h2 id="Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-−1"><a href="#Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-−1" class="headerlink" title="Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1"></a>Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1</h2><p><img src="/../images/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240630190852246.png" alt="TITLE"></p><blockquote><p>arXiv:1602.02830v2 [cs.LG] 29 Feb 2016</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>本文提出了一种称为二值化神经网络（Binarized Neural Networks, BNNs）的方法。这种方法对神经网络中的权重和激活值进行二值化处理，将它们限制为+1或-1。这种处理方式的主要优势在于：计算效率：二值化操作可以大幅减少计算所需的复杂度，使得计算变得更为简单和快速。内存节省：由于权重和激活值仅需存储为1位（bit），内存需求显著降低。硬件友好：这种方法特别适用于在硬件上实现，如FPGA和ASIC等专用集成电路。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>二值化方法：</p><p>（1）Derterministic<br>$$<br>x^b&#x3D;Sign(x)&#x3D;\begin{cases}+1&amp; if\ x\geq0\-1&amp; \text{otherwise}\end{cases}<br>$$<br>（2）Stochastic(硬件生成随机数)<br>$$<br>x^b&#x3D;\begin{cases}+1&amp; 随机计算p&#x3D;\sigma(x) \-1&amp;1-p \end{cases}<br>$$<br>本文选用第一种方法，避免了使用硬件生成随机数。</p><p>二值化网络：</p><p>（1）二值化网络只是将网络的参数和激活值二值化，没有改变网络结构，且输出层的概率输出仍是浮点型，其前馈模型的公式表示为：<br>$$<br>x^k&#x3D;\sigma(W^k·x^{k-1})\<br>x^k是第k层输入，W^k是第k层权值矩阵，\\sigma()为非线性激活函数。<br>$$<br>（2）二值化激活函数：<br>$$<br>\sigma(x)&#x3D;sign(x)<br>$$<br>训练过程：</p><p>（1）前馈过程：先将实数型权值参数二值化得到二值型权值参数，即$W^b_k&#x3D;sign(W_k)$。然后利用二值化后的参数计算得到实数型的中间向量，该向量再通过Batch Normalization操作，得到实数型的隐藏层激活向量。如果不是输出层的话，就将该向量二值化。<br>$$<br>x^k&#x3D;\sigma(BN(W_b^k·x^{k-1}))&#x3D;sign(BN(W_b^k·x^{k-1}))<br>$$<br>（2）反向更新：</p><p><img src="/../images/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240701210215374.png" alt="反向更新"></p><p>作者为了解决sign的导数几乎处处为零的问题，对sign(x)进行了改写，让其在-1和1之间加一个线性变化的过程。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240701210433148.png" alt="DATA"></p><p>展示了在CIFAR-10和SVHN等多个数据集上的实验结果，表明二值化神经网络在保持较低计算和内存开销的情况下，依然能够取得接近甚至超过传统神经网络的性能。</p><p>与实值网络相比准确率并没有太多降低，时间复杂度却可以降低60%。相对于32bit的DNN，BNN内存需求量减少为原来的1&#x2F;3</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>二值化神经网络通过简化计算和降低内存需求，为神经网络的实际应用提供了一种有效的方法。特别是在计算资源有限的场景下（如移动设备和嵌入式系统），这种方法具有显著的优势。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Decoupled Neural Interfaces using Synthetic Gradients</title>
    <link href="/2024/06/22/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/"/>
    <url>/2024/06/22/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/</url>
    
    <content type="html"><![CDATA[<h2 id="Decoupled-Neural-Interfaces-using-Synthetic"><a href="#Decoupled-Neural-Interfaces-using-Synthetic" class="headerlink" title="Decoupled Neural Interfaces using Synthetic"></a>Decoupled Neural Interfaces using Synthetic</h2><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/image-20240622194336563.png" alt="DNI"></p><blockquote><p>使用合成梯度的解耦神经接口arXiv:1608.05343v2 ICML2016</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>训练神经网络需要数据通过前向传播，随后反向传播误差来更新权重，在这个过程中，网络和模块各层之间的相互依赖，需要等待其他层的计算完成才能完成更新，导致效率低下。本文的作者使用建模误差梯度，通过使用建模用合成梯度代替真正的反向传播误差梯度，将子图解耦，并且可以独立和异步地更新它们，即实现了解耦的神经接口。</p><p>本文的核心创新在于使用合成梯度。合成梯度使用局部信息进行预测，而不是等待从误差中计算出的真实梯度。这些合成梯度允许网络的不同部分独立且异步地进行更新。从而在前向和后向解耦的模型<br>和向后传递 相当于独立网络共同学习，这样它们就可以组成一个单一运作的模块。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624201340762.png" alt="DNI网络"></p><p>图中$M_B$是DNI网络，相当于使用自建的模型来预测梯度。输入的是某一层的输出，输出的就是该层对应的梯度，这样就解除了更新锁和反向锁，优化了梯度的计算时间。</p><p>传统的反向传播(Backpropagation, BP)算法，是先计算出最后一层的残差，然后用最后一层的残差去计算倒数第二层的残差，依次类推，如果在训练模型 M 时依然遵照这个流程，毫无疑问 Update Locking 和 Backward Locking 依然存在，所以作者在计算每一层的“实际残差”时，用的是后一层的“合成残差”，而合成残差的计算是可以立即计算的，这样近似出的结果去评估模型中的残差估计值，如下图所示：</p><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624203729386.png" alt="前馈网络训练期间的执行情况"></p><p>再进一步地，作者表示，利用 DNI 的思想，去预测每一层的输入也是可以的，这样就把 Forward Locking 也去掉了。基本思想和合成梯度是一样的，不同之处在于预测每一层的输入时只用到第一层也就是输入层的输入</p><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624203826206.png" alt="完全解锁前馈网络训练，允许层的前向和更新解耦。"></p><p>这样 Forward Locking、Update Locking 和 Backward Locking 都被去掉了，通过适当的设计，整个训练可以被很好地并行化、异步化了。</p><p>DNI 的思想除了用在前馈神经网络上，也可以用于循环神经网络(Recurrent Neural Network, RNN)的训练上面，因为 RNN 在时间维度上展开后，其实就相当于是一个前馈神经网络了。而且由于应用 DNI 的模型，最多只有两层的网络层依赖，那么在用于 RNN 训练时，可以不用将 RNN 完全展开，而是可以以两个 time step 为最小单元进行展开，即一次只展开两个 time step，这样在存储上的消耗也可以被降低。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624204006174-17192328144371.png" alt="MNIST和CIFAR-10两个数据集上测试了 DNI 方法和 BP 方法之间的训练效果"></p><p>实验表明使用 DNI 模型能够被训练 。</p><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624204549569.png" alt="随机更新解耦 与 转发和更新分离"></p><p>左：对一个四层的前馈网络，以随机的顺序来更新每一层，并且每一层在被选中都是有概率的。在这样的情况下，模型依然是可以被训练的。不过明显能看出来，概率值越大，收敛是越快的。</p><p>右：加上了 synthetic inputs ，也就是把 Forward Locking 去掉了，从结果上来看，和第上一个实验差不多。</p><p><img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624204812811.png" alt="RNN上的实验"></p><p>最后在 RNN 上进行了三个实验，分别是:</p><ul><li>Copy: 读入 N 个字符，然后将这 N 个字符原样输出，有点类似 char-level language model 和 autoencoder。</li><li>Repeat Copy: 读入 N 个字符，以及一个表示重复次数的数字 R，然后重复输出 R 次这 N 个字符构成的序列。</li><li>char-level language modeling: (持续地)读取一个字符，并预测下一个字符。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文提出了一种使用合成梯度来加速神经网络训练的新方法，通过解耦网络层或模块之间的依赖性，提高训练效率。异步训练：网络层或模块可以独立训练，提高了训练效率。扩展时间依赖性：特别是对于RNN，这种方法有助于更有效地建模长期依赖性。灵活的网络结构：该技术可以应用于各种网络架构，不仅限于标准的前馈或循环网络。这种方法通过打破传统的训练过程中的层依赖性，显著提高了神经网络训练的效率和可扩展性。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Layer Normalization</title>
    <link href="/2024/06/22/0-Layer-Normalization/"/>
    <url>/2024/06/22/0-Layer-Normalization/</url>
    
    <content type="html"><![CDATA[<h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p><img src="/../images/0-Layer-Normalization/image-20240622151144967.png" alt="Layer Normalization "></p><blockquote><p>层标准化 arXiv:1607.06450v1  2016年</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><a href="https://cnwuyueyu.github.io/2024/05/25/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/">BN（2015）</a>、<a href="#">LN</a>做为常用的标准化方法，不同之处就是在于对于激活函数的改变方式。标准化的目的是为了把输入转化成均值为0,方差为1的数据。</p><p>BN通过在深度神经网络中加入额外的归一化阶段来减少训练时间，除了训练时间的改善外，批量统计的随机性还可在训练过程中充当正则化器。但是BN在处理RNN任务序列化数据不适用，并且BN依赖Batch Size,所以引出了本文，层归一化的思想：与批量归一化不同，所提出的方法直接从隐藏层内神经元的总输入中估计归一化统计数据，因此归一化不会在训练案例之间引入任何新的依赖关系。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>层规范化LN就是为了克服BN的缺点，通过固定每层内输入总和的均值和方差，可以减少“协变量偏移”的问题。在RNN中，例如输入文本处理任务，训练案例中的不同句子长度不同是很常见的，使用BN的话，我们需要为序列中每个时间步长计算和存储单独的统计数据，如果测试数据比训练数据长，那么就会出现问题，而LN的归一化项仅取决于当前时间步长对层的输入求和，并且只有一组共享的增益和偏差参数。</p><h4 id="1-权重和数据变换的不变性"><a href="#1-权重和数据变换的不变性" class="headerlink" title="1.权重和数据变换的不变性"></a>1.权重和数据变换的不变性</h4><p>两个标量$\mu$和$\sigma$将总输入$a_i$归一化到神经元，之后为每一个神经元学习自适应偏差b和增益g。<br>$$<br>h_i&#x3D;f(\frac{g_i}{\sigma_i}(a_i-\mu_i)+b_i)<br>$$<br>在经过权重与数据的重新缩放和重新居中后：<br>$$<br>h_i^丿&#x3D;f(\frac{g_i}{\sigma^丿}w_i^Tx^丿-\mu^丿)+b_i)&#x3D;f(\frac{g_i}{\delta\sigma}\delta w_i^Tx-\delta\mu)+b_i)&#x3D;h_i<br>$$<br>重新缩放单个数据点不会改变模型在层下的预测归一化，类似于层归一化中权重矩阵的重新居中，可以表明批量标准化对于数据集的重新居中具有不变性。</p><h4 id="2-学习过程中参数空间的几何形状"><a href="#2-学习过程中参数空间的几何形状" class="headerlink" title="2.学习过程中参数空间的几何形状"></a>2.学习过程中参数空间的几何形状</h4><p>本部分，作者介绍了，通过权重向量的增长来隐性降低学习率和学习输入权重的大小的选取方法，归一化模型仅取决于预测误差的大小。标准化模型中传入权重对输入的缩放更具鲁棒性及其参数比标准模型更精确。详细推导见附录。</p><p><img src="/../images/0-Layer-Normalization/image-20240622193442114.png" alt="BN与LN"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Layer-Normalization/image-20240622193608398.png" alt="实验结果"></p><p>专注阅读模型的验证曲线，可以看出使用LN方法在最少的训练步骤获得了低错误率。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>Layer Normalization (LN) 的一个优势是不需要批训练，在单条数据内部就能归一化。LN不依赖于batch size和输入sequence的长度，因此可以用于batch size为1和RNN中。LN用于RNN效果比较明显，但是在CNN上，效果不如BN。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-HyKGE AHypothesis Knowledge Graph Enhanced Framework</title>
    <link href="/2024/06/22/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/"/>
    <url>/2024/06/22/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/</url>
    
    <content type="html"><![CDATA[<h2 id="HyKGE：利用知识图谱增强大语言模型在医学领域提升准确度"><a href="#HyKGE：利用知识图谱增强大语言模型在医学领域提升准确度" class="headerlink" title="HyKGE：利用知识图谱增强大语言模型在医学领域提升准确度"></a>HyKGE：利用知识图谱增强大语言模型在医学领域提升准确度</h2><p><img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143024238.png" alt="HyKGE"></p><blockquote><p>arXiv:2312.15883v2 2024年4月19日(v2)</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>LLM增强的知识图谱问答：是指结合大型语言模型（LLM）和知识图谱（KG）来改进和增强问答系统的能力。通过利用LLM的自然语言处理和生成能力，结合知识图谱的结构化数据。通过结合LLM和KG，问答系统可以处理更复杂和多样化的问题，同时提供更高质量和更可信的回答。这种增强方法有助于突破传统问答系统的限制，提升用户体验和满意度。</p><p>大型语言模型（LLM）：基于深度学习技术训练的模型，能够理解和生成自然语言文本。擅长处理各种自然语言任务，如文本生成、翻译、总结和问答等。例如，GPT-4、文心一言等。</p><p>知识图谱（KG）：一种以图形结构表示知识的数据库，节点表示实体（如人物、地点、事件等），边表示实体之间的关系。提供结构化和关联的数据，可以用于回答具体问题和提供事实信息。</p><p>知识问答系统（QA System）：一个能够接受自然语言问题并生成答案的系统。通常包括问题理解、信息检索和答案生成三个主要步骤。</p><p>检索增强生成（RAG）：通过检索外部信息来增强内容生成，减少知识密集型任务中的事实错误。RAG 被认为是一种有前途的解决方案，可以解决错误答案、幻觉和解释不足的问题。</p><p>Retrieval-Augmented Generation（检索增强生成）：通过提示工程将外部知识检索组件纳入其中，以实现更符合事实的一致性，提高可靠性和 LLM 响应的可解释性，但在获取高精度方面仍然遇到困难用于训练查询文档对检索器的优质数据集，或用户查询中的信息有限，削弱了普遍性。</p><p> Knowledge Graph Query-Answer (知识图谱问答)： 知识知识图谱具有结构化和可推断的优势，相比知识存储在文档库中。但是如何从 KG 中获取知识，以及如何设计LLM 与 KG 之间的交互策略仍处于探索阶段。 目前的解决办法是语义解析方法：允许LLM 将问题转换为结构化查询（例如 SPARQL），可以由查询引擎执行来得出答案。</p><p>所面临的挑战：</p><ul><li>避免事实错误（如幻觉和有限解释性）</li><li>数据约束（如资源限制、高训练成本和隐私问题）</li><li>灾难性遗忘</li><li>知识过时</li><li>处理特定领域或高度专业化查询的专业知识不足</li></ul><p>解决方案：</p><ul><li>将用户不一致的非结构化查询与高质量的结构化知识图谱对接，存在显著挑战。</li><li>提出了一种假设知识图谱增强（HyKGE）框架，利用 LLMs 强大的推理能力来补偿用户查询的不完整性，优化与 LLMs 的交互过程，并提供多样化的检索知识。</li></ul><p> HyKGE在预检索过程中使用图推理链纠正模型错误，并在后检索中应用细粒度对齐来保持有效、多样的知识，在没有微调或过度交互的情况下高效地增强检索。</p><p><img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143438955.png" alt="HyKGE介绍"></p><p>KGRAG（左）。基本 KGRAG 从用户查询中提取关键实体，并在其中搜索相应实体 KG，然后与查询一起输入到 LLM 中。询问饭后，我感觉有点胃反流。用什么药？ 仅根据查询条件搜索KG 提示 &#x3D;查询+实体 答案：胃食管反流 可能是由于落后 食物或胃酸的流动。您 可以考虑使用抑酸 缓解症状的药物 胃反流和减轻 反流性食管炎的发展⋯⋯</p><p>HyKGE（右）。HyKGE 首先查询 LLM 以获得假设 输出并从假设输出和查询中提取实体。然后 HyKGE 检索 任意两个锚实体，并将推理链与查询一起输入到 LLM问题吃完饭后，感觉有点胃痛 胃食管反流。我应该服用什么药物治疗？ 假设输出⋯⋯胃食管反流可能是由于胃酸反流到食管引起的⋯⋯根据 证据，考虑使用H2 受体拮抗剂或质子泵抑制剂⋯⋯ 推理链： ①胆汁反流→腹部←胃痛 ②碳酸铝镁→胃灼热→胃酸过多→胃痛 锚实体 提示&#x3D;查询+推理链 回答：胃酸倒流可能是导致 胃食管反流⋯⋯你可以考虑奥美拉唑或 埃索美拉唑减少胃酸分泌，⋯⋯或者， 您可以使用酸中和药物（抗酸药），例如 碳酸镁铝。另一种选择是使用 ⋯ H2 受体拮抗剂，如雷尼替丁或法莫替丁⋯ 中。</p><h3 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h3><p><img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143544030.png" alt="整体框架"></p><p>HyKGE 的整体框架。HyKGE 首先将用户查询（Q）输入到 LLM 中，得到假设输出（H ·O）。然后通过 NER 模块，应用 W2NER 模型识别实体并分离关系。然后通过 GTE 编码器将这 些识别出的实体与知识图谱中的实体链接起来。之后，HyKGE 从知识图谱中提取出相关推理链。然后，由于Q 的稀疏性，在 HO 片段粒度感知重排序模块中， HyKGE 将Q和HO进行分 块，并通过 TopK 链重排序器与推理链对齐，以消除不相关的知识。最后，我们根据用户查询来组织检索到的知识，并通过 LLM Reader 获取答案。</p><p><strong>预检索阶段：</strong>包括假设输出模块和NER模块。HOM利用LLM通过探索可能的答案来获得假设输出。然后NER模块提取来自假设输出模块的医疗实体和用户查询。</p><p>NER（医学命名实体识别）模块：为了解决模型可能出现的幻觉或医学实体之间的误解，作者提取实体而不是关系，并使用KG中完全无误的三元组进行真实性验证，而不是在HO中分析的关系，使用 CMEEE（中文医学命名实体识别数据集）数据训练了一个医学命名实体识别(NER) 模型。</p><p><strong>知识图谱上的检索</strong>：利用提取的实体作为锚点搜索不同类型的推理链，这些推理链将这些锚点相互连接起来，提供相关且合乎逻辑的知识。</p><p>此过程涉及使用编码模型对潜在实体和KG中的实体进行编码，使用GTE嵌入模型，这是目前在检索领域中文本向量嵌入表现最好的模型。GTE 编码器遵循两阶段训练过程最初使用来自文本对的弱监督大规模数据集，然后使用对比 学习对高质量手动标记数据进行微调。计算和的嵌入之间的内积相似度，相似度最高的实体视为匹配。</p><p>选择匹配的实体，使用实体之间的推理链，原因如下：</p><ul><li>推理链为 LLM 提供了更丰富的逻辑知识以帮助其消化。</li><li>推理链帮助 LLM 阅读器理解 不同实体之间的关系，从而减轻幻觉和错误问题。</li><li>推理链充当有效的修剪机制，比 子图更有效地过滤噪音并节省资源。</li></ul><p><strong>后检索阶段：</strong></p><p>采用 HO 片段粒度感知重排序方法。首先，假设输出和用户查询被分割成离散片段，随后，我们根据片段对检索到的推理链进行重排序。</p><p>传统的重新排序仅基于Q上的学习可能会过滤掉通过HOM获得的有价值的知识，从而导致重复和单调的情况。作者创新性地将HO和Q 结合起来，而不是仅仅依赖用户查询，利用其中包含的更丰富的医学知识。</p><p><strong>LLM阅读器：</strong></p><p>接收用户查询和修剪后的检索到的推理链，并通过精心设计的提示进行组织。</p><p><img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143731734.png" alt="假设输出模块和LLM阅读器的提示格式"></p><p><img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143741162.png" alt="算法框架"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143759561.png" alt=" CMB‑Exam 和 MMCU‑Medical 在医学问答答案上的表现比较"></p><p>红色阴影表示表现最佳的模型，蓝色表示消融研究中第二好的模型，绿色表示基线排名第二。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文介绍了HyKGE框架，旨在提高医学领域大型语言模型（LLMs）在回答问题时的准确性和可靠性。该框架利用知识图谱增强了LLMs的推理能力，通过识别实体、关系和知识图谱的嵌入对用户查询进行处理，并从知识图谱中提取相关的推理链。在处理查询和假设输出时，HyKGE采用了分段处理和重新排序的方法，以消除无关知识并提供更精确的答案。该框架的设计使得LLMs能够更好地理解和回答医学领域的复杂问题，提高了在实际应用中的性能表现。</p><p><strong>未来发展</strong>:</p><ul><li>动态优化片段粒度：在后检索阶段，可以探索如何动态优化片段粒度，以进一步提高知识的密度和效率。</li><li>探索更多语言或领域特定的知识图谱：尽管存在数据源的限制和LLMs的高计算成本，但未来可以在更多其他语言或领域特定的知识图谱上进行实验，以增强HyKGE框架的可扩展性和泛化性能。</li><li>持续的实验和优化：未来可以继续尝试不同的策略，并对HyKGE框架进行进一步优化，以不断提升其性能和效果。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Network Morphism</title>
    <link href="/2024/05/26/0-Network-Morphism/"/>
    <url>/2024/05/26/0-Network-Morphism/</url>
    
    <content type="html"><![CDATA[<h2 id="Network-Morphism"><a href="#Network-Morphism" class="headerlink" title="Network Morphism"></a>Network Morphism</h2><p><img src="/../images/0-Network-Morphism/image-20240526152658190.png" alt="Network Morphism"></p><blockquote><p>网络态射 ICML 2016</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在深度学习中，模型架构的设计和优化是一个复杂且耗时的过程。现有的方法通常需要从头开始训练新的模型，或者进行复杂的超参数优化。论文提出了网络态射的概念，旨在通过调整现有网络结构，保持或提高网络性能，同时减少训练时间和资源。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>网络态射包括以下几种主要操作：</p><ol><li><p><strong>增加层数（Layer Morphism）</strong>：</p><ul><li>在现有网络中增加新的层，并确保新的网络在初始化时的输出与原始网络保持一致。</li><li>通过将新层初始化为恒等映射，使得新层不会影响初始的输出。</li></ul><p>数学表示：</p><p>$h’&#x3D;f(W_x+b)$</p><p>其中，$f$ 是激活函数，$W$ 和 $b$ 是新层的权重和偏置，初始化为单位矩阵和零向量。</p></li><li><p><strong>增加节点数（Node Morphism）</strong>：</p><ul><li>增加网络中某一层的节点数，并保持输出不变。</li><li>通过复制和调整权重，使得新的节点不会影响初始的输出。</li></ul><p>数学表示：</p><p>$W^′&#x3D;[W,W_{new}]$</p><p>其中，$W_{\text{new}}$ 是新增加的节点权重，初始化为原始权重的拷贝。</p></li><li><p><strong>改变激活函数（Activation Morphism）</strong>：</p><ul><li>改变网络中的激活函数，同时确保网络的输出保持不变。</li><li>通过适当的初始化和调整，使新的激活函数与原始激活函数等效。</li></ul></li></ol><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Network-Morphism/image-20240526154225741.png" alt="MNIST"></p><p><img src="/../images/0-Network-Morphism/image-20240526154300999.png" alt="CIFAR10"></p><p>通过在 CIFAR-10、CIFAR-100 和 ImageNet 等数据集上的实验，验证了网络变形方法的有效性。</p><p>实验结果表明，通过网络变形方法，可以在不影响性能的情况下，快速调整和优化现有网络结构。</p><p>与从头开始训练的新网络相比，网络变形方法显著减少了训练时间和计算资源。</p><p>主要贡献为：</p><ul><li>提出了一种系统的方法，可以在不影响现有模型性能的情况下，变换神经网络的结构。</li><li>通过一系列的变换操作，如增加层数、增加节点数、改变激活函数等，来调整和优化网络。</li></ul><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>网络态射提供了一种高效的模型调整和优化方法，可以在保持现有网络性能的前提下，快速进行结构调整。这一方法具有重要的应用价值，特别是在需要频繁调整和优化模型结构的深度学习研究和应用中。未来的研究可以进一步探索更多类型的变形操作，以及在更复杂任务中的应用。</p><h3 id="代码分析"><a href="#代码分析" class="headerlink" title="*代码分析"></a>*代码分析</h3><p>网络态射的一个比较火的开源应用是autokeras，其网络结构用 keras 的图模型 graph 表示。</p><p>graph 类中的每个节点都是层之间的中间张量，每一层都是图中的一条边。</p><p>graph 类中包含所有节点 (包括它们的 shape 和 id)、所有的层（包含 层 本身和它们的 id）、关系（层和输入节点、输出节点的关系以及邻接矩阵）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># in autokeras/graph.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_build_network</span>(<span class="hljs-params">self</span>):<br>    self._node_to_id = &#123;&#125;<br><span class="hljs-comment"># Recursively find all the interested nodes.</span><br>    <span class="hljs-keyword">for</span> input_node <span class="hljs-keyword">in</span> self.inputs:<br>        self._search_network(input_node, self.outputs, <span class="hljs-built_in">set</span>(), <span class="hljs-built_in">set</span>())<br>    self._nodes = <span class="hljs-built_in">sorted</span>(<br>        <span class="hljs-built_in">list</span>(self._node_to_id.keys()), key=<span class="hljs-keyword">lambda</span> x: self._node_to_id[x]<br>    )<br><br>    <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> self.inputs + self.outputs:<br>        <span class="hljs-keyword">if</span> node <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self._node_to_id:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Inputs and outputs not connected.&quot;</span>)<br><br>    <span class="hljs-comment"># Find the blocks.</span><br>    blocks = []<br>    <span class="hljs-keyword">for</span> input_node <span class="hljs-keyword">in</span> self._nodes:<br>        <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> input_node.out_blocks:<br>            <span class="hljs-keyword">if</span> (<br>                <span class="hljs-built_in">any</span>(<br>                    [<br>                        output_node <span class="hljs-keyword">in</span> self._node_to_id<br>                        <span class="hljs-keyword">for</span> output_node <span class="hljs-keyword">in</span> block.outputs<br>                    ]<br>                )<br>                <span class="hljs-keyword">and</span> block <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> blocks<br>            ):<br>                blocks.append(block)<br><br>    <span class="hljs-comment"># Check if all the inputs of the blocks are set as inputs.</span><br>    <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> blocks:<br>        <span class="hljs-keyword">for</span> input_node <span class="hljs-keyword">in</span> block.inputs:<br>            <span class="hljs-keyword">if</span> input_node <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self._node_to_id:<br>                <span class="hljs-keyword">raise</span> ValueError(<br>                    <span class="hljs-string">&quot;A required input is missing for HyperModel &quot;</span><br>                    <span class="hljs-string">&quot;&#123;name&#125;.&quot;</span>.<span class="hljs-built_in">format</span>(name=block.name)<br>                )<br><br>    <span class="hljs-comment"># Calculate the in degree of all the nodes</span><br>    in_degree = [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(self._nodes)<br>    <span class="hljs-keyword">for</span> node_id, node <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self._nodes):<br>        in_degree[node_id] = <span class="hljs-built_in">len</span>(<br>            [block <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> node.in_blocks <span class="hljs-keyword">if</span> block <span class="hljs-keyword">in</span> blocks]<br>        )<br><br>    <span class="hljs-comment"># Add the blocks in topological order.</span><br>    self.blocks = []<br>    self._block_to_id = &#123;&#125;<br>    <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(blocks) != <span class="hljs-number">0</span>:<br>        new_added = []<br><br>        <span class="hljs-comment"># Collect blocks with in degree 0.</span><br>        <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> blocks:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>([in_degree[self._node_to_id[node]] <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> block.inputs]):<br>                <span class="hljs-keyword">continue</span><br>            new_added.append(block)<br><br>        <span class="hljs-comment"># Remove the collected blocks from blocks.</span><br>        <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> new_added:<br>            blocks.remove(block)<br><br>        <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> new_added:<br>            <span class="hljs-comment"># Add the collected blocks to the Graph.</span><br>            self._add_block(block)<br><br>            <span class="hljs-comment"># Decrease the in degree of the output nodes.</span><br>            <span class="hljs-keyword">for</span> output_node <span class="hljs-keyword">in</span> block.outputs:<br>                output_node_id = self._node_to_id[output_node]<br>                in_degree[output_node_id] -= <span class="hljs-number">1</span>`<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Net2Net: Accelerating Learning Via Knowledge Transfer</title>
    <link href="/2024/05/26/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/"/>
    <url>/2024/05/26/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/</url>
    
    <content type="html"><![CDATA[<h2 id="Net2Net-Accelerating-Learning-Via-Knowledge-Transfer"><a href="#Net2Net-Accelerating-Learning-Via-Knowledge-Transfer" class="headerlink" title="Net2Net: Accelerating Learning Via Knowledge Transfer"></a>Net2Net: Accelerating Learning Via Knowledge Transfer</h2><p><img src="/../images/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/image-20240526135132205.png" alt="Net2Net"></p><blockquote><p>ICLR 2016</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>大型的深度神经网络的训练通常需要大量的计算资源和时间。随着模型需求增加（更深和更宽的网络），训练时间和资源也随之增加。于是作者给出了一种通过迁移学习来加速训练的方法。</p><p>传统的机器学习算法是接受一个固定的数据集作为输入，在不接受任何知识情况下初始化，并训练模型至收敛。但实际应用场景中，数据集往往是不断增长的，为避免过拟合和降低模型计算成本，一开始会选择小模型，之后需要一个大模型以充分利用大型数据集。而重新训练一个大的神经网络十分耗时，通过实验证明使用Net2Net操作初始化的模型比标准模型收敛得更快。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>Net2Net 包括两个主要的变换方法：Net2WiderNet 和 Net2DeeperNet。</p><h4 id="1-Net2WiderNet"><a href="#1-Net2WiderNet" class="headerlink" title="1.Net2WiderNet"></a>1.Net2WiderNet</h4><p>Net2WiderNet 的目标是将现有神经网络的层变宽，即增加每层的神经元数量，同时保持网络的功能不变。</p><h5 id="操作步骤："><a href="#操作步骤：" class="headerlink" title="操作步骤："></a>操作步骤：</h5><ol><li><strong>权重矩阵扩展</strong>：<ul><li>给定一个原始层的权重矩阵 $W$（维度为 $m \times n$，其中 $m$ 是输入神经元数量，$n$ 是输出神经元数量）。</li><li>生成一个新的更宽的权重矩阵 $W’$（维度为 $m \times n’$，其中 $n’ &gt; n$）。</li></ul></li><li><strong>权重复制与扰动</strong>：<ul><li>将原始的 $W$ 中的每一列复制到 $W’$ 的多列上。</li><li>对复制的列施加微小的随机扰动，确保新的输出节点不会完全相同，这样可以避免梯度消失或爆炸问题。</li></ul></li></ol><h5 id="数学表示："><a href="#数学表示：" class="headerlink" title="数学表示："></a>数学表示：</h5><p>假设原始的权重矩阵 $W$ 为： </p><p>$W&#x3D;[w_1,w_2,…,w_n]$</p><p>新的权重矩阵 $W’$ 通过复制和扰动生成：</p><p>$W’&#x3D;[w_1,w_1,w_2,w_2,…,w_n,w_n]+ϵ$</p><p>其中 $\epsilon$ 是一个微小的随机扰动矩阵。</p><p>偏置项扩展：类似地，对应的偏置项向量 $b$ 也进行扩展和复制。</p><p><img src="/../images/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/image-20240526150150706.png" alt="Net2WiderNet"></p><h5 id="目的："><a href="#目的：" class="headerlink" title="目的："></a>目的：</h5><ul><li>通过适当的权重复制和调整，新网络的输出可以保持与原始网络相同。</li><li>新的宽网络已经包含了原始网络的知识，无需从头开始训练，只需进行微调。</li></ul><h4 id="2-Net2DeeperNet"><a href="#2-Net2DeeperNet" class="headerlink" title="2. Net2DeeperNet"></a>2. Net2DeeperNet</h4><p>Net2DeeperNet 的目标是增加网络的深度，即在现有网络中增加新的层，同时保持网络的功能不变。</p><h5 id="操作步骤：-1"><a href="#操作步骤：-1" class="headerlink" title="操作步骤："></a>操作步骤：</h5><ol><li><strong>增加新层</strong>：<ul><li>在现有网络的某一层后增加一个新的层（可以是卷积层、全连接层等）。</li></ul></li><li><strong>恒等变换初始化</strong>：<ul><li>将新层的权重初始化为恒等变换，这样新层在初始时不会改变输入的数据。</li><li>对于全连接层，使用单位矩阵进行初始化： $W&#x3D;I$</li><li>对于卷积层，使用类似单位矩阵的滤波器进行初始化，即在中心位置设置为1，其余位置为0。</li></ul></li></ol><h5 id="数学表示：-1"><a href="#数学表示：-1" class="headerlink" title="数学表示："></a>数学表示：</h5><p>假设在现有网络的某一层 $h &#x3D; f(x)$ 后增加一个新层 $g$，新的网络输出应为： $h’&#x3D;g(f(x))$</p><p>初始化新层 $g$ 的权重使其为恒等变换： $g(h)&#x3D;h$</p><p>具体实现中，对于全连接层 $W &#x3D; I$，卷积层使用 $\delta$ 函数作为滤波器。</p><p><img src="/../images/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/image-20240526150221032.png" alt="Net2DeeperNet"></p><h5 id="目的：-1"><a href="#目的：-1" class="headerlink" title="目的："></a>目的：</h5><ul><li>新层在初始化时等效于一个恒等映射，不会改变网络的输出。</li><li>通过对新层的微调，可以逐渐引入新的表示能力，而不影响原有网络的性能。</li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/image-20240526151142874.png" alt="不同模型的训练率"></p><p><img src="/../images/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/image-20240526151210698.png" alt="不同模型的准确率"></p><p>Net2Net 算法在多个数据集和不同模型上进行了验证，结果表明：</p><ul><li>Net2WiderNet 和 Net2DeeperNet 能够显著加速模型的训练时间。</li><li>在扩展后的网络上，训练后的验证准确率与直接从头训练的模型相当，甚至更高。</li><li>Net2Net 方法在保持原有网络性能的前提下，有效地增加了网络的容量和复杂性。</li></ul><p>论文的主要贡献为：</p><ol><li><p>提出保留功能的初始化策略，有如下优点：</p><ul><li>新的大网络和原来的性能一样，不花费时间在之前低性能时期训练；</li><li>保证在初始化后的任何更改都是改进的，之前的方法可能无法在baseline上改进，因为对较大模型初始化后的更改恶化了性能</li><li>对网络中所有参数的优化都是“安全的”，从来没有哪个阶段某一层会接收到有害的梯度、需要冻结。这与级联相关（cascade correlation）等方法形成对比，后者将冻结旧单元，以避免在试图影响新的随机连接单元的行为时产生不良的适应性。</li></ul></li><li><p>提出Net2Net方法，在现有模型基础上加速新模型训练</p></li><li><p>应用于终身学习系统：</p><p>真实场景下的机器学习系统，最终都会变成<strong>终身学习系统</strong>(Lifelong learning system)，不断的有新数据，通过新的数据改善模型，刚开始数据量小，我们使用小的网络，可以防止过拟合并加快训练速度，但是随着数据量的增大，小网络就不足以完成复杂的问题了，这个时候我们就需要在小网络上进行扩展变成一个大网络了。</p><p>Net2Net操作使我们能够顺利地实例化一个大得多的模型，并立即开始在我们的终身学习系统中使用它，而不需要花费数周或数月的时间在最新的、最大版本的训练集上从头开始重新训练一个大模型。</p></li></ol><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>Net2Net 提供了一种简单而有效的方法，通过知识转移加速神经网络的训练过程。该方法能够帮助研究人员和工程师快速构建和训练更大规模的神经网络，减少计算资源和时间的消耗。Net2Net 算法具有广泛的应用前景，尤其是在需要频繁扩展和调整模型结构的深度学习研究和应用中。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
    <link href="/2024/05/25/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/"/>
    <url>/2024/05/25/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/</url>
    
    <content type="html"><![CDATA[<h2 id="Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift"><a href="#Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift" class="headerlink" title="Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"></a>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</h2><p><img src="/../images/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/image-20240525163201675.png" alt="BN"></p><blockquote><p>批量归一化：通过减少内部协变量偏移加速深度网络训练 <strong><a href="https://arxiv.org/abs/1502.03167"> arXiv:1502.03167</a></strong> ICML 2015</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>提到BN操作，一定会想到CNN，如果说之前各种Net是模型创新，那么本篇就是优化创新。BN是对CNN中间层feature map在激活函数前进行归一化操作，让他们的分布不至于那么散，这样的数据分布经过激活函数之后更加有效。</p><p>在整个网络的训练过程中，由于上一层网络参数的变化将导致输出层结果分布的改变，这就使得网络中每一层输入的分布均会发生改变，从而加大的网络的训练难度，这种变化会减缓训练速度，需要更小的学习率和更加复杂的参数初始化方法。</p><p>那么这个问题是如何产生的：<br>$$<br>\mathcal{L}&#x3D;F_2(F_1(u,\Theta_1),\Theta_2)\tag{1}<br>$$<br>其中$F_1$,$F_2$为任意的两个变换，u为原始的网络输出，$\Theta_1,\Theta_2$分别为两个网络层的参数。</p><p>现在我们的目的就是通过最小化$\mathcal{L}$来求得参数$\Theta_1,\Theta_2$的取值。此时，我们也可以将$F_2$的输入看成是$x&#x3D;F_1(u,\Theta_1)$，那么根据式子(1)我们就有：<br>$$<br>\mathcal{L}&#x3D;F_2(x,\Theta_2)\tag{2}<br>$$<br>接着根据式子(3)就可以完成$\Theta_2$的迭代求解：<br>$$<br>\Theta_2\leftarrow\Theta_2-\frac{\alpha}{m}\sum_{i&#x3D;1}^m\frac{\partial F_2(x_i,\Theta_2)}{\partial \Theta_2}\tag{3}<br>$$<br>但一个不争的事实就是，原始输入u的分布在经过网络层$F_1$之后会发生改变，而这也就意味着网络层$F_2$中的参数$\Theta_2$就需要再来学习输入值x的分布。也就是说，尽管你一开始对原始的输入u进行了标准化，但是再经历过一个网络层后它的分布就发生了改变，那么下一层又需要重新学习另外一种分布，这就意味着每一层其实都是在学习不同的分布。因此，作者将这种由于网络参数发生变化而引起分布发生改变的现象称为网络的Internal Covariate Shift(ICS)问题。</p><p>同时作者继续说到，尽管先前由于ISC导致的梯度消失问题能够通过ReLU激活函数、较小的学习率或者是反复的初始化来解决。但是，如果我们能够确保每一层网络输入的分布更稳定，那么这将会极大的提高网络的训练速度。</p><p>所以采用mini-batch的方式对每一层网络的输入进行标准化。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h4 id="1-对每个纬度进行标准化："><a href="#1-对每个纬度进行标准化：" class="headerlink" title="1.对每个纬度进行标准化："></a>1.对每个纬度进行标准化：</h4><p>假设现在有一个d维的网络层，其输出$x&#x3D;(x^{(1)},x^{(2)},…,x^{(d)})$，那么对于每一个维度，我们就可以通过如下公式来进行标准化：<br>$$<br>\hat{x}^{(k)}&#x3D;\frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}\tag{4}<br>$$<br>其中，期望$E[x^{(k)}]和方差Var[x^{(k)}]$都是在整个 数据集上计算得到的。</p><p>但是，作者又说到，如果仅仅只是简单通过公式(4)来对每个维度进行标准化，那么在某些情况下将会改变该维度原本的表示信息。</p><p>为了解决这一问题，作者在公式(4)的基础上，加入了一组可学习的参数$\gamma^{(k)}和\beta^{(k)}对\hat{x}^{(k)}$进行了一次线性变换：<br>$$<br>y^{(k)}&#x3D;\gamma^{(k)}\hat{x}^{(k)}+\beta^{(k)}\tag{5}<br>$$<br>其中$y^{(k)}$就是我们最后得到的标准化后的结果，而$\gamma^{(k)}和\beta^{(k)}$也会随着网络中的权重参数一起训练，当且仅当$\gamma^{(k)}&#x3D;\sqrt{Var[x^{(k)}]}，\beta^{(k)}&#x3D;E[x^{(k)}]$时，公式(5)就变成了恒等变换，也就相当于没有进行标准化（如果网络确实需要的话）。</p><h4 id="2-以mini-batch的方式进行标准化"><a href="#2-以mini-batch的方式进行标准化" class="headerlink" title="2.以mini-batch的方式进行标准化"></a>2.以mini-batch的方式进行标准化</h4><p>假设现在有一个大小为m的小批量数据$\mathcal{B}$，同时由于BN是<strong>独立地对每个神经元的输出值进行标准化，这意味着每个神经元都有自己独立的参数</strong>，因此我们这里以对第k个神经元$x^{(k)}$标准化为例进行介绍，并且进一步为了书写方便我们把k也暂时省略掉。此时，对于m个样本的输入，在第k个神经元就会有对应的m个输出：<br>$$<br>\mathcal{B}&#x3D;{x_{1,2,…,m}}\tag{6}<br>$$<br>接着，我们将标准化后的结果记为$\hat{x}<em>{1,2,…,m}$，线性变换后的结果为$y</em>{1,2,…,m}$，我么就可以将整个BN的过程表示为：<br>$$<br>BN_{\beta,\gamma}:x_{1,2,…,m}\rightarrow y_{1,2,…,m}\tag{7}<br>$$<br>具体的，对于整个BN的详细过程如图2所示：</p><p><img src="/../images/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/image-20240525175006453.png" alt="BN算法流程图"></p><p>其中$\mu_{\mathcal{B}}$为在小批量$\mathcal{B}上对x_i期望的估计，\sigma^2_{\mathcal{B}}$为对$x_i$方差的估计，而$\hat{x}<em>i$则表示标准化后的结果，$y_i$表示线性变换后的结果，也就是我们最后真正需要的结果。同时，为了防止方差为0的情况，在进行标准化时分母额外的加了一个很小的常数$\epsilon$。这里需要说明的是，$\mu</em>{\mathcal{B}}$和$\sigma^2_{\mathcal{B}}$并不是整个数据集真实的期望与方差，而仅仅只是根据采样mini-batch估计得到的。</p><p>就这样，每一层的每个神经元的输出值都将会经历过如图所示的处理，使得均值为0方差为1，然后再输出到下一层网络中。尽管在这一个过程中可能会导致不同神经元之间的联合分布发生变换，但是这却使得每一层网络的输入具有了同样的均值与方差，进而加速了网络的训练过程。</p><h4 id="3-BN的训练与预测"><a href="#3-BN的训练与预测" class="headerlink" title="3.BN的训练与预测"></a>3.BN的训练与预测</h4><p>BN中一共有五个参数：$\mu_{\mathcal{B}},\sigma^2_{\mathcal{B}},\epsilon,\gamma,\beta$，但是只有后两个参数才是随着网络一起训练，前两个参数是训练过程中用mini-batch中的样本估计得到的，用于对训练时的mini-bath进行标准化，而第三个参数则是自己预先设定的。前两个参数的预测时均值和方差应该只取决于整个输入的训练集。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="BN处处可导"><a href="#BN处处可导" class="headerlink" title="BN处处可导"></a>BN处处可导</h4><p>根据链式法则我们便能求得损失$\mathcal{L}$关于各个参数的梯度，其对应公式如下：</p><p>$$<br>\begin{aligned} \frac{\partial \mathcal{L}}{\partial \hat{x}<em>i}&amp;&#x3D;\frac{\partial \mathcal{L}}{\partial y_i}\cdot\gamma;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;(10)\[2ex] \frac{\partial \mathcal{L}}{\partial\sigma^2</em>{\mathcal{B}}}&amp;&#x3D;-\sum_{i&#x3D;1}^m\frac{\partial \mathcal{L}}{\partial \hat{x}<em>i}\cdot(x_i-\mu</em>{\mathcal{B}})\cdot\frac{1}{2}(\sigma^2_{\mathcal{B}}+\epsilon)^{-3&#x2F;2};;;(11)\[2ex] \frac{\partial \mathcal{L}}{\partial \mu_{\mathcal{B}}}&amp;&#x3D;\sum_{i&#x3D;1}^m\frac{\partial \mathcal{L}}{\partial \hat{x}<em>i}\cdot\frac{\partial \hat{x}<em>i}{\partial \mu</em>{\mathcal{B}}} &#x3D;\sum</em>{i&#x3D;1}^m\frac{\partial \mathcal{L}}{\partial \hat{x}<em>i}\left[\frac{\partial\hat{x}<em>i}{\partial\mu</em>{\mathcal{B}}}+\frac{\partial\hat{x}<em>i}{\partial\sigma^2</em>{\mathcal{B}}}\frac{\partial\sigma^2</em>{\mathcal{B}}}{\partial\mu_{\mathcal{B}}}\right];;;(12)\[2ex] &amp;&#x3D;-\left(\sum_{i&#x3D;1}^m\frac{\partial\mathcal{L}}{\partial\hat{x}<em>i}\cdot\frac{1}{\sqrt{\sigma^2</em>{\mathcal{B}}+\epsilon}}\right)-\frac{\partial\mathcal{L}}{\partial\sigma^2_{\mathcal{B}}}\frac{2}{m}\sum_{i&#x3D;1}^m(x_i-\mu_{\mathcal{B}})\[2ex] \frac{\partial \mathcal{L}}{\partial x_i}&amp;&#x3D;\frac{\partial \mathcal{L}}{\partial\mu_{B}}\cdot\frac{\partial\mu_{B}}{\partial x_i}+\frac{\partial \mathcal{L}}{\partial \hat{x}<em>{i}}\cdot\frac{\partial\hat{x}</em>{i}}{\partial x_i}+\frac{\partial \mathcal{L}}{\partial\sigma^2_{\mathcal{B}}}\cdot\frac{\partial\sigma^2_{\mathcal{B}}}{\partial x_i};;;;;;;;;;;;;(13)\[2ex] &amp;&#x3D;\frac{\partial \mathcal{L}}{\partial\mu_{B}}\cdot\frac{1}{m}+\frac{\partial \mathcal{L}}{\partial \hat{x}<em>{i}}\cdot\frac{1}{\sqrt{\sigma^2</em>{\mathcal{B}}+\epsilon}}+\frac{\partial \mathcal{L}}{\partial\sigma^2_{\mathcal{B}}}\cdot\frac{2(x_i-\mu_{\mathcal{B}})}{m}\[2ex] \frac{\partial \mathcal{L}}{\partial \gamma}&amp;&#x3D;\sum_{i&#x3D;1}^m\frac{\partial \mathcal{L}}{\partial y_i}\cdot\hat{x}<em>i ;,\frac{\partial \mathcal{L}}{\partial \beta}&#x3D;\sum</em>{i&#x3D;1}^m\frac{\partial \mathcal{L}}{\partial y_i};;;;;;;;;;;(14) \end{aligned} \<br>$$</p><p>整个BN过程都是可导的，因此这也就保证了网络模型能够正常的按照设想进行学习，进而可以加快网络的训练速度。</p><p>BN可以被用于网络中任意神经元的标准化。</p><p>在普通的前馈网络中BN是以每一个神经元为单位进行BN标准化，而在卷积中BN则是以每一个特征图为单位进行标准化。</p><p>本篇文章的主要贡献是：</p><ol><li><strong>减少内部协变量偏移</strong>：通过在每层对输入进行归一化，显著减少了内部协变量偏移，使得每层的输入分布更加稳定。</li><li><strong>加速训练</strong>：由于输入分布的稳定性，网络可以使用更高的学习率，收敛速度显著加快。</li><li><strong>简化参数初始化</strong>：减轻了对复杂参数初始化方法的依赖，使得网络训练更加鲁棒。</li><li><strong>正则化效果</strong>：由于在每个小批量上进行归一化，Batch Normalization在一定程度上起到了正则化的作用，有助于防止过拟合。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过引入Batch Normalization技术，有效减少了深度神经网络训练中的内部协变量偏移，显著加速了训练过程，并提高了模型的性能。Batch Normalization简单易用，效果显著，已成为深度学习模型训练中的标准技术。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Improving neural networks by preventing coadaptation of feature detectors</title>
    <link href="/2024/05/25/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/"/>
    <url>/2024/05/25/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/</url>
    
    <content type="html"><![CDATA[<h2 id="Improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors"><a href="#Improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors" class="headerlink" title="Improving neural networks by preventing co-adaptation of feature detectors"></a>Improving neural networks by preventing co-adaptation of feature detectors</h2><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525154637137.png" alt="TITLE"></p><blockquote><p>arXiv:1207.0580v1 2012 06</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>简而言之 Dropout 的提出，用于解决神经网络在训练过程中的过拟合问题，提升模型在测试集上的泛化能力。</p><p>Dropout 就是在每个训练步骤中，随机忽略（即“丢弃”）一部分神经元，使得网络不能依赖特定的神经元来进行特征检测，从而减少联合适应模式的发生。其原因就是神经网络中的神经元容易形成复杂的联合适应模式（co-adaptation），这种模式可能导致模型在训练数据上的表现很好，但在新数据上的表现较差。</p><p>过拟合已存在许久，之前也尝试过用诸如L2正则化、L1正则化等方式去解决这个问题，这些方法可以减少过拟合，但对于非常深的网络，其效果可能不如预期，或者增加大量的存储和计算成本。Dropout作为一种随机正则化技术，通过在训练过程中随机忽略一部分神经元，有效地防止了神经元之间的联合适应，显著提升了模型的泛化能力。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><ul><li>在每次前向传播过程中，对于每个神经元，以一定的概率$p$决定是否将其暂时移除（即设为0）。</li><li>在训练过程中，每次随机选择的被忽略神经元集不同。</li><li>在测试过程中，使用整个网络，但每个神经元的输出按训练中被忽略的概率$p$进行缩放，以反映训练时的期望输出。</li></ul><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525160239002.png" alt="MNIST数据集测试"></p><p>在MNIST数据集，什么都没有用在MNIST没有dropout时160个错误，50%的dropout得到130个错误，在输入加入20%的dropout得到110个错误。可以看到，输入一定量的dropout可以有效减少错误率。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>MINIST数据集</p><p>28*28的手写数字图像，10分类，6万训练集，1万测试集</p><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525161312218.png" alt="MINIST"></p><p>SVHN数据集</p><p>32*32*3的房子门牌号图像，识别房子门牌号，60万训练集，2万6测试集</p><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525161440070.png" alt="SVHN"></p><p>CIFAR-10&#x2F;CIFAR-100数据集</p><p>32*32*3的现实图像，10分类和100分类，5万训练集，1万测试集</p><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525161558748.png" alt="CIFAR"></p><p>ImageNet数据集</p><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525161650035.png" alt="Imagenet"></p><p>与其他正则化方法比较</p><p><img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525161723994.png" alt="正则化方法比较"></p><p>在多个数据集上的实验结果显示，使用Dropout的神经网络在分类任务中的错误率显著降低。Dropout已成为神经网络训练中常用的正则化技术，被广泛应用于各种深度学习模型中，如卷积神经网络（CNN）和循环神经网络（RNN）。</p><p>总而言之，本文的主要贡献为：</p><ol><li><strong>防止过拟合</strong>：通过Dropout，网络变得更加鲁棒，不容易过拟合训练数据，提升了在测试数据上的表现。</li><li><strong>提高泛化能力</strong>：Dropout通过减少神经元间的联合适应模式，使得网络对不同特征的依赖更加平均，从而提高了模型的泛化能力。</li><li><strong>简单有效</strong>：Dropout是一种简单但非常有效的正则化技术，不需要对网络结构进行复杂的修改。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过引入Dropout技术，有效防止了神经元间的过度联合适应，显著提升了神经网络的泛化能力和性能。Dropout的简单实现和显著效果，使其成为深度学习领域的重要技术。Dropout技术对深度学习的研究和应用产生了深远的影响，推动了更鲁棒、更高效的神经网络模型的发展。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>1-基础部分-4-常用英文</title>
    <link href="/2024/05/25/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-4-%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/"/>
    <url>/2024/05/25/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-4-%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/</url>
    
    <content type="html"><![CDATA[<table><thead><tr><th>英文</th><th>翻译</th></tr></thead><tbody><tr><td><strong>review</strong></td><td>总结；综述</td></tr><tr><td><strong>high-resolution</strong></td><td>高分辨率</td></tr><tr><td><strong>top-1 error rate</strong></td><td>top1错误率，即分类预测的最大可能结果不是正确标签的概率</td></tr><tr><td><strong>top-5 error rate</strong></td><td>top5错误率，即分类预测的前5个可能结果都不是正确标签的概率</td></tr><tr><td><strong>neuron</strong></td><td>神经元</td></tr><tr><td><strong>non-saturating</strong></td><td>非饱和的</td></tr><tr><td><strong>object recognition</strong></td><td>目标识别&#x2F;对象检测</td></tr><tr><td><strong>label-preserving transformations</strong></td><td>标签保留转换，一种数据增强从而减少过拟合的方式</td></tr><tr><td><strong>feedforward neural network</strong></td><td>前馈神经网络</td></tr><tr><td><strong>down-sampled</strong></td><td>下采样</td></tr><tr><td><strong>rescaled</strong></td><td>重新调整图像大小</td></tr><tr><td><strong>nonlinearity</strong></td><td>非线性单元</td></tr><tr><td><strong>gradient descent</strong></td><td>梯度下降</td></tr><tr><td><strong>stochastic gradient descent (SGD)</strong></td><td>随机梯度下降法</td></tr><tr><td><strong>Rectified Linear Units (ReLUs)</strong></td><td>修正线性单元</td></tr><tr><td><strong>iteration</strong></td><td>迭代</td></tr><tr><td><strong>cross-GPU parallelization</strong></td><td>跨GPU并行化操作</td></tr><tr><td><strong>local response normalization</strong></td><td>局部响应归一化</td></tr><tr><td><strong>generalization</strong></td><td>泛化</td></tr><tr><td><strong>activity</strong></td><td>激活值</td></tr><tr><td><strong>overlapping pooling</strong></td><td>重叠池化，即移动步长小于核尺寸</td></tr><tr><td><strong>data augmentation</strong></td><td>数据增强</td></tr><tr><td><strong>weight decay</strong></td><td>权重衰减</td></tr><tr><td><strong>fine-tuning</strong></td><td>微调（网络）</td></tr><tr><td><strong>Euclidean distance</strong></td><td>欧几里得距离&#x2F;欧氏距离</td></tr><tr><td><strong>restricted</strong></td><td>受限的</td></tr><tr><td><strong>component</strong></td><td>成分；组成部分；组件、元件</td></tr><tr><td><strong>unit variance</strong></td><td>方差为1、单位方差</td></tr><tr><td><strong>retrieval</strong></td><td>检索</td></tr><tr><td><strong>reconstruction</strong></td><td>重构、重建</td></tr></tbody></table><table><thead><tr><th>英文</th><th>翻译</th></tr></thead><tbody><tr><td>shortcut connections</td><td>快捷连接</td></tr><tr><td>identity mappings</td><td>恒等映射</td></tr><tr><td>degradation</td><td>网络训练退化</td></tr><tr><td>projection mappings</td><td>投影映射</td></tr><tr><td>Deeper Bottleneck Architectures</td><td>深度瓶颈架构</td></tr><tr><td>Residual Learning</td><td>残差学习</td></tr><tr><td>vanishing&#x2F;exploding gradients</td><td>梯度消失&#x2F;发散</td></tr></tbody></table><table><thead><tr><th>英文</th><th>中文</th></tr></thead><tbody><tr><td>embedded computing</td><td>嵌入式计算</td></tr><tr><td>sparsity</td><td>稀疏性</td></tr><tr><td>sparse matrix&#x2F;matrices</td><td>稀疏矩阵</td></tr><tr><td>dense matrix&#x2F;matrices</td><td>密集矩阵</td></tr><tr><td>ensemble</td><td>组合</td></tr><tr><td>reduction&#x2F;projection layers</td><td>降维&#x2F;投影层</td></tr><tr><td>auxiliary classifier</td><td>辅助分类器</td></tr><tr><td>data-parallelism</td><td>数据并行</td></tr><tr><td>asynchronous stochastic gradient descent</td><td>异步随机梯度下降法</td></tr><tr><td>ground truth</td><td>实际结果</td></tr><tr><td>bounding box</td><td>边界框</td></tr><tr><td>false positive</td><td>假阳性</td></tr><tr><td>mean average precision (mAP)</td><td>平均精度均值</td></tr><tr><td>object bounding box recall</td><td>目标边界框召回率</td></tr><tr><td>bounding box regression</td><td>边界框回归</td></tr><tr><td>contextual model</td><td>上下文模型</td></tr></tbody></table><table><thead><tr><th>英文</th><th>中文&#x2F;解释</th></tr></thead><tbody><tr><td>adaptive moment estimation</td><td>自适应矩估计：基于不同阶数矩阵来适应不同参数的学习速率</td></tr><tr><td>sparse features&#x2F;gradients</td><td>稀疏特征&#x2F;稀疏梯度</td></tr><tr><td>exponential moving average</td><td>指数移动平均数</td></tr><tr><td>initialization bias correction</td><td>初始偏差修正</td></tr><tr><td>over-fitting</td><td>过拟合</td></tr><tr><td>robust,robustness</td><td>稳健性&#x2F;鲁棒性：一个系统或组织有抵御或克服不利条件的能力</td></tr><tr><td>normalization</td><td>规范化&#x2F;归一化&#x2F;标准化</td></tr></tbody></table><table><thead><tr><th>英文</th><th>中文释义</th></tr></thead><tbody><tr><td>regularizer</td><td>正则化项</td></tr><tr><td>internal covariate shift</td><td>内部协变量转移</td></tr><tr><td>stochastic gradient descent(SGD)</td><td>随机梯度下降法</td></tr><tr><td>convergence</td><td>收敛</td></tr><tr><td>differentiable</td><td>可微的</td></tr><tr><td>element-wise</td><td>逐元素地</td></tr><tr><td>nonlinearity</td><td>非线性</td></tr><tr><td>benchmark</td><td>基准</td></tr></tbody></table><table><thead><tr><th>英文</th><th>翻译</th></tr></thead><tbody><tr><td><strong>prohibitively</strong></td><td>静止地；过高地；过分地</td></tr><tr><td><strong>exponentially</strong></td><td>以指数方式</td></tr><tr><td><strong>robust</strong></td><td>健壮的，鲁棒</td></tr><tr><td><strong>conspiracy</strong></td><td>阴谋</td></tr><tr><td><strong>max-norm constraint</strong></td><td>最大范式约束</td></tr><tr><td><strong>Salient</strong></td><td>突出</td></tr><tr><td><strong>co-adaptation</strong></td><td>共适性</td></tr><tr><td><strong>marginalization</strong></td><td>边缘化</td></tr><tr><td><strong>inverted</strong></td><td>倒</td></tr><tr><td><strong>deterministic counterpart</strong></td><td>原图</td></tr><tr><td><strong>adversary</strong></td><td>对手</td></tr><tr><td><strong>Monte-Carlo</strong></td><td>蒙特卡罗</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>基础部分</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Going Deeper with Convolutions</title>
    <link href="/2024/05/24/0-Going-Deeper-with-Convolutions/"/>
    <url>/2024/05/24/0-Going-Deeper-with-Convolutions/</url>
    
    <content type="html"><![CDATA[<h2 id="Going-Deeper-with-Convolutions"><a href="#Going-Deeper-with-Convolutions" class="headerlink" title="Going Deeper with Convolutions"></a>Going Deeper with Convolutions</h2><p><img src="/../images/0-Going-Deeper-with-Convolutions/image-20240524144235051.png" alt="GoogLeNet"></p><blockquote><p>GoogLeNet CVPR2015</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在大规模图像识别挑战赛2014上，仅用AlexNet $\frac{1}{12}$ 的参数，就有比其更好的准确率。提出了名为“Inception”的网络架构（也称Inception v1），提高网络内部计算资源的利用率，增加网络深度和广度并保持计算预算不变。同时考虑到了移动与嵌入式设备的应用（减少算力和内存的消耗），增强实际工程的应用。</p><p>相关工作中作者提到了CNN的传统结构$（卷积+Normalization+max pooling）× n + 全连接层 × m$ 用于进行定位和目标检测，但是容易出现过拟合的现象，所以作者使用了稀疏连接（将全连接层换为稀疏的全连接层甚至是卷积层。稀疏连接可以要求更多的复杂计算，可能导致计算效率十分底下，所以需要一种方法，即能保持网络的稀疏性又能利用密集矩阵的高计算性能，所以作者提出来Inception结构。</p><h3 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h3><h4 id="1-Inception模块的设计"><a href="#1-Inception模块的设计" class="headerlink" title="1.Inception模块的设计"></a>1.Inception模块的设计</h4><p>Inception模块的核心思想是通过并行化不同大小的卷积核和池化层来捕捉输入特征的多尺度信息。具体来说，每个Inception模块包括以下几种操作：</p><ol><li><strong>1x1卷积</strong>：用于降维和增加网络的非线性能力。</li><li><strong>3x3卷积</strong>：捕捉中等范围的空间特征。</li><li><strong>5x5卷积</strong>：捕捉更大范围的空间特征。</li><li><strong>3x3最大池化</strong>：提供某种形式的下采样，同时保持局部特征不变。</li></ol><p><img src="/../images/0-Going-Deeper-with-Convolutions/image-20240525142343170.png" alt="Inception模块设计"></p><p>直接应用上述不同大小的卷积核和池化操作会导致计算量急剧增加。为了应对这一挑战，Inception模块通过：</p><ol><li><strong>1x1卷积用于降维</strong>：在应用3x3和5x5卷积之前，首先使用1x1卷积对输入进行降维。这一步骤显著减少了输入通道数，从而降低了后续卷积操作的计算量。这种做法不仅降低了计算复杂度，还通过增加非线性变换提升了模型的表达能力。</li><li><strong>并行计算与合并</strong>：Inception模块通过并行执行不同的卷积和池化操作，然后将这些操作的输出在通道维度上合并。这种并行设计允许网络在相同层次上捕捉到不同尺度的特征，而不会显著增加计算复杂度。</li></ol><p>用来实现高效计算。</p><p><img src="/../images/0-Going-Deeper-with-Convolutions/image-20240525142420927.png" alt="1x1卷积核降维"></p><h4 id="2-GoogleNet的网络结构"><a href="#2-GoogleNet的网络结构" class="headerlink" title="2.GoogleNet的网络结构"></a>2.GoogleNet的网络结构</h4><p>Inception架构师GoogleNet中的基本构建模块，由多个Inception模块堆叠而成，每个模块通过执行大小不同的卷积和池化操作来捕捉输入特征的多尺度信息。Inception模块的设计思想是通过1x1卷积进行降维，减少计算复杂度，同时增加网络的非线性和表达能力。通过这种方式，GoogleNet在保持计算效率的同时，显著增加了网络深度。GoogleNet在其结构中使用了22层（如果计算参数层则更深），其中包含了多个Inception模块。每个Inception模块都独立执行一组并行的卷积和池化操作，并将结果在通道维度上合并。</p><ul><li><strong>初始层</strong>：GoogleNet的初始层由几个标准的卷积层和池化层组成，用于初步提取输入图像的低级特征。</li><li><strong>Inception模块堆叠</strong>：在初始层之后，GoogleNet由多个Inception模块堆叠组成。这些模块并行执行不同大小的卷积和池化操作，捕捉不同尺度的特征，然后将结果合并。</li><li><strong>全局平均池化</strong>：在最后的几层，GoogleNet使用全局平均池化层取代了传统的全连接层，这样不仅减少了参数数量，还降低了过拟合的风险。</li><li><strong>分类层</strong>：最后，GoogleNet使用一个Softmax分类器输出预测结果。</li></ul><p><img src="/../images/0-Going-Deeper-with-Convolutions/image-20240525143716959.png" alt="GoogleNet网络架构"></p><h4 id="3-模型训练"><a href="#3-模型训练" class="headerlink" title="3.模型训练"></a>3.模型训练</h4><p>训练过程中对于数据集（ILSVRC2014）的增强方法也是这篇论文贡献的IDEA。</p><ul><li>独立训练了7个版本的相同的GoogLeNet模型，并用它们进行了整体预测。这些模型的训练具有相同的初始化和学习率策略，仅在采样方法和随机输入图像顺序方面不同。</li><li>在测试中，采用更激进的裁剪方法。<br>具体来说，我们将图像归一化为四个尺度，其中较短维度（高度或宽度）分别为256，288，320和352，取这些归一化的图像的左，中，右方块（在肖像图片中，我们采用顶部，中心和底部方块）。对于每个方块，我们将采用4个角以及中心224×224裁剪图像以及方块尺寸归一化为224×224，以及它们的镜像版本。这导致每张图像会得到4×3×6×2 &#x3D; 144的裁剪图像。<br>在实际应用中，这种激进的裁剪可能是不必要的，因为存在合理数量的裁剪图像后，更多裁剪图像的好处会变得很微小。</li><li>softmax概率在多个裁剪图像上和所有单个分类器上进行平均，然后获得最终预测。<br>分析了验证数据的替代方法，例如裁剪图像上的最大池化和分类器的平均，但是它们比简单平均的性能略逊。</li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Going-Deeper-with-Convolutions/image-20240525144636980.png" alt="分类任务"></p><p><img src="/../images/0-Going-Deeper-with-Convolutions/image-20240525144725901.png" alt="检测任务"></p><p>ImageNet大规模视觉识别挑战赛（ILSVRC 2014）GoogleNet（Inception V1)在比赛中取得了最佳成绩，展示了其卓越的性能和高效的计算能力。GoogleNet在当年的分类和检测任务都取得了很好的结果。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作者通过引入Inception架构，在深度和计算效率之间找到了一个平衡点，显著提升了卷积神经网络的性能。其创新性的设计和方法对深度学习领域产生了重要影响。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>0-SimCSE: Simple Contrastive Learning of Sentence Embeddings</title>
    <link href="/2024/05/24/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/"/>
    <url>/2024/05/24/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/</url>
    
    <content type="html"><![CDATA[<h2 id="SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings"><a href="#SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings" class="headerlink" title="SimCSE: Simple Contrastive Learning of Sentence Embeddings"></a>SimCSE: Simple Contrastive Learning of Sentence Embeddings</h2><h2 id=""><a href="#" class="headerlink" title=""></a><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506182339276.png" alt="SimCSE"></h2><blockquote><p>SimCSE：对比学习句向量表示 发布于EMNLP 2021</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><strong>Embedding</strong>是指将高维度的数据（例如文字、图片、音频）映射到低维度空间的过程。Embedding向量是包含语义信息的。也就是含义相近的单词，Embedding向量在空间中有相似的位置。Embedding是数据科学工具包中至关重要的部分，已经广泛应用于各种不同领域的生产级机器学习系统，包括自然语言处理、推荐系统和计算机视觉等</p><p><strong>Dropout</strong>：Dropout是一种用于减少神经网络过拟合的正则化技术。在训练过程中，dropout会随机地将神经元的输出置为零，这样可以防止网络对特定的输入特征过度依赖，从而提高了模型的泛化能力。在SimCSE中，dropout被用作一种噪声注入的手段，用于生成不同的句子表示，从而帮助模型学习更加鲁棒和具有表征能力的句子嵌入。</p><p>**Simple Contrastive Learning of Sentence Embeddings(SimCSE)**：一种简单的对比学习框架，用于学习句子表示。SimCSE提出了无监督和监督两种方法来学习句子表示。在无监督方法中，SimCSE利用对比学习的方式，通过预测输入句子本身来学习句子表示。而在监督方法中，SimCSE利用自然语言推理数据集中的标注句对来训练模型，以进一步提高句子表示的性能。SimCSE的方法简单而高效，在语义文本相似性任务上取得了令人满意的性能表现。</p><p>   SimCSE这个对比学习框架，它可以通过预测输入句子本身来学习句子表示。例如，对于输入句子”The cat is sleeping on the mat.”，SimCSE会使用标准的dropout噪声来生成两个不同的嵌入向量，然后将其他句子作为“负样本”，并让模型预测哪个嵌入向量是“正样本”。这个过程可以在无标注数据上进行，因此是一种无监督的方法。SimCSE的监督方法则利用自然语言推理数据集中的标注句对来训练模型。例如，对于一个标注句对”The cat is sleeping on the mat.”和”The feline is resting on the mat.”，SimCSE会将它们的嵌入向量作为“正样本”，并将其他句子的嵌入向量作为“负样本”，从而训练模型。</p><p><strong>对比学习</strong>：对比学习的两个优化目标:</p><p>1.正例之间表示保持较近的距离;</p><p>2.随机样例的表示应分散在超平面上。并且这两个目标分别可以用指标alignment和uniformity来衡量。</p><p>样本对数据 D ，X_i和X_i^+是一对相似样本对。训练目标函数为</p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506182601761.png" alt="目标函数"></p><p><strong>正样本</strong>:构造(X_i,X_i^+)样本对。在CV领域可通过裁剪、翻转等方法很容易构建，在NLP领域则很难构造语义一致的样本。比较常见的是通过数据增强来构造，如同义词的替换，删除某个或某些不重要的词等，但这些方法很容易引入噪声，致使模型的效果提升有限。</p><p><strong>alignment</strong>和<strong>uniformity</strong>:alignment是正样本 （x_i,x_i^+）的平均距离. （对齐性）越小越好</p><p>uniformity计算向量整体分布的均匀程度，越均匀，保留的信息越多。 （均匀性） 越小越好</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><strong>无监督</strong>SimCSE：</p><p>无监督SimCSE的工作原理，它使用对比学习的方法，通过预测输入句子本身来学习句子表示。使用不同的隐藏层dropout掩码来生成不同的句子表示，并将它们与同一批次中的其他句子表示进行比较，以学习更好的句子表示。 </p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506182827852.png" alt="无监督"></p><p>一般来说，我们会使用一些数据扩增手段，让正例的两个样本有所差异，但是在 NLP 中如何做数据扩增本身也是一个问题，SimCSE 提出了一个极为简单优雅的方案：直接把 Dropout 当做数据扩增！</p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506182856730.png" alt="Dropout 当做数据扩增"></p><p><strong>有监督</strong>SimCSE：</p><p>监督SimCSE的工作原理，它利用自然语言推理数据集（NLI数据集）中的标注句对来训练模型，以进一步提高句子表示的性能。使用自然语言推理数据，以学习更好的句子表示。</p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506182928868.png" alt="有监督SimCSE"></p><p><strong>SimCSE</strong>的各向异性（Anisotropy）：</p><p>各向异性，又叫做表征退化问题，表示词嵌入在向量空间中占据了一个狭窄的圆锥体。与各向异性对应的是各向同性，指的是数据的分布在各个方向都一样，如图5。SimCSE论文中讨论的各向异性是和我们前面的均匀性类似的概念。目前缓解模型坍塌的策略消除主成分，加入正则项以及将各向异性映射为各向同性等等。SimCSE则证明了对比学习的训练目标可以降低模型的各向异性。</p><p>在SimCSE中，作者表明，对比目标还可以通过提高嵌入空间的均匀性来缓解各向异性问题。他们从奇异谱的角度证明了对比学习目标“平坦”了句子嵌入空间的奇异值分布，从而提高了一致性。这是通过将对比学习目标中的负面事例分开来实现的。因此，SimCSE为语言表征中的各向异性问题提供了一种新的解决方案。</p><p>对比学习能平缓奇异值的分布。</p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506183000010.png" alt="各向异性"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>Sentence embedding performance on STS tasks</p><p>语义文本相似性</p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506183047519.png" alt="语义文本相似性"></p><p><strong>alignment</strong>和<strong>uniformity</strong>对比其他方法，可以看出SimCSE在alignment和uniformity两个方面均要好于BERT算法。</p><p><img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506183056349.png" alt="实验结果"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​SimCSE是一个原理并不复杂的算法，它提出了使用Dropout构建正样本对这个简单易行的方案，解决了模型预训练过程中容易出现的模型坍塌的问题。Sim-CSE非常简单但效果非常好，其背后的数学原理是引入深思的。SimCSE一文对对比学习之后的数学原理进行了深入的探讨。证明了对比学习的损失函数是具有同时优化对齐性和均匀性这两个方向的。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Knowledge Mining with Scene Text for Fine-Grained Recognition</title>
    <link href="/2024/05/24/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/"/>
    <url>/2024/05/24/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/</url>
    
    <content type="html"><![CDATA[<h2 id="Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition"><a href="#Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition" class="headerlink" title="Knowledge Mining with Scene Text for Fine-Grained Recognition"></a><strong>Knowledge Mining with Scene Text for Fine-Grained Recognition</strong></h2><p><img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624151929402.png" alt="Knowledge Mining with Scene Text for Fine-Grained Recognition"></p><blockquote><p>基于场景文字知识挖掘的细粒度图像识别算法 CVPR 2022</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><strong>场景文字的识别：</strong>和文档文本不同，场景文字具有稀疏性，通常以少许关键词的形式存在于自然环境中。通过稀疏的关键词，机器难以获取精准的语义。然而，人类能够较为充分地理解稀疏的场景文字。原因在于，人类具有大量的外部知识库，能够通过知识库来弥补稀疏的场景文字所带来的语义损失。</p><p><img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/image-20240506184438727.png" alt="Bottle 数据集中的案例，3 张图像均属于 soda 类别"></p><p>如图所示：</p><p>​该数据集是关于细粒度图像分类任务，旨在区分图像中的瓶子属于哪种饮品或。图中 3 张图像均属于 soda 类饮品，尽管案例（c）同样属于 soda 类饮品，但是其附属的场景文本的表面信息无法提供明显的线索。场景文字在 百科 中的描述，百科 告知我们，场景文本 leninade 代表某种品牌，其属于 soda 类饮品。因此，挖掘场景文本背后丰富的语义信息能够进一步弥补场景文本的语义损失，从而更为准确地理解图像中的目标。</p><p><strong>Fine-Grained Image Classification</strong>（细粒度图像分类）：区分某些领域中物体类别之间具有细微视觉差异的图像。</p><p>   1.仅使用视觉线索对对象进行分类，并旨在找到有区别的图像路径。</p><p>   2.通过使用场景文本的视觉线索来利用场景文本进行细粒度图像分类任务。</p><p>   3.利用场景文本的文本线索作为判别信号，并结合GoogLeNet获得的视觉特征来区分商业场所。</p><p>尽管取得了有希望的进展，但现有的方法利用了场景文本的字面意义，而忽略了有意义的人类的文本知识。</p><p>**Knowledge-aware Language Models(<strong>知识感知语言模型</strong>)**：预训练语言模型经过优化，可以预测给定序列中的下一个单词或一些屏蔽单词。这种知识通常是从预训练模型生成的潜在上下文表示中获得的，或者通过使用预训练模型的参数来初始化特定于任务的模型以进行进一步微调来获得。</p><p>   在论文的方法中，采用 BERT 和 KnowBert 作为知识感知语言模型，并应用它们来提取知识特征。尽管以前的方法从视觉语言任务的句子中提取知识特征，但它们需要图像文本对的注释。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>算法框架：</p><p><img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/image-20240506184601627.png" alt="image-20240506184601627"></p><p>算法框架图，由视觉特征分支、知识提取分支和知识增强分支、视觉-知识注意力模块（VKAC）和分类器构成。</p><p>网络框架由视觉特征分支、知识提取分支和知识增强分支、视觉-知识注意力模块和分类器构成。算法输入包括 3 部分：图像，图像中包含的场景文本实例，外部知识库。其中场景文本实例通过已有的文字识别器从输入图像中获取，外部知识库采用了 Wikipedia。知识提取分支提取场景文本实例背后的语义信息（知识特征），知识增强分支融合场景文本实例和挖掘出的知识特征。随后，视觉-知识注意力模块融合视觉和知识特征，并将其输入给分类器进行分类。</p><p><strong>知识提取分支</strong>：该分支由实体候选选择器和实体编码器构成。实体候选选择器预先在大量语料库上统计单词在所有可能实体上的概率分布，根据概率分布选取前 10 个候选实体，并将其输入给实体编码器进行特征编码。实体编码器在 Wikipedia 的数据库上进行预训练，预训练任务旨在通过 Wikipedia 上实体的描述来预测该页面的标题（实体名称）。</p><p><strong>知识增强特征分支</strong>：该分支主要由 bert 构成，在 bert 的第 10 层后插入知识注意力模块（KARC），该模块融合了文本实例特征和知识特征后，接着输入给 bert 剩余的层。Bert 第 12 层输出的特征给 VKAC 模块。</p><p><strong>视觉</strong>-知识注意力模块：并非所有的场景文本或知识对理解图像有积极作用，为选取和图像内容相关的场景文本和知识来加强对图像的理解。该模块以图像全局特征作为访问特征，从增强的知识特征中选取相关的知识特征来加强视觉特征。其网络结构由注意力模型构成。</p><p><img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/image-20240506184654534.png" alt="image-20240506184654534"></p><p>通过在BERT模型中的特定层(第十层)插入一个KARC（knowledge attention and recontextualization component）</p><p>•将一个单词序列输入到BERT中10层连续的编码层，得到语境 Hi</p><p>•将 Hi ，knowledge extraction得到的entity embedding输入到KARC中，输出知识增强的text representation Hi ’</p><p>•将 Hi ‘输入到BERT中剩余的编码层，并获得最终的知识增强的特征，输送给下一子模型(<em>Visual-knowledge attention component</em> )。</p><p><strong>注意力机制</strong>：</p><p>主要目标：将注意力放在和场景内容有较强相关的文字上，忽略和场景关系不大的文字。</p><p> 方法：提取全局的视觉特征，将视觉特征和提取到的知识特征做对比，选取相似度高的视觉特征（注意力机制）。</p><p>  为研究场景文本背后的知识对图像识别的帮助，收集了一个关于人群活动的数据集。该数据集中的类别主要分为游行示威和日常人群密集活动两大类，细分为 21 类。</p><p><img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/image-20240506184732594.png" alt="image-20240506184732594"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/image-20240506184743920.png" alt="image-20240506184743920"></p><p><strong>和</strong> <strong>SOTA</strong> <strong>对比：</strong>在公开数据集 Con-Text、Bottles 以及我们收集的 Activity 数据集上，在使用 resnet50[3]和 E2E-MLT[4]作为视觉特征提取器和文字提取器时，我们方法能在同等情况下取得最佳结果。当使用 ViT 和 Google OCR 时，其模型性能结果能进一步提升。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​本文提出了一种通过挖掘场景文本背后语义来增强分类模型理解图像内容的方法，该方法的核心是利用场景文字作为关键词，到 wikipedia 知识库中检索出相关的知识，并获取其特征表达，和图像视觉特征进行融合理解，而并非仅仅利用场景文字的表面语义信息。得益于挖掘场景文本背后的知识，该方法能够更好地理解文字语义并不非常直观的内容。实验表明，该方法在 3 个数据集上均取得了最佳结果。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Instance and Panoptic Segmentation Using Conditional Convolutions</title>
    <link href="/2024/05/24/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/"/>
    <url>/2024/05/24/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/</url>
    
    <content type="html"><![CDATA[<h2 id="Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions"><a href="#Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions" class="headerlink" title="Instance and Panoptic Segmentation Using Conditional Convolutions"></a>Instance and Panoptic Segmentation Using Conditional Convolutions</h2><p><img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240506183518983.png" alt="Instance and Panoptic Segmentation Using Conditional Convolutions"></p><blockquote><p>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 45, NO. 1, JANUARY 2023</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>​作者提出了一种实例和全景分割框架,其在COCO数据集上的表现优于其他几种最先进的方法,这种实例和全景分割框架称为”Condlnst(实例分割和条件卷积)”.</p><p>​实例分割和全景分割是计算机视觉中的重要任务，需要算法对图像中的每个感兴趣实例进行像素级的分割，并为图像中的每个像素分配语义标签。全景分割在实例分割框架的基础上进一步要求对场景中的“stuff”进行分割，为图像中的每个像素分配语义标签。实例分割和全景分割面临着一个共同的挑战，即如何高效有效地区分个体实例。传统的方法通常采用Mask R-CNN等两阶段方法，通过ROI操作来关注每个实例，但这种方法存在一些缺点，如需要更大的计算量、固定的掩模头等。作者提出的Condlnst 框架，通过将实例分割和全景分割统一为完全卷积网络，消除了ROI裁剪和特征对齐的需要,由于动态生成的条件卷积容量大大提高，掩模头可以非常紧凑，从而大大加快每个实例的推理时间，在实例和全景分割任务上实现了最先进的性能，同时速度快且简单。</p><p><img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240504165817465.png" alt="Condlnst动态生成过滤器,每个输出映射只包含一个实例的掩码."></p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p>Condlnst用于实例分割的整体架构:通过使用实例敏感的卷积滤波器和相对坐标来动态生成掩模头，实现了对每个实例的关注。与传统的固定权重掩模头不同，Condlnst的掩模头参数根据要预测的实例进行调整，使得网络参数能够编码实例的特征，并且只在该实例的像素上激活，从而绕过了标准FCN中的困难。</p><p><img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240504170419450.png" alt="CondInst整体框架"></p><p>Condlnst结构可以分为四个主要部分:</p><ol><li>**特征提取网络:**负责从输入图像中提取多尺度的特征图。这些特征图通常具有深度学习中的层级结构，表现为从浅层到深层的不同抽象级别。</li><li><strong>特征金字塔网络:</strong> 特征金字塔网络是一种受人体视觉启发的结构，能够将高层次的语义信息与低层次的细节信息结合起来，产生一系列尺度的特征图，这对于检测不同尺寸的对象非常有用。</li><li><strong>CondInst:</strong> 在这一模块，网络通过一组称作“head”的子网络来进行实际的实例分割。这些头部分别负责预测类别得分，边界框回归，以及产生实例分辨率的特定掩膜。掩膜生成是实例分割的核心，需要精准地为每个检测到的物体实例生成一个像素级的掩膜。</li><li><strong>输出和后处理：</strong> 最后，网络结合来自头部网络的预测结果，并通过逐像素的分类来生成最终的实例分割掩膜。</li></ol><p>​    以对实例分割掩码、类别预测和边界框预测进行监督学习为训练目标，使网络能够准确地预测每个物体实例的位置、类别和掩码。</p><p><strong>模型细节:</strong></p><p>​实验使用了的MS COCO和Cityscapes数据集进行训练和评估。</p><p>​在训练过程中，作者采用了多尺度数据增强策略，以提高模型的泛化能力。</p><p>​基准掩码头采用了三个1x1卷积层，每个卷积层有8个通道，并使用ReLU作为激活函数，最后一层使用sigmoid函数预测前景的概率。</p><p>​掩码头总共有169个参数，非常轻量级，相比Mask R-CNN等模型，计算复杂度大大降低。</p><p>​改变底部分支输出特征图的通道数（C_bottom），实验结果表明，在合理范围内（从2到16），性能基本保持稳定。</p><p>​生成的动态滤波器可以被视为轮廓的表示，与Mask R-CNN不同，Condlnst通过生成的滤波器编码实例的轮廓，因此可以轻松表示包括不规则形状在内的各种形状，更加灵活。</p><p>​作者建议在Condlnst模型中使用<strong>上采样因子</strong>为2，因为这种设置在各项指标上表现较好。</p><p>​在推断过程中去除边界框分支并使用基于掩码的NMS(非极大值抑制)，可以获得与基于边界框的NMS相似的性能。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240504173341240.png" alt="与先前最先进方法的比较"></p><p>​结果显示，Condlnst在1次学习率计划（90K迭代）下的性能优于原始的Mask R-CNN，并且比原始Mask R-CNN更快（每张图像在单个V100 GPU上）。</p><p>​Condlnst还在性能上优于Detectron2中的Mask R-CNN。</p><p>​通过更长的训练计划或更强大的骨干网络，如ResNet-101，也可以实现一致的改进。</p><p>​通过辅助语义分割任务，Condlnst的性能可以从37.7%提升到38.6%（ResNet-50），或从39.1%提升到40.0%（ResNet-101），而推理时间不增加。</p><p><img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240504173634513.png" alt="实时CondInst模型在COCO测试开发数据上的Mask AP和推理速度"></p><p>​实验结果表明，基于ResNet-50的Condlnst-RT在AP方面优于YOLACT++，并且几乎具有相同的推理速度。</p><p>​使用更强大的骨干网络DLA-34，CondInst-RT可以实现47 FPS的速度，并保持类似的性能水平。</p><p><img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240504173851199.png" alt="Cityscapes数据集上进行实例分割的实验"></p><p>​在Cityscapes数据集上，作者使用COCO风格的mask AP作为性能评估指标。实验结果表明，Condlnst在Cityscapes数据集上的表现优于之前的强基线模型Mask R-CNN，提高了超过1%的mask AP。</p><p>​另外在Cityscapes数据集上，CondInst在全景分割任务上表现优异，超过了之前的方法，包括Panoptic-FPN等。与类似方法AdaptIS相比，CondInst在ResNet-101基础上取得了显着更好的性能，这表明在这里使用动态滤波器可能更为有效。与最近的方法（如Panoptic-FCN）相比，CondInst在全景分割任务上也取得了显著的性能提升。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​Condlnst是一个新的实例分割框架，通过动态生成掩码头部的滤波器，减少了参数和计算复杂度，提高了速度和准确性，同时无需更长的训练周期。它还可以简单地扩展到解决全景分割问题，并在COCO数据集上达到最先进的性能。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Faster R-CNN</title>
    <link href="/2024/05/21/0-Faster-R-CNN/"/>
    <url>/2024/05/21/0-Faster-R-CNN/</url>
    
    <content type="html"><![CDATA[<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><p><img src="/../images/0-Faster-R-CNN/image-20240521164920800.png" alt="Faster R-CNN"></p><blockquote><p>发布于NIPS 2015</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li><strong>R-CNN</strong>：使用选择性搜索算法生成候选区域，然后对每个区域进行卷积神经网络（CNN）特征提取和分类。这种方法的计算效率低，因为每个候选区域都要单独进行特征提取。</li><li><strong>Fast R-CNN</strong>：改进了R-CNN，通过在整个图像上进行一次特征提取，然后使用区域兴趣（RoI）池化层对候选区域进行分类和回归。这减少了冗余计算，但候选区域的生成仍是一个瓶颈。</li></ul><p>目标检测不仅需要识别图像中的对象，还需要确定每个对象的位置（分类与回归），先前的方法在速度和准确性上难以均衡，由于生成候选区的过程比较慢，所以候选区域生成成为了检测速度的瓶颈。</p><p><strong>Faster R-CNN</strong>通过引入区域建议网络（RPN，Region Proposal Network）解决了候选区域生成的瓶颈问题。RPN是一个全卷积网络，能够直接从图像的特征图中生成高质量的候选区域。这一设计使得整个目标检测过程可以端到端地进行，大大提高了检测速度和准确性。</p><p>通过将RPN和Fast R-CNN结合，Faster R-CNN实现了更快且更精确的目标检测，成为当时目标检测领域的一个重要突破。这一创新影响深远，奠定了后续目标检测方法的发展基础。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-Faster-R-CNN/image-20240521191841145.png" alt="处理多尺度和多尺寸问题"></p><p>Fast R-CNN使用参考框金字塔，即在在单一特征图上使用不同尺寸的参考框进行回归，既高效又灵活。</p><p><img src="/../images/0-Faster-R-CNN/image-20240521192258207.png" alt="Faster R-CNN基本结构"></p><p>从图中即可看到，主要分为4层：Conv layers,Region Proposal Network(RPN),RoI pooling, Classification.</p><h4 id="1-Conv-layers"><a href="#1-Conv-layers" class="headerlink" title="1.Conv layers"></a>1.Conv layers</h4><p>包含了卷积层，池化层，激活函数这三层。</p><p>在卷积（13层）操作时，原图的四周被加了一圈零，这使得3x3卷积后的图像与原图大小一致。在池化（4层）操作时，将输出的长宽都变为输入的二分之一，激活函数有13层。最终图片变为原来的1&#x2F;16。</p><p>生成的特征图保留了输入图像的重要空间信息和上下文信息，为后续的RPN提供基础特征。</p><h4 id="2-RPN"><a href="#2-RPN" class="headerlink" title="2.RPN"></a>2.RPN</h4><p>是一个轻量级的全卷积网络，直接在卷积层生成的特征图上运行。</p><p>主要由一个3x3的卷积层，以及两个并行的1x1卷积层组成，一个用于分类（是否包含对象），一个用于边界框回归（预测候选区域的位置）。</p><p>生成一系列潜在的候选区域（anchor boxes），这些区域可能包含对象。每个anchor box通过分类分支判断是否包含对象，通过回归分支调整其位置和尺寸。输出高质量的候选区域，这些区域将被进一步处理。</p><p>这里作者提到了一个词叫做“anchors”，就是RPN生成的一堆矩形，根据图像的大小来生成很多不重合的矩形选框,为每一个点都进行anchors选框，再进行遍历计算。</p><p><img src="/../images/0-Faster-R-CNN/image-20240521195617224.png" alt="anchors选框"></p><p>这些大量的anchors，使用CNN判断那些是有目标的anchor，哪些是没有目标的anchor，退化为二分类问题，例如一个800x600的图像就有17100个anchor。</p><p>另外，光靠anchor定位判断positive和negative是不够的，所以采用了bounding box regression：</p><p>当Ground Truch（GT 实际框）和提取出的框不准时，我们希望有方法能微调，所以我们的思路是先做平移，再做缩放。训练时作者给出了应该的平移量$(x_t ,x_y)$与尺度因子$(t_w,t_h)$：</p><p><img src="/../images/0-Faster-R-CNN/image-20240521201000480.png" alt="平移量与尺度因子"></p><p>训练时让其尽量接近，就可以修正anchor的位置了。</p><p>最后就是生成proposals。</p><h4 id="3-Roi-Pooling"><a href="#3-Roi-Pooling" class="headerlink" title="3.Roi Pooling"></a>3.Roi Pooling</h4><p>RoI池化层将RPN生成的候选区域映射到特征图上，并将每个区域池化到相同的固定大小。通过一个固定大小的窗口对候选区域内的特征进行池化。</p><p>大小不一的候选区域转换为固定大小的特征图，便于后续的全连接层处理。保留候选区域内的空间信息，并生成统一大小的特征向量。</p><h4 id="4-Classification"><a href="#4-Classification" class="headerlink" title="4.Classification"></a>4.Classification</h4><p>经过RoI池化层处理后的特征向量通过一系列全连接层进行进一步处理。最终通过两个并行的全连接层，一个用于分类，一个用于边界框回归。</p><p>分类层：对每个候选区域进行分类，确定其类别（包括背景类）。</p><p>边界框回归层：进一步调整每个候选区域的边界框，使其更精确地定位对象。</p><h4 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h4><p><img src="/../images/0-Faster-R-CNN/image-20240521201436051.png" alt="损失函数"></p><p>i代表第i个anchor，pi是正softmax概率，pi*是GT概率，t代表预测边界框，t*是正预测边界框。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>将检测速度一举提升到17 FPS，而且在VOC 2012测试集上实现了70.4%的检测效果</p><p><img src="/../images/0-Faster-R-CNN/image-20240521201705947.png" alt="实验结果"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Faster R-CNN通过引入区域建议网络（RPN）极大地提高了目标检测的速度和精度，解决了多尺度对象检测的难题，对计算机视觉领域产生了深远的影响。这一方法不仅提高了目标检测的性能，还为后续研究提供了新的思路和方法。Faster R-CNN的提出标志着目标检测技术的一个重要里程碑，开启了更多关于高效目标检测算法的研究和发展。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-CDDSA: Contrastive Domain Disentanglement and Style Augmentation for Generalizable Medical Image Segmentation</title>
    <link href="/2024/05/16/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/"/>
    <url>/2024/05/16/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/</url>
    
    <content type="html"><![CDATA[<h2 id="CDDSA-用于广义医学图像分割的对比域去纠缠和风格增强"><a href="#CDDSA-用于广义医学图像分割的对比域去纠缠和风格增强" class="headerlink" title="CDDSA:用于广义医学图像分割的对比域去纠缠和风格增强"></a>CDDSA:用于广义医学图像分割的对比域去纠缠和风格增强</h2><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516203813793.png" alt="CDDSA"></p><blockquote><p>发表于：Medical Image Analysis  Volume 89 ,2023年10月, 102904 </p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在分割未见过的临床医学图像的过程中，区分域特定特征和域不变特征的能力是实现域泛化（鼓励模型DG）的关键。现有的DG方法难以有效的解纠缠，从而获得高泛化能力，故提出了本文的方法：CDDSA框架（对比域去纠缠和风格增强），用于推广医学图像分割。CDDSA的大概步骤如下：</p><ol><li><strong>特征分解</strong>：首先，提出了一个分解网络，将图像分解为领域不变的解剖表示和领域特定的风格编码。解剖表示被送入一个分割模型，该模型不受领域转移的影响。</li><li><strong>重建图像</strong>：分解网络通过一个解码器进行正则化，结合解剖和风格编码来重建输入图像。这有助于学习如何有效地分离领域特定和领域不变的特征。</li><li><strong>分割模型</strong>：分割器采用领域不变的解剖表示作为输入，以获得分割结果。这样可以确保分割模型不受领域变化的影响，从而提高泛化能力。</li><li><strong>风格增强</strong>：引入风格增强策略，将给定图像的解剖表示与增强的风格编码相结合，生成新领域中的图像。这有助于模型学习如何适应不同风格的图像，提高泛化性能。</li></ol><p>使用视杯和椎间盘分割的公共多位点眼底图像数据集和用于鼻咽总肿瘤体积（GTVnx）分割的内部多位点鼻咽癌磁共振图像（NPC-MRI）数据集上进行了验证，实验结果表明，所提出的CDDSA在不同领域具有显著的可推广性，并且在领域可推广分割方面优于几种最先进的方法。</p><p>在医学图像分割中，深度学习方法取得了显著的性能，但现有模型通常建立在训练和测试图像来自相同领域且具有非常相似（甚至相同）分布的假设上。然而，在临床实践中，由于多种因素（如扫描设备、成像协议、患者群体和图像质量的差异），测试图像通常来自于与训练集不同的医疗中心，这种假设经常不成立。这种领域转移会显著降低模型在测试时的性能。为了解决这一问题，许多领域自适应方法被探索，以将源领域中的一组标记图像的知识转移到目标领域中的图像。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516213050418.png" alt="CDDSA方法的工作流程"></p><p>a）图像分割；b）图像增强。仅使用一对解剖编码器和样式编码器将不同领域中的医学图像组合成领域不变的解剖表示和领域特定的样式代码，该编码器和样式代码由接受解剖表示和样式代码的解码器正则化以重建图像。</p><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516222055623.png" alt="CDDSA网络概述"></p><p>图中几个主要组件：</p><ol><li>**编码器部分 (E_anat 和 E_sty)**：解剖编码器（E_anat）和风格编码器（E_sty）分别提取输入图像的解剖结构和风格信息。</li><li>**域对比学习 (Domain-wise contrastive learning)**：在潜在空间中进行对比学习，以使来源域和目标域的数据表示彼此靠近，并远离其他域的数据表示。</li><li>**域增强 (Domain augmentation)**：通过加入风格扰动（s_seg）来增强图像，从而提高网络的鲁棒性。</li><li>**重构模块 (D_rec)**：用来重构输入图像，以确保编码后的解剖和风格表示的质量。</li><li>**判别器模块 (D_dom)**：用来区分不同域的图像，并在损失函数（L_adv）中发挥作用，进一步指导表示学习。</li></ol><p>通过这些模块和损失函数的协同作用，网络能够学习到解耦的解剖结构和风格信息，实现多域医学图像的处理和分析。</p><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516222254046.png" alt="重建解码器"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516222720457.png" alt="不同数据收集方法的眼底数据集的比较"></p><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516222818541.png" alt="不同DG方法对眼底数据集的比较"></p><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516222920629.png" alt="实验结果"></p><p><img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516223004772.png" alt="图像增强"></p><p>作者也对其他不同的数据集做了实验， 并附加了消融学习结果。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>CDDSA框架在多领域医学图像分割任务上有效性。通过对多领域眼底图像和多领域鼻咽癌磁共振图像（NPC-MRI）的全面实验结果，作者展示了CDDSA在未见领域上取得了高泛化性能，并且优于几种最先进的领域泛化方法。表明CDDSA框架在处理医学图像分割中的领域泛化问题上具有潜在的应用前景。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-ImageNet Classification with Deep Convolutional Neural Networks</title>
    <link href="/2024/04/22/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/"/>
    <url>/2024/04/22/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/</url>
    
    <content type="html"><![CDATA[<h2 id="AlexNet-2012-NIPS"><a href="#AlexNet-2012-NIPS" class="headerlink" title="AlexNet 2012 NIPS"></a>AlexNet 2012 NIPS</h2><p><img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422232943298.png" alt="AlexNet"></p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>为了从数以百万计的图像中学习出数千种的目标，需要一个具有很强学习能力的模型。尽管CNNs有效率的局部结构，但大规模地应用于高分辨率图像消耗资源仍然过多。本文介绍了一种可以进行图像识别的卷积神经网络，包含了大量的不常见和新的特征来提升网络性能，减少训练时间。</p><p>包含6千万个参数和65万个神经元，包含了5个卷积层，其中有几层后面跟着最大池化层，以及3个全连接层，最后还有一个1000路的softmax层。为了加快训练速度，本文使用了不饱和神经元以及一种高效的基于GPU的卷积运算方法。为了减少全连接层的过拟合，采用了正则化方法“dropout”，该方法被证明非常有效。</p><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p>8层学习层——5层卷积层和三层全连接层</p><p><img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422233750222.png" alt="网络结构"></p><p>用ReLUs主要是对训练集的拟合进行加速。快速学习对由大规模数据集上训练出大模型的性能有相当大的影响。</p><p>ReLUs具有符合本文要求的一个性质：它不需要对输入进行归一化来防止饱和。</p><p><img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422234147225.png" alt="实线代表ReLUs，虚线代表tanh"></p><p>（1）输入图像大小：224 * 224 * 3</p><p>（2）第一层卷积设置：卷积–&gt;ReLU–&gt;局部响应归一化（LRN）–&gt;池化</p><p>（3）第二层卷积：卷积–&gt;ReLU–&gt;局部响应归一化（LRN）–&gt;池化</p><p>（4）第三层卷积：卷积–&gt;ReLU</p><p>（5）第四层卷积：卷积–&gt;ReLU</p><p>（6）第五层卷积：卷积–&gt;ReLU–&gt;池化</p><p>（7）全连接层</p><p>（8）全连接层2</p><p>（9）输出层（全连接层3）</p><h3 id="降低过拟合所采用的方法"><a href="#降低过拟合所采用的方法" class="headerlink" title="降低过拟合所采用的方法"></a>降低过拟合所采用的方法</h3><h5 id="数据扩增"><a href="#数据扩增" class="headerlink" title="数据扩增"></a>数据扩增</h5><p>为了降低过拟合，提高模型的鲁棒性，这里采用了两种Data Augmentation数据扩增方式：<br>a.生成图像平移和水平反射。通过从256×256幅图像中提取随机224×224块图像(及其水平反射)，并在这些提取的图像上训练AlexNet。这将训练集的大小增加了2048倍。<br>b.改变训练图像中RGB通道的强度。在整个ImageNet训练集中对RGB像素值集执行PCA（Principal Component Analysis)[<a href="https://zhuanlan.zhihu.com/p/366337471#ref_5">5]</a>操作。</p><h5 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h5><p>训练采用了0.5丢弃率的传统Dropout，对于使用了Dropout的layer中的每个神经元，训练时都有50%的概率被丢弃。所以每次输入时，神经网络都会对不同的结构进行采样，但是所有这些结构都共享权重。这种技术减少了神经元之间复杂的相互适应，因为神经元不能依赖于其他神经元的存在，因此，它被迫获得更健壮的特征。测试时使用所有的神经元，但将它们的输出乘以0.5。 论文中还提到了：Dropout使收敛所需的迭代次数增加了一倍。</p><h4 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h4><p>batch size&#x3D;128，动量项v&#x3D;0.9，权值衰减(weight decay) wd&#x3D;0.0005，W服从均值为0、标准差为0.01的高斯分布。</p><p>偏置项：第2、4、5卷积层和全连接层的b&#x3D;1（促进最初阶段ReLU的学习）；其它层b&#x3D;0。</p><p>学习率：初始为0.01，当验证集的错误率停止降低时，手动缩减学习率（除以10）。</p><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p><img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422234515097.png" alt="本文的算法错误率明显比前两个算法低"></p><p>最后结果top-1是67.4%，top-5是40.9%，比发布的最好的结果还要好。</p><p><img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422234549188.png" alt="验证误差"></p><p><img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422234630193.png" alt="定性分析"></p><p>左边部分，作者展示了8张图片的预测结果来说明网络在预测top-5时都从测试图片中学到了什么。右边部分则对比了测试集中的五张图片和在训练集中与之最相似的6张图片，如果两张图片产生的特征激活向量（即CNN的输出结果）的欧几里得距离小，就认为这两张图片相似。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>对于一个较大的数据集，给出了一种解决分类任务的方法，在当时取得了很重大的突破，<strong>AlexNet</strong>在深度学习</p><p>发展史上的<strong>历史意义远大于其模型的影响</strong>。卷积神经网络也成为计算机视觉的核心算法模型。</p><blockquote><p>如果我们今天回过头看看，将人工智能领域的蓬勃发展归功于某个事件的话，这份殊荣应属于2012年 ImageNet大赛的比赛成果。<br>2012年 ImageNet 的那场赛事的的确确引发了今天人工智能井喷式的发展。之前在语音识别领域是有一些成果，但大众并不知道，也不关心，而 ImageNet 让人工智能开始进入公众视野。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Very Deep Convolutional Networks For Large-Scale Image Recognition</title>
    <link href="/2024/04/22/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/"/>
    <url>/2024/04/22/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/</url>
    
    <content type="html"><![CDATA[<h2 id="用于大规模图像识别的超深卷积网络-2015-VGG"><a href="#用于大规模图像识别的超深卷积网络-2015-VGG" class="headerlink" title="用于大规模图像识别的超深卷积网络 2015 (VGG)"></a>用于大规模图像识别的超深卷积网络 2015 (VGG)</h2><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713777253973.png" alt="VGG"></p><blockquote><p>ImageNet Large-ScaleVisual Recognition Challenge (ILSVRC)：ImageNet大规模视觉识别挑战</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>卷积核到底该设置为多少？AlexNet采用了极大的size(11x11)、ZFNet将size调小了但仍然使用到了7x7，GoogLeNet同时使用了不同的filter size…</p><p>本篇文章VGG使用3x3不断叠加，使得CNN模型可以达到更深的层数且得到更好的精准度。本方法其实是对于AlexNet的基础上做了更好的改进。VGG的模型架构如下图所示：</p><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713778810157.png" alt="VGG的模型架构"></p><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713778871429.png" alt="参数数量" title="参数数目"></p><p>作者根据配置进行了分析：7x7的卷积和3个3x3的卷积感受野实际上是一样的，那为什么要用小卷积来代替大卷积呢？</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h4 id="VGGNet-1x1卷积"><a href="#VGGNet-1x1卷积" class="headerlink" title="VGGNet 1x1卷积"></a>VGGNet 1x1卷积</h4><p>选用1x1卷积核的最直接原因是在维度上继承全连接，conv1x1更加专注于跨通道的特征组合，conv3x3既考虑跨通道，也考虑局部信息整合。使用1x1卷积也可以在3x3或5x5卷积计算前先降低feature map的维度。</p><h4 id="VGGNet-卷积核变小"><a href="#VGGNet-卷积核变小" class="headerlink" title="VGGNet 卷积核变小"></a>VGGNet 卷积核变小</h4><p>卷积核全部替换为3×3（极少用了1×1）步长为1，而使用小的卷积核可以提升性能，加深网络结构。</p><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713779093966.png" alt="VGGNet"></p><h4 id="VGGNet-层数更深更宽"><a href="#VGGNet-层数更深更宽" class="headerlink" title="VGGNet 层数更深更宽"></a>VGGNet <strong>层数更深更宽</strong></h4><p>3个激活函数（ReLU）去代替1个，可使决策函数更加具有辨别能力；</p><p>3x3比5x5,7x7,11x11的Conv filter的参数减少，减少卷积数量带来性能提升。</p><h4 id="VGGNet-池化核变小且为偶数"><a href="#VGGNet-池化核变小且为偶数" class="headerlink" title="VGGNet 池化核变小且为偶数"></a>VGGNet <strong>池化核变小且为偶数</strong></h4><p>AlexNet中的max-pool全是3×3的，但VGGNet中是2×2的，可能的原因是2×2的max-pool带来的信息损失相对于3×3的来说要小一些，相比于3×3更容易捕获细小的特征变化起伏。在网络的层数增长的过程中，池化忽略的信息加上缓冲，并降低softmax的学习压力。</p><p>卷积只增加feature map的通道数，而池化只减少feature map的宽高。如今也有不少做法用大stride卷积去替代池化，未来可能没有池化。</p><h4 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h4><ul><li>优化方法：带动量（momentum）的小批量梯度下降</li><li>batch size：256</li><li>learning rate：0.01<br>和AlexNet一样，当val-acc 不下降则学习率缩小十倍，训练过程缩小了三次</li><li>momentum：0.9</li><li>weight decay（L2惩罚乘子）：0.0005</li><li>dropout rate（前两个全连接层）：0.5</li><li>目标函数：多项式逻辑斯特回归（SoftMax）</li><li>迭代次数：37万次iteration（74 epochs）后，停止训练</li></ul><h4 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h4><ul><li>测试图像的尺寸Q和训练图像的尺寸 S 没必要完全一样。</li><li>全连接层先转化为卷积层第一个全连接层转为7x7的卷积层，后两个转化为1x1的卷积层。</li><li>再将这样得到的全卷积网络运用在整幅图像上。</li><li>使用水平翻转对测试图像进行增强。</li></ul><h3 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h3><h5 id="单一尺寸上的卷积网络"><a href="#单一尺寸上的卷积网络" class="headerlink" title="单一尺寸上的卷积网络"></a>单一尺寸上的卷积网络</h5><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713795644679.png" alt="1713795644679"></p><p>注意使用局部相应标准化网络（A-LRN）的性能并没有比未用标准化层的A高。</p><p>更大的数据集使用更深的模型会更好。小滤波器的卷积网络比大滤波器的千层网络性能更好。</p><h5 id="多尺寸上的卷积网络"><a href="#多尺寸上的卷积网络" class="headerlink" title="多尺寸上的卷积网络"></a>多尺寸上的卷积网络</h5><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713795949526.png" alt="多尺寸上的卷积网络"></p><p>测试时图片尺寸波动会使性能更好。</p><h5 id="多裁剪的评估"><a href="#多裁剪的评估" class="headerlink" title="多裁剪的评估"></a>多裁剪的评估</h5><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713796032170.png" alt="多裁剪"></p><p>多重裁切比密集评估的效果好，并且两者互补。</p><h5 id="融合卷积网络"><a href="#融合卷积网络" class="headerlink" title="融合卷积网络"></a>融合卷积网络</h5><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713796158321.png" alt="融合卷积网络"></p><p>将两个表现最好的多尺寸模型组合禁用，将会进一步减少错误率。</p><h5 id="结果比较"><a href="#结果比较" class="headerlink" title="结果比较"></a>结果比较</h5><p><img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713796323671.png" alt="结果比较"></p><p>使用了7个模型组合的测试错误率，为7.3%，使用2个模型的组合，将错误率降低到了6.8%。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>VGG网络继承了AlexNet中的不少网络结构，同时继承了OverFeat在Localization任务中的做法，学习这种经典的网络应该可以对日后在Computer Vision领域的学习起到一定的作用，小卷积核的应用以及VGGNet的输入图像rescale应该是本论文中重点关注的点。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Leetcode</title>
    <link href="/2024/03/06/Leetcode/"/>
    <url>/2024/03/06/Leetcode/</url>
    
    <content type="html"><![CDATA[<p class="note note-success">简单</p><p class="note note-warning">中等</p> <p class="note note-danger">困难</p><h2 id="2024-03-06简单"><a href="#2024-03-06简单" class="headerlink" title="2024-03-06简单"></a>2024-03-06<p class="note note-success">简单</p></h2><p><a href="https://leetcode.cn/problems/find-the-k-or-of-an-array/">2917. 找出数组中的 K-or 值</a></p><p>位运算问题，考虑到K-or数只看第i位的值是否为1，并且需要知道的仅仅是超过k值的数组中的数，使用O(n)来解决此问题</p><p>简单的位运算模拟。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">findKOr</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-type">int</span> res = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">31</span>; ++i) &#123;<br>            <span class="hljs-type">int</span> cnt = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num:nums) &#123;<br>                <span class="hljs-keyword">if</span>((num &gt;&gt; i) &amp; <span class="hljs-number">1</span>)&#123;<br>                    ++cnt;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">if</span> (cnt &gt;= k) &#123;<br>                res |= <span class="hljs-number">1</span> &lt;&lt; i;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2024-03-07中等"><a href="#2024-03-07中等" class="headerlink" title="2024-03-07中等"></a>2024-03-07<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/find-the-divisibility-array-of-a-string/">2575. 找出字符串的可整除数组</a></p><p>考虑到 word 长达 1e5，故无法每一个数字取模确认，因为十进制数字退一位有着 10 个数一循环的特性，故一次取模不影响后面是否会被 m 整除，遂只需要 O(n)即可解决问题。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">divisibilityArray</span><span class="hljs-params">(string word, <span class="hljs-type">int</span> m)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n=word.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(n)</span></span>;<br>        <span class="hljs-type">long</span> cur=<span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;n;i++)&#123;<br>            cur = <span class="hljs-number">10</span>*cur+((<span class="hljs-type">int</span>)word[i]<span class="hljs-number">-48</span>);<br>            cur %= m;<br>            <span class="hljs-keyword">if</span>(cur==<span class="hljs-number">0</span>) res[i]=<span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">else</span> res[i]=<span class="hljs-number">0</span>;<br>        &#125;<br>            <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>如何更快？使用位运算可加快计算速度。</p><h2 id="2024-03-08中等"><a href="#2024-03-08中等" class="headerlink" title="2024-03-08中等"></a>2024-03-08<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/find-the-minimum-possible-sum-of-a-beautiful-array/">2834. 找出美丽数组的最小和</a></p><p>考虑到一个数可分解为两个数相加，题意为数组中的“两个”数相加不得target，那么如果相等则向下延顺，比如9可分为1 + 8，2 + 7，3 + 6,4 + 5这四组不同的加法，而默认最小数组就是1到n这n个数字，则去除延顺后的最小数组就是[1,2,3,4,9,10,………,n]推出正常情况下的公示，再对1和target不影响默认最小数组的情况特殊判断即可。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-type">int</span> mod=<span class="hljs-number">1e9</span> + <span class="hljs-number">7</span>;<br>    <span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">a_sum</span><span class="hljs-params">(<span class="hljs-type">int</span> a,<span class="hljs-type">int</span> b,<span class="hljs-type">int</span> l)</span></span>&#123;<span class="hljs-keyword">if</span>(l==<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> a; <span class="hljs-keyword">return</span> (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)(a+b)*l/<span class="hljs-number">2</span>;&#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minimumPossibleSum</span><span class="hljs-params">(<span class="hljs-type">int</span> n, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(n==<span class="hljs-number">1</span> <span class="hljs-keyword">or</span> target==<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-built_in">a_sum</span>(<span class="hljs-number">1</span>,n,n)%mod;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> pd= target/<span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">if</span>(pd&gt;n) <span class="hljs-keyword">return</span> <span class="hljs-built_in">a_sum</span>(<span class="hljs-number">1</span>,n,n)%mod;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> n1=<span class="hljs-built_in">a_sum</span>(<span class="hljs-number">1</span>,target+n-pd<span class="hljs-number">-1</span>,target+n-pd<span class="hljs-number">-1</span>);<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> n2=<span class="hljs-built_in">a_sum</span>(pd+<span class="hljs-number">1</span>,target<span class="hljs-number">-1</span>,target-pd<span class="hljs-number">-1</span>);<br>        <span class="hljs-keyword">return</span> (n1-n2)%mod;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p><img src="/../images/Leetcode/image-20240314171703628.png" alt="time"></p><h2 id="2024-03-09困难"><a href="#2024-03-09困难" class="headerlink" title="2024-03-09困难"></a>2024-03-09<p class="note note-danger">困难</p></h2><p><a href="https://leetcode.cn/problems/find-the-k-sum-of-an-array/">2386. 找出数组的第 K 大和</a></p><p>一个有n个元素的数组有2^n个子数组，既然是找出第K大的子数组和，那么本题对于给出数组的排序并不敏感，关键是子数组的排序，既然求最大的子数组，那么所有正数相加就是第1个大的子数组，其他子数组就是减去一个最小的正数，或者加上一个最大的负数就是第二个最大子数组….再向后可能就是减去多个正数，加上多个负数….</p><p>那么问题转化为只需要求第K个最大子数组的值减去第一个最大子数组的值。使用优先队列的小顶堆维护即可：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">kSum</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> s=<span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> n=nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> &amp;x:nums)&#123;<br>            <span class="hljs-keyword">if</span>(x&gt;=<span class="hljs-number">0</span>) s+=x;<br>            <span class="hljs-keyword">else</span> x=-x;<br>        &#125;<br>        <span class="hljs-built_in">sort</span>(nums.<span class="hljs-built_in">begin</span>(),nums.<span class="hljs-built_in">end</span>());<br>        priority_queue&lt;pair&lt;<span class="hljs-type">long</span> <span class="hljs-type">long</span>,<span class="hljs-type">int</span>&gt;,vector&lt;pair&lt;<span class="hljs-type">long</span> <span class="hljs-type">long</span>,<span class="hljs-type">int</span>&gt;&gt;,greater&lt;&gt;&gt;q;<br>        q.<span class="hljs-built_in">push</span>(&#123;<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;);<br>        <span class="hljs-keyword">while</span> (--k)<br>        &#123;<br>            <span class="hljs-keyword">auto</span> ts=q.<span class="hljs-built_in">top</span>();q.<span class="hljs-built_in">pop</span>();<br>            <span class="hljs-keyword">if</span>(ts.second&gt;=n) <span class="hljs-keyword">continue</span>;<br>            q.<span class="hljs-built_in">push</span>(&#123;ts.first+nums[ts.second],ts.second+<span class="hljs-number">1</span>&#125;);<br>            <span class="hljs-keyword">if</span>(ts.second) q.<span class="hljs-built_in">push</span>(&#123;ts.first-nums[ts.second<span class="hljs-number">-1</span>]+nums[ts.second],ts.second+<span class="hljs-number">1</span>&#125;);<br>        &#125;<br>        <span class="hljs-keyword">return</span> s-q.<span class="hljs-built_in">top</span>().first;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2024-03-10中等"><a href="#2024-03-10中等" class="headerlink" title="2024-03-10中等"></a>2024-03-10<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/bulls-and-cows/">299. 猜数字游戏</a></p><p>使用键值对可以轻松解决此问题。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">getHint</span><span class="hljs-params">(string secret, string guess)</span> </span>&#123;<br>        unordered_map&lt;<span class="hljs-type">char</span>,<span class="hljs-type">int</span>&gt; mp1,mp2;<br>        <span class="hljs-type">int</span> n=secret.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">bulls</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span>,<span class="hljs-title">cows</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;n;i++)&#123;<br>            <span class="hljs-keyword">if</span>(secret[i]==guess[i])&#123;bulls++;<span class="hljs-keyword">continue</span>;&#125;<br>            mp1[secret[i]]++,mp2[guess[i]]++;<br>        &#125;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> &amp;it:mp1)<br>            <span class="hljs-keyword">if</span>(mp2[it.first]) cows+=<span class="hljs-built_in">min</span>(it.second,mp2[it.first]);<br>        string ans=<span class="hljs-built_in">to_string</span>(bulls)+<span class="hljs-string">&quot;A&quot;</span>+<span class="hljs-built_in">to_string</span>(cows)+<span class="hljs-string">&quot;B&quot;</span>;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2024-03-11简单"><a href="#2024-03-11简单" class="headerlink" title="2024-03-11简单"></a>2024-03-11<p class="note note-success">简单</p></h2><p><a href="https://leetcode.cn/problems/capitalize-the-title/">2129. 将标题首字母大写</a></p><p>使用字符流容易解决，还可以避免指针越界。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">capitalizeTitle</span><span class="hljs-params">(string title)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n=title.<span class="hljs-built_in">size</span>();<br>        string ans=<span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-function">stringstream <span class="hljs-title">ss</span><span class="hljs-params">(title)</span></span>;<br>        string str;<br>        <span class="hljs-keyword">while</span>(ss&gt;&gt;str)&#123;<br>            <span class="hljs-keyword">if</span>(str.<span class="hljs-built_in">size</span>()&lt;=<span class="hljs-number">2</span>)&#123;<br>                ans+=<span class="hljs-built_in">tolower</span>(str[<span class="hljs-number">0</span>]);<br>                <span class="hljs-keyword">if</span>(str.<span class="hljs-built_in">size</span>()==<span class="hljs-number">2</span>) ans+=<span class="hljs-built_in">tolower</span>(str[<span class="hljs-number">1</span>]); <br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                <span class="hljs-type">int</span> nn=str.<span class="hljs-built_in">size</span>();<br>                ans+=<span class="hljs-built_in">toupper</span>(str[<span class="hljs-number">0</span>]);<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">1</span>;i&lt;nn;i++)&#123;<br>                    ans+=<span class="hljs-built_in">tolower</span>(str[i]);<br>                &#125;<br>            &#125;<br>            ans+=<span class="hljs-string">&quot; &quot;</span>;<br>        &#125;<br>        ans.<span class="hljs-built_in">pop_back</span>();<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2024-03-12中等"><a href="#2024-03-12中等" class="headerlink" title="2024-03-12中等"></a>2024-03-12<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/find-elements-in-a-contaminated-binary-tree/">1261. 在受污染的二叉树中查找元素</a></p><p>二叉树….</p><h2 id="2024-03-13简单"><a href="#2024-03-13简单" class="headerlink" title="2024-03-13简单"></a>2024-03-13<p class="note note-success">简单</p></h2><p><a href="https://leetcode.cn/problems/maximum-odd-binary-number/">2864. 最大二进制奇数</a></p><p>贪心</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">maximumOddBinaryNumber</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n=s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">n0</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span>,<span class="hljs-title">n1</span><span class="hljs-params">(<span class="hljs-number">0</span>)</span></span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;n;i++)<br>            <span class="hljs-keyword">if</span>(s[i]==<span class="hljs-string">&#x27;0&#x27;</span>) n0++;<span class="hljs-keyword">else</span> n1++;<br>        string ans=<span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>;i&lt;n1<span class="hljs-number">-1</span>;i++) ans+=<span class="hljs-string">&#x27;1&#x27;</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=n1<span class="hljs-number">-1</span>;i&lt;n<span class="hljs-number">-1</span>;i++) ans+=<span class="hljs-string">&#x27;0&#x27;</span>;<br>        ans+=<span class="hljs-string">&#x27;1&#x27;</span>;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2024-03-14中等"><a href="#2024-03-14中等" class="headerlink" title="2024-03-14中等"></a>2024-03-14<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/largest-element-in-an-array-after-merge-operations/">2789. 合并后数组中的最大元素</a></p><p>一开始想如果两对两对的看成一个树的结果，维护一个最大的根，后来发现既然只有两个相邻的数，那么直接从后往前加在一块，在不符合规则前取最大的那个不就行了，后来有发现既然他不符合规则，那么后面遍历完的数据就必不可能是答案喽，还是比较容易解决的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">maxArrayValue</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n=nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> ans=nums[n<span class="hljs-number">-1</span>];<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=n<span class="hljs-number">-2</span>;i&gt;=<span class="hljs-number">0</span>;i--)&#123;<br>            <span class="hljs-keyword">if</span>(nums[i]&lt;=ans)&#123;<br>                ans=(<span class="hljs-type">long</span> <span class="hljs-type">long</span>)ans+(<span class="hljs-type">long</span> <span class="hljs-type">long</span>)nums[i];<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                ans=(<span class="hljs-type">long</span> <span class="hljs-type">long</span>)nums[i];<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2024-03-15困难"><a href="#2024-03-15困难" class="headerlink" title="2024-03-15困难"></a>2024-03-15<p class="note note-danger">困难</p></h2><p><a href="https://leetcode.cn/problems/selling-pieces-of-wood/">2312. 卖木头块</a></p><p>求出卖出方案的最大值，可以确定是DP，题目中说明切割一次只能完全切割，那么如何正确的遍历切割方案和递推公式就是本题的难点。</p><p>观察到一个M*N的矩形有2种切割方法，首先是切割成（M1+M2）*N，或者是M*(N1+N2)，其中会存在相同的M*N，如果将其记录则优化时间，使用二维数组更新切割的最大值，创建DP。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-keyword">typedef</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ll;<br>    <span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">sellingWood</span><span class="hljs-params">(<span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; prices)</span> </span>&#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">mp</span>(m+<span class="hljs-number">1</span>,<span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt; (n+<span class="hljs-number">1</span>,<span class="hljs-number">0</span>));<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> &amp;p:prices) mp[p[<span class="hljs-number">0</span>]][p[<span class="hljs-number">1</span>]]=p[<span class="hljs-number">2</span>];<br>        vector&lt;vector&lt;ll&gt;&gt; <span class="hljs-built_in">dp</span>(m+<span class="hljs-number">1</span>,<span class="hljs-built_in">vector</span>&lt;ll&gt; (n+<span class="hljs-number">1</span>,<span class="hljs-number">-1</span>));<br><br>        function&lt;<span class="hljs-type">void</span>(<span class="hljs-type">int</span>,<span class="hljs-type">int</span>)&gt; dfs = [&amp;](<span class="hljs-type">int</span> i,<span class="hljs-type">int</span> j)&#123;<br>            <span class="hljs-keyword">if</span>(dp[i][j] != <span class="hljs-number">-1</span>) <span class="hljs-keyword">return</span>;<br>            dp[i][j]=mp[i][j];<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x=i/<span class="hljs-number">2</span>;x&gt;<span class="hljs-number">0</span>;x--)&#123;<br>                <span class="hljs-built_in">dfs</span>(x,j);<br>                <span class="hljs-built_in">dfs</span>(i-x,j);<br>                dp[i][j] = <span class="hljs-built_in">max</span>(dp[i][j],dp[x][j]+dp[i-x][j]);<br>            &#125;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> y=j/<span class="hljs-number">2</span>;y&gt;<span class="hljs-number">0</span>;y--)&#123;<br>                <span class="hljs-built_in">dfs</span>(i,y);<br>                <span class="hljs-built_in">dfs</span>(i,j-y);<br>                dp[i][j] = <span class="hljs-built_in">max</span>(dp[i][j],dp[i][y]+dp[i][j-y]);<br>            &#125;<br>        &#125;;<br>        <span class="hljs-built_in">dfs</span>(m,n);<br>        <span class="hljs-keyword">return</span> dp[m][n];<br><br>    &#125;<br>&#125;;<br><br><br><span class="hljs-comment">//后来在speed rank里看到比我快8倍的代码，真是又快又好，很值得学习</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-type">long</span> <span class="hljs-type">long</span> dp[<span class="hljs-number">201</span>][<span class="hljs-number">201</span>];<br>    <span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">sellingWood</span><span class="hljs-params">(<span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n, vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; prices)</span> </span>&#123;<br>        <span class="hljs-type">int</span> i,j,k;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> &amp;x : prices) &#123;<br>            dp[x[<span class="hljs-number">0</span>]][x[<span class="hljs-number">1</span>]] = x[<span class="hljs-number">2</span>];<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= m; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++) &#123;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">1</span>; k &lt;= j/<span class="hljs-number">2</span>; k++) dp[i][j] = <span class="hljs-built_in">max</span>(dp[i][j], dp[i][k] + dp[i][j - k]); <span class="hljs-comment">// 垂直切割</span><br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">1</span>; k &lt;= i/<span class="hljs-number">2</span>; k++) dp[i][j] = <span class="hljs-built_in">max</span>(dp[i][j], dp[k][j] + dp[i - k][j]); <span class="hljs-comment">// 水平切割</span><br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[m][n];<br>    &#125;<br>&#125;;<br><br></code></pre></td></tr></table></figure><h2 id="2024-03-16"><a href="#2024-03-16" class="headerlink" title="2024-03-16"></a>2024-03-16</h2><h2 id="2024-03-17"><a href="#2024-03-17" class="headerlink" title="2024-03-17"></a>2024-03-17</h2><h2 id="2024-03-18"><a href="#2024-03-18" class="headerlink" title="2024-03-18"></a>2024-03-18</h2><h2 id="2024-03-19"><a href="#2024-03-19" class="headerlink" title="2024-03-19"></a>2024-03-19</h2><h2 id="2024-03-20中等"><a href="#2024-03-20中等" class="headerlink" title="2024-03-20中等"></a>2024-03-20<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/minimum-non-zero-product-of-the-array-elements/">1969. 数组元素的最小非零乘积</a></p><p>​基于贪心算法，优先将小的变小，大的变大，最后数组就会成为[0,0,0,0,0,……..,2^p -1,2^p -1,…..]，因为要求数组非零，所以再将后面2^p -1的最后一个1补到前面即可，但是不知道为什么，pow（2，p）的效果居然和(ll)1&lt;&lt;(p-1)不一样，这点还有待考量。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-keyword">typedef</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> ll;<br>    ll mod=<span class="hljs-number">1e9</span>+<span class="hljs-number">7</span>;<br><span class="hljs-function"><span class="hljs-type">long</span> <span class="hljs-type">long</span> <span class="hljs-title">my_pow</span><span class="hljs-params">(<span class="hljs-type">long</span> <span class="hljs-type">long</span> x, <span class="hljs-type">long</span> <span class="hljs-type">long</span> n)</span> </span>&#123;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> res = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (; n != <span class="hljs-number">0</span>; n &gt;&gt;= <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">if</span> (n &amp; <span class="hljs-number">1</span>) &#123;<br>                res = res * x % mod;<br>            &#125;<br>            x = x * x % mod;<br>        &#125;<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minNonZeroProduct</span><span class="hljs-params">(<span class="hljs-type">int</span> p)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(p==<span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> p;<br>        ll a=<span class="hljs-built_in">my_pow</span>((ll)<span class="hljs-number">2</span>,p)%mod;<span class="hljs-comment">//2^p</span><br><br>        <span class="hljs-comment">// ll y=my_pow(a-(ll)2,a/(ll)2-(ll)1)%mod;</span><br>        <span class="hljs-comment">// ll x=a-(ll)1;</span><br>        <span class="hljs-comment">// x%=mod;</span><br>        <span class="hljs-comment">// ll ans=x*y%mod;</span><br>        <span class="hljs-comment">// return ans%mod;</span><br>        ll x=<span class="hljs-built_in">my_pow</span>(<span class="hljs-number">2</span>,p)<span class="hljs-number">-1</span>;<br>        ll y=(ll)<span class="hljs-number">1</span>&lt;&lt;(p<span class="hljs-number">-1</span>);<br>        <span class="hljs-comment">// ll y=my_pow((ll)2,p-(ll)1);</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">my_pow</span>(x<span class="hljs-number">-1</span>,y<span class="hljs-number">-1</span>)*x%mod;<br>    &#125;<br>&#125;;<br><span class="hljs-comment">/*</span><br><span class="hljs-comment">p=2</span><br><span class="hljs-comment">1 2 3</span><br><span class="hljs-comment">1 2 3</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">p=3</span><br><span class="hljs-comment">1 2 3 4 5 6 7</span><br><span class="hljs-comment"> +4 -2+2-4</span><br><span class="hljs-comment">1 6 1 6 1 6 7</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">p=4</span><br><span class="hljs-comment">1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</span><br><span class="hljs-comment"> +8+4  -4       -8            </span><br><span class="hljs-comment"> 1     2    3    4   5    6    7    8     9    10  11   12   13   14   15</span><br><span class="hljs-comment">0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111</span><br><span class="hljs-comment">0001 1010 0011 0100 0101 0110 0111 1000 0001 1010 1011 1100 1101 1110 1111</span><br><span class="hljs-comment">0001 1010 0111 0100 0001 0110 0111 1000 0001 1010 1011 1100 1101 1110 1111</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="2024-03-21中等"><a href="#2024-03-21中等" class="headerlink" title="2024-03-21中等"></a>2024-03-21<p class="note note-warning">中等</p></h2><p><a href="https://leetcode.cn/problems/frequency-tracker/">2671. 频率跟踪器</a></p><p>第一眼看见直接用map就解决了吗？看到查询次数可能很多，那就动态记录一下num的存量。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FrequencyTracker</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    unordered_map&lt;<span class="hljs-type">int</span>,<span class="hljs-type">int</span>&gt; mp;<br>    unordered_map&lt;<span class="hljs-type">int</span>,<span class="hljs-type">int</span>&gt; cnt;<br><br>    <span class="hljs-built_in">FrequencyTracker</span>() &#123;<br>        mp.<span class="hljs-built_in">clear</span>();<br>        cnt.<span class="hljs-built_in">clear</span>();<br>    &#125;<br>    <br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> number)</span> </span>&#123;<br>        mp[number]++;<br>        cnt[mp[number]<span class="hljs-number">-1</span>]--;<br>        cnt[mp[number]]++;<br>    &#125;<br>    <br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">deleteOne</span><span class="hljs-params">(<span class="hljs-type">int</span> number)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(mp[number]&gt;<span class="hljs-number">0</span>)&#123;<br>            mp[number]--;<br>            cnt[mp[number]+<span class="hljs-number">1</span>]--;<br>            cnt[mp[number]]++;<br><br>        &#125;<br>    &#125;<br>    <br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">hasFrequency</span><span class="hljs-params">(<span class="hljs-type">int</span> frequency)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(cnt[frequency]&gt;<span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>&#125;;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Your FrequencyTracker object will be instantiated and called as such:</span><br><span class="hljs-comment"> * FrequencyTracker* obj = new FrequencyTracker();</span><br><span class="hljs-comment"> * obj-&gt;add(number);</span><br><span class="hljs-comment"> * obj-&gt;deleteOne(number);</span><br><span class="hljs-comment"> * bool param_3 = obj-&gt;hasFrequency(frequency);</span><br><span class="hljs-comment"> */</span><br></code></pre></td></tr></table></figure><h2 id="2024-03-22"><a href="#2024-03-22" class="headerlink" title="2024-03-22"></a>2024-03-22</h2><h2 id="第-33-次-CCF-CSP-认证考试总结"><a href="#第-33-次-CCF-CSP-认证考试总结" class="headerlink" title="第 33 次 CCF CSP 认证考试总结"></a>第 33 次 CCF CSP 认证考试总结</h2><p>第一题和第二题都很简单，不到 20 分钟就敲完了，全程使用 STL。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-meta">#<span class="hljs-keyword">define</span> closeSync            \</span><br><span class="hljs-meta">    ios::sync_with_stdio(0); \</span><br><span class="hljs-meta">    cin.tie(0);              \</span><br><span class="hljs-meta">    cout.tie(0)</span><br><br>map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; mp1;<br>unordered_set&lt;<span class="hljs-type">int</span>&gt; st1;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    closeSync;<br>    <span class="hljs-type">int</span> n, m;<br>    cin &gt;&gt; n &gt;&gt; m;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">v</span><span class="hljs-params">(m + <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)</span></span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)<br>    &#123;<br>        <span class="hljs-type">int</span> t;<br>        cin &gt;&gt; t;<br>        unordered_set&lt;<span class="hljs-type">int</span>&gt; st;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; t; j++)<br>        &#123;<br>            <span class="hljs-type">int</span> word;<br>            cin &gt;&gt; word;<br>            mp1[word]++;<br>            st.<span class="hljs-built_in">insert</span>(word);<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> &amp;it : st)<br>        &#123;<br>            v[it]++;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= m; i++)<br>    &#123;<br>        cout &lt;&lt; v[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span> &lt;&lt; mp1[i] &lt;&lt; <span class="hljs-string">&#x27;\n&#x27;</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-meta">#<span class="hljs-keyword">define</span> closeSync            \</span><br><span class="hljs-meta">    ios::sync_with_stdio(0); \</span><br><span class="hljs-meta">    cin.tie(0);              \</span><br><span class="hljs-meta">    cout.tie(0)</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    closeSync;<br>    <span class="hljs-type">int</span> n, m;<br>    cin &gt;&gt; n &gt;&gt; m;<br>    unordered_set&lt;string&gt; st1;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)<br>    &#123;<br>        string s;<br>        cin &gt;&gt; s;<br>        <span class="hljs-type">int</span> sz = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; sz; j++)<br>        &#123;<br>            <span class="hljs-keyword">if</span> (s[j] &gt;= <span class="hljs-string">&#x27;A&#x27;</span> <span class="hljs-keyword">and</span> s[j] &lt;= <span class="hljs-string">&#x27;Z&#x27;</span>)<br>            &#123;<br>                s[j] += <span class="hljs-number">32</span>;<br>            &#125;<br>        &#125;<br>        st1.<span class="hljs-built_in">insert</span>(s);<br>        <span class="hljs-comment">//    cout &lt;&lt; s &lt;&lt; &quot; &quot;;</span><br>    &#125;<br>    unordered_set&lt;string&gt; st2;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)<br>    &#123;<br>        string s;<br>        cin &gt;&gt; s;<br>        <span class="hljs-type">int</span> sz = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; sz; j++)<br>        &#123;<br>            <span class="hljs-keyword">if</span> (s[j] &gt;= <span class="hljs-string">&#x27;A&#x27;</span> <span class="hljs-keyword">and</span> s[j] &lt;= <span class="hljs-string">&#x27;Z&#x27;</span>)<br>            &#123;<br>                s[j] += <span class="hljs-number">32</span>;<br>            &#125;<br>        &#125;<br>        st2.<span class="hljs-built_in">insert</span>(s);<br>        <span class="hljs-comment">//  cout &lt;&lt; s &lt;&lt; &quot; &quot;;</span><br>    &#125;<br>    unordered_set&lt;string&gt; st3;<br>    <span class="hljs-type">int</span> n1 = st1.<span class="hljs-built_in">size</span>();<br>    <span class="hljs-type">int</span> n2 = st2.<span class="hljs-built_in">size</span>();<br>    <span class="hljs-comment">// U</span><br>    <span class="hljs-built_in">set_union</span>(st1.<span class="hljs-built_in">begin</span>(), st1.<span class="hljs-built_in">end</span>(), st2.<span class="hljs-built_in">begin</span>(), st2.<span class="hljs-built_in">end</span>(), <span class="hljs-built_in">inserter</span>(st3, st3.<span class="hljs-built_in">begin</span>()));<br>    <span class="hljs-type">int</span> onaji = st3.<span class="hljs-built_in">size</span>();<br>    cout &lt;&lt; n1 + n2 - onaji &lt;&lt; <span class="hljs-string">&#x27;\n&#x27;</span>;<br>    cout &lt;&lt; onaji &lt;&lt; <span class="hljs-string">&#x27;\n&#x27;</span>;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>第三题是对矩阵求秩，有时候想把代码写的好看一点，可是这反而浪费了很多时间，再加上找不到 bug 在哪，让我一度又推翻重写的想法，大概 2 个小时才修改完。</p><p>（可惜我没有高斯消元板子，只能现场手搓）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-meta">#<span class="hljs-keyword">define</span> closeSync            \</span><br><span class="hljs-meta">    ios::sync_with_stdio(0); \</span><br><span class="hljs-meta">    cin.tie(0);              \</span><br><span class="hljs-meta">    cout.tie(0)</span><br><br><span class="hljs-type">int</span> q, n;<br>vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">a</span>(<span class="hljs-number">52</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(<span class="hljs-number">52</span>, <span class="hljs-number">0</span>));<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">scan</span><span class="hljs-params">(<span class="hljs-type">int</span> ssum)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> r;<br>    <span class="hljs-type">int</span> cnt = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= ssum; i++)<br>    &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++)<br>        &#123;<br>            <span class="hljs-keyword">if</span> (a[i][j] != <span class="hljs-number">0</span>)<br>            &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span><br>                cnt++;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (cnt == n)<br>        &#123;<br>            <span class="hljs-keyword">return</span> i - <span class="hljs-number">1</span>;<br>        &#125;<br>        cnt = <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> ssum;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">gcd</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">return</span> b == <span class="hljs-number">0</span> ? a : <span class="hljs-built_in">gcd</span>(b, a % b);<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">lcm</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">return</span> a / <span class="hljs-built_in">gcd</span>(a, b) * b;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-type">int</span> ssum)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= ssum; i++)<br>    &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++)<br>        &#123;<br>            cout &lt;&lt; a[i][j] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>        &#125;<br>        cout &lt;&lt; endl;<br>    &#125;<br>    cout &lt;&lt; endl;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">solve</span><span class="hljs-params">(<span class="hljs-type">int</span> ssum)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// print(ssum);</span><br>    <span class="hljs-type">int</span> l = <span class="hljs-number">1</span>;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= ssum; i++)<br>    &#123;<br>        <span class="hljs-type">int</span> pd0 = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++)<br>        &#123;<br>            pd0 += a[i][j];<br>        &#125;<br>        <span class="hljs-keyword">if</span> (pd0 == <span class="hljs-number">0</span>)<br>        &#123;<br>            l++;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (a[i][l] == <span class="hljs-number">0</span>)<br>        &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = i + <span class="hljs-number">1</span>; k &lt;= ssum; k++)<br>            &#123;<br>                <span class="hljs-keyword">if</span> (a[k][l] != <span class="hljs-number">0</span>)<br>                &#123;<br>                    <span class="hljs-built_in">swap</span>(a[i], a[k]);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = i + <span class="hljs-number">1</span>; k &lt;= ssum; k++)<br>        &#123;<br>            <span class="hljs-type">int</span> aa = a[i][l], bb = a[k][l];<br>            <span class="hljs-keyword">if</span> (bb == <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">continue</span>;<br><br>            <span class="hljs-type">int</span> beishu1 = <span class="hljs-built_in">lcm</span>(aa, bb);<br>            <span class="hljs-comment">// cout &lt;&lt; beishu1 &lt;&lt; endl;</span><br>            <span class="hljs-type">int</span> beishu2 = bb * beishu1 / aa;<br>            <span class="hljs-comment">// cout &lt;&lt; bb &lt;&lt; &quot;aa/a &quot; &lt;&lt; aa &lt;&lt; endl;</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ll = l; ll &lt;= n; ll++)<br>            &#123;<br>                a[k][ll] *= beishu1;<br>                <span class="hljs-comment">// cout &lt;&lt; &quot;a[k][ll]前 =&quot; &lt;&lt; a[k][ll] &lt;&lt; endl;</span><br>                a[k][ll] = a[k][ll] - beishu2 * a[i][ll];<br>                <span class="hljs-comment">// cout &lt;&lt; &quot;a[k][ll]后 =&quot; &lt;&lt; a[k][ll] &lt;&lt; endl;</span><br>            &#125;<br>        &#125;<br>        <span class="hljs-comment">// print(ssum);</span><br><br>        <span class="hljs-keyword">if</span> (l &lt; n)<br>            l++;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            <span class="hljs-keyword">return</span> l;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> l;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    closeSync;<br>    cin &gt;&gt; q;<br>    <span class="hljs-keyword">while</span> (q--)<br>    &#123;<br>        cin &gt;&gt; n;<br>        unordered_map&lt;string, vector&lt;<span class="hljs-type">int</span>&gt;&gt; mp;<br>        string s;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">1</span>; k &lt;= n; k++)<br>        &#123;<br>            cin &gt;&gt; s;<br>            string elem = <span class="hljs-string">&quot;&quot;</span>;<br>            <span class="hljs-type">int</span> sz = s.<span class="hljs-built_in">size</span>();<br>            string num_s = <span class="hljs-string">&quot;&quot;</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; sz; i++)<br>            &#123;<br>                <span class="hljs-keyword">if</span> (s[i] &gt;= <span class="hljs-string">&#x27;a&#x27;</span> <span class="hljs-keyword">and</span> s[i] &lt;= <span class="hljs-string">&#x27;z&#x27;</span>)<br>                    elem += s[i];<br>                <span class="hljs-keyword">else</span><br>                &#123;<br>                    <span class="hljs-keyword">while</span> (s[i] &gt;= <span class="hljs-string">&#x27;0&#x27;</span> <span class="hljs-keyword">and</span> s[i] &lt;= <span class="hljs-string">&#x27;9&#x27;</span>)<br>                        num_s += s[i++];<br>                    i--;<br>                    <span class="hljs-type">int</span> num = <span class="hljs-built_in">atoi</span>(num_s.<span class="hljs-built_in">c_str</span>());<br>                    <span class="hljs-keyword">if</span> (mp[elem].<span class="hljs-built_in">empty</span>())<br>                    &#123;<br>                        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">v</span><span class="hljs-params">(<span class="hljs-number">52</span>, <span class="hljs-number">0</span>)</span></span>;<br>                        mp[elem] = v;<br>                        mp[elem][k] += num;<br>                    &#125;<br>                    <span class="hljs-keyword">else</span><br>                    &#123;<br>                        mp[elem][k] += num;<br>                    &#125;<br>                    <span class="hljs-comment">// debuge: cout &lt;&lt; elem &lt;&lt; &quot; &quot; &lt;&lt; num_s &lt;&lt; endl;</span><br>                    elem = <span class="hljs-string">&quot;&quot;</span>, num_s = <span class="hljs-string">&quot;&quot;</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-type">int</span> Ssum = mp.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-comment">// debug: cout &lt;&lt; Ssum &lt;&lt; endl;</span><br>        <span class="hljs-comment">// 消元:</span><br><br>        <span class="hljs-type">int</span> ind = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> &amp;it : mp)<br>        &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> b = <span class="hljs-number">1</span>; b &lt;= <span class="hljs-number">50</span>; b++)<br>            &#123;<br>                a[ind][b] = it.second[b];<br>            &#125;<br>            ind++;<br>        &#125;<br>        <span class="hljs-type">int</span> R = <span class="hljs-built_in">solve</span>(Ssum);<br>        R = <span class="hljs-built_in">scan</span>(Ssum);<br>        <span class="hljs-comment">// print(Ssum);</span><br>        <span class="hljs-comment">// cout &lt;&lt; R &lt;&lt; endl;</span><br>        mp.<span class="hljs-built_in">clear</span>();<br>        cout &lt;&lt; ((R &lt; n) ? <span class="hljs-string">&quot;Y\n&quot;</span> : <span class="hljs-string">&quot;N\n&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>第四题维护一个点以及相邻两个非零点的数值，因为数据非常大（1e9），还需要对数据进行离散化处理，考试的时候是这样想的，大概用了 30 分钟，感觉自己大概率是没发把这个题 100 分过掉，索性在开 3e5 的数组爆搜拿了 40 分。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//40&#x27;  满分代码还需官网上传题目再完善</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(2)</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(3, <span class="hljs-string">&quot;Ofast&quot;</span>, <span class="hljs-string">&quot;inline&quot;</span>)</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-meta">#<span class="hljs-keyword">define</span> closeSync            \</span><br><span class="hljs-meta">    ios::sync_with_stdio(0); \</span><br><span class="hljs-meta">    cin.tie(0);              \</span><br><span class="hljs-meta">    cout.tie(0)</span><br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">3e5</span> + <span class="hljs-number">9</span>;<br><span class="hljs-type">int</span> a[N];<br><br><span class="hljs-type">int</span> c, m, n;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">search</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> cnt = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= c; i++)<br>    &#123;<br>        <span class="hljs-comment">// cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;;</span><br>        <span class="hljs-keyword">if</span> (a[i] != <span class="hljs-number">0</span>)<br>            cnt++;<br>    &#125;<br>    <span class="hljs-keyword">return</span> cnt;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">opp</span><span class="hljs-params">(<span class="hljs-type">int</span> op)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> l = op - <span class="hljs-number">1</span>, r = op + <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">if</span> (l &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> r &gt; c + <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span>;<br>    <span class="hljs-keyword">if</span> (a[op] &gt;= <span class="hljs-number">5</span>)<br>    &#123;<br>        <span class="hljs-keyword">while</span> (a[l] == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> l &gt;= <span class="hljs-number">0</span>)<br>        &#123;<br>            l--;<br>        &#125;<br>        <span class="hljs-keyword">while</span> (a[r] == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> r &lt;= c)<br>        &#123;<br>            r++;<br>        &#125;<br>        a[op] = <span class="hljs-number">0</span>;<br>        a[l]++;<br>        a[r]++;<br>    &#125;<br>    <span class="hljs-keyword">else</span><br>    &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-built_in">opp</span>(l);<br>    <span class="hljs-built_in">opp</span>(r);<br>&#125;<br><span class="hljs-comment">// map&lt;int, int&gt; mp;</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    closeSync;<br>    cin &gt;&gt; c &gt;&gt; m &gt;&gt; n;<br>    <span class="hljs-type">int</span> ind = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= m; i++)<br>    &#123;<br>        <span class="hljs-type">int</span> t1, t2;<br>        cin &gt;&gt; t1 &gt;&gt; t2;<br>        a[t1] = t2;<br>    &#125;<br><br>    <span class="hljs-keyword">while</span> (n--)<br>    &#123;<br>        <span class="hljs-type">int</span> op;<br>        cin &gt;&gt; op;<br>        a[op]++;<br>        <span class="hljs-built_in">opp</span>(op);<br>        cout &lt;&lt; <span class="hljs-built_in">search</span>() &lt;&lt; <span class="hljs-string">&#x27;\n&#x27;</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>第五题貌似也是维护一个树形结构？或许也能使用线段树解决，当时只剩下 20 分钟的时间，想使用暴力 STL 嵌套来模拟，最后时间不够了，没用写完。</p><p>&#x2F;&#x2F;代码等待官网上传题目再完善</p><p>总结：第一次打 csp，貌似听说同考场有 390 的选手，不由得赞叹校友们的能力，我还缺乏对于模拟过程中的代码的可读性的提高，因为有时候我不知道我在写什么，这也是我第三题浪费了很多时间，再加上机房的电脑没有配置好断点调试，导致我很难找到之前的 bug；另外虽然可带纸质材料，但是基本上是用不上的，翻书更加浪费时间:( 今年还会再打 1~2 次，希望能刷到 400+。</p>]]></content>
    
    
    <categories>
      
      <category>C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>0-Fast R-CNN</title>
    <link href="/2024/03/06/0-Fast-R-CNN/"/>
    <url>/2024/03/06/0-Fast-R-CNN/</url>
    
    <content type="html"><![CDATA[<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h2><p><img src="/../images/0-Fast-R-CNN/image-20240321162127988.png" alt="Fast R-CNN"></p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>​上回说到R-CNN，而Fast R-CNN是原作者在2015年发表的续作，性能比之前的R-CNN块9倍。目标检测要面临的两大问题是（1）需要处理的候选框过多（2）候选框的位置不精确要进行微调。</p><p>​这就不得不提到R-CNN的缺点：训练以及测试的过程复杂，需要大量的RAM，R-CNN网络需要对候选框进行形变操作后再输入CNN网络提取特征，形变会产生一些列问题。</p><p>相比于RCNN主要在以下方面进行了改进：</p><p>（1）Fast RCNN仍然使用selective search选取2000个建议框，但是这里不是将这么多建议框都输入卷积网络中，而是将原始图片输入卷积网络中得到特征图，再使用建议框对特征图提取特征框。这样做的好处是，原来建议框重合部分非常多，卷积重复计算严重，而这里每个位置都只计算了一次卷积，大大减少了计算量</p><p>（2）由于建议框大小不一，得到的特征框需要转化为相同大小，这一步是通过ROI Pooling层来实现的（ROI表示region of interest即目标）</p><p>（3）Fast RCNN里没有SVM分类器和回归器了，分类和预测框的位置大小都是通过卷积神经网络输出的</p><p>（4）为了提高计算速度，网络最后使用SVD代替全连接层</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h4 id="inference过程"><a href="#inference过程" class="headerlink" title="inference过程"></a>inference过程</h4><p><img src="/../images/0-Fast-R-CNN/image-20240321164621432.png" alt="inference过程"></p><ul><li><strong>CNN</strong>：将任意size的图像输入网络，计算整张图的feature maps</li><li><strong>Selective search</strong>：在任意size图片上采用selective search算法提取约2k个候选框</li><li><strong>RoI projection</strong>：在特征图中找到每个候选框对应的特征框（深度和特征图一致）</li><li><strong>RoI pooling</strong>：相当于只有一层的空间金字塔池化SPP，将每个特征框划分为H<em>W个网格（eg: 7</em>7 for VGG16），每个网格中执行最大池化，输出为H<em>W</em>C，特征图深度不变。RoI pooling的输出需要满足下一层全连接层输入要求</li><li><strong>FC+softmax&#x2F;bbox regerssion</strong></li><li><strong>NMS：</strong>利用窗口得分分别对每一类物体进行非极大值抑制剔除重叠候选框，最终得到每个类别中回归修正后的得分最高的窗口</li></ul><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p><img src="/../images/0-Fast-R-CNN/image-20240321170935327.png" alt="损失函数"></p><p>[u≥1]是艾弗森括号，当u≥1，这一项为1，否则，这一项为0</p><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><p>​对训练集中的图片，用selective search提取出每一个图片对应的一些proposal，保存图片路径和bounding box信息</p><p>​对每张图片，根据图片中bounding box的ground truth信息，给该图片的每一个proposal标记类标签，并保存。具体操作：对于每一个proposal，如果和ground truth中的proposal的IOU值超过了阈值（IOU&gt;&#x3D;0.5），则把ground truth中的proposal对应的类标签给原始产生的这个proposal，其余的proposal都标为背景；</p><p>​使用mini-batch&#x3D;128，25%来自非背景标签的proposal，其余来自标记为背景的proposal；</p><p>​训练CNN，最后一层的结果包含分类信息和位置修正信息，用多任务的loss，一个是分类的损失函数，一个是位置的损失函数。</p><p><img src="/../images/0-Fast-R-CNN/image-20240321171524578.png" alt="训练过程"></p><h4 id="测试过程"><a href="#测试过程" class="headerlink" title="测试过程"></a>测试过程</h4><p>​用selective search方法提取图片的2000个proposal，并保存到文件；将图片输入到已经训好的多层全卷积网络，对每一个proposal，获得对应的RoI Conv featrue map；对每一个RoI Conv featrue map，按照3.1中的方法进行池化，得到固定大小的feture map，并将其输入到后续的FC层，最后一层输出类别相关信息和4个boundinf box的修正偏移量；</p><p>​对bounding box 按照上述得到的位置偏移量进行修正，再根据nms对所有的proposal进行筛选，即可得到对该张图片的bounding box预测值以及每个bounding box对应的类和score。</p><p><img src="/../images/0-Fast-R-CNN/image-20240321171625086.png" alt="测试过程"></p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/../images/0-Fast-R-CNN/image-20240321171646898.png" alt="结果"></p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>0-Rich feature hierarchies for accurate object detection and semantic segmentation</title>
    <link href="/2024/03/05/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/"/>
    <url>/2024/03/05/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/</url>
    
    <content type="html"><![CDATA[<h2 id="基于区域的卷积神经网络-R-CNN"><a href="#基于区域的卷积神经网络-R-CNN" class="headerlink" title="基于区域的卷积神经网络 (R-CNN)"></a>基于区域的卷积神经网络 (R-CNN)</h2><p><img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240305204216064.png" alt="R-CNN"></p><p>Rich feature hierarchies for accurate object detection and semantic segmentation </p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>​2013 年 11 月：R-CNN。给定输入图像，R-CNN 首先应用一种称为选择性搜索的机制来提取感兴趣区域(ROI)，其中每个 ROI 是一个可以表示图像中对象边界的矩形。根据场景的不同，ROI 可能多达两千个。之后，每个 ROI 都会通过神经网络产生输出特征。对于每个 ROI 的输出特征，使用支持向量机分类器的集合来确定 ROI 中包含什么类型的对象（如果有）。</p><blockquote><p>2013 年 11 月：R-CNN。给定输入图像，R-CNN 首先应用一种称为选择性搜索的机制来提取感兴趣区域(ROI)，其中每个 ROI 是一个可以表示图像中对象边界的矩形。根据场景的不同，ROI 可能多达两千个。之后，每个 ROI 都会通过神经网络产生输出特征。对于每个 ROI 的输出特征，使用支持向量机分类器的集合来确定 ROI 中包含什么类型的对象（如果有）。<br>2015 年 4 月：Fast R-CNN。原始 R-CNN 在多达 2000 个感兴趣区域中独立计算神经网络特征，而 Fast R-CNN 在整个图像上运行一次神经网络。网络的末端是一种称为 ROIPooling 的新颖方法，它从网络的输出张量中切出每个 ROI，对其进行整形并进行分类。与原始 R-CNN 一样，Fast R-CNN 使用选择性搜索来生成其区域建议。<br>2015 年 6 月：Faster R-CNN。Fast R-CNN 使用选择性搜索来生成 ROI，而 Faster R-CNN 将 ROI 生成集成到神经网络本身中。<br>2017 年 3 月：Mask R-CNN。之前版本的 R-CNN 专注于对象检测，而 Mask R-CNN 添加了实例分割。Mask R-CNN 还用一种名为 ROIAlign 的新方法取代了 ROIPooling，该方法可以表示像素的分数。<br>2019 年 6 月：Mesh R-CNN增加了从 2D 图像生成 3D 网格的功能。</p></blockquote><p>​在本论文研究之前的方法：SIFT和HOG是块方向直方图，但是效果并不好。论文作者通过连接图像分类和目标检测，主要关注了1.使用深度网络定位物体和在小规模的标注数据集上进行大型网络模型的训练。2.与图像分类不同的是检测需要定位一个图像内的许多物体；使用滑动窗口探测器，但是由于网络层次更深，输入图片有非常大的感受野和步长，使得滑动窗口的方法充满挑战，通过操作”recognition using regions”范式，解决了CNN的定位问题。</p><p>​由于结合了Region proposals和CNNs，所以起名<em><strong>R-CNN：Regions with CNN features。</strong></em></p><p>​第二个挑战是标签数据太少，传统方法多是采用无监督与训练，再进行有监督调优，本论文使用了也就是第二个核心贡献是在辅助数据集（ILSVRC）上进行有监督预训练，再在小数据集上针对特定问题进行调优。这是在训练数据稀少的情况下一个非常有效的训练大型卷积神经网络的方法。</p><h3 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h3><h4 id="模型设计"><a href="#模型设计" class="headerlink" title="模型设计"></a>模型设计</h4><p>使用selective search进行<strong>Region proposals</strong>，使用AlexNet对每个region提取一个4096维的特征向量的特征提取，采用各向异性缩放变换。</p><p><img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240306113347937.png" alt="模型设计"></p><p>使用selective search(‘fast mode’模式)得到2000个左右的proposals，进行形状变换后传入CNN得到对应特征，然后将特征向量送入SVM中得到对应的类别。现在，我们得到图像中所有已经打分的region，应用greedy non-maximum suppression，去除重复框。</p><h4 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h4><p>​在ImageNet数据集上对CNN进行预训练。</p><p>​为了将预训练的CNN迁移到本任务(warped proposal windows分类)上，在warped region proposals上使用SGD进行fine-tune，不改变整体的网络结构，只将最后的1000-way分类层改为(N+1)-way，其中N为物体类别数，1为背景类别。SGD的初始学习率为预训练的1&#x2F;10，这样可以进行fine-tune，并且不破坏初始化。batch size为128，其中32个positive windows(所有类别，将IoU≥0.5的proposal视为该类别的positive，其他的为negative)，96个背景windows。 并且，在采样时倾向于采样positive windows，因为与背景相比它们是罕见的。<br>对于R-CNN的分类器，正例就是每一类ground -truth bounding box，IoU小于0.3的作为负类，其他的全部丢弃，不考虑。再训练SVM过程中，为了加速收敛使用了”Hard Negative Mining”策略(将每次loss很大的样本继续送到下一次训练中)。<br><img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240306113750317.png" alt="实验结果"></p><h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><p>​作者在这里提出了一个可视化的想法，核心思想就是让神经元”speak for itself”：挑选出网络中的某个特定uint(当做检测器)，计算所有proposal在这个uint上的输出，按输出大小进行排序之后使用非极大值抑制(NNS)显示那些top-scoring区域。下图为关于CNN的池化层pool5的一个可视化效果。<br><img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240306113906119.png" alt="可视化"></p><h4 id="消融研究"><a href="#消融研究" class="headerlink" title="消融研究"></a>消融研究</h4><p>​证明CNN的表征能力基本来自卷积层</p><h4 id="错误率分析"><a href="#错误率分析" class="headerlink" title="错误率分析"></a>错误率分析</h4><p>​引入Bounding Box Regression可以减少定位问题，fine-tuning可以提高模型的鲁棒性等</p><p><img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240306114037739.png" alt="错误率分析"></p><p><img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240306114137183.png" alt="对物体特征的敏感性"></p><h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>​第一是应用了自底向上的候选框训练的高容量的卷积神经网络进行定位和分割物体。另外一个是使用在标签数据匮乏的情况下训练大规模神经网络的一个方法。论文展示了在有监督的情况下使用丰富的数据集（图片分类）预训练一个网络作为辅助性的工作是很有效的，然后采用稀少数据（检测）去调优定位任务的网络。猜测“有监督的预训练+特定领域的调优”这一范式对于数据稀少的视觉问题是很有效的。</p><p>​最后，论文能得到这些结果，将计算机视觉中经典的工具和深度学习(自底向上的区域候选框和卷积神经网络）组合是非常重要的。而不是违背科学探索的主线，这两个部分是自然而且必然的结合。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1-基础部分-3-读论文</title>
    <link href="/2024/03/05/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    <url>/2024/03/05/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/</url>
    
    <content type="html"><![CDATA[<h1 id="学位论文"><a href="#学位论文" class="headerlink" title="学位论文"></a>学位论文</h1><p>摘要<br>第一章绪论<br>第二章材料与方法<br>第三章结果与讨论(1)<br>第四章结果与讨论(2)<br>第五章结果与讨论(3)<br>结论<br>参考文献<br>攻读硕士学位期间取得创新性成果<br>学位论文原创性声明及使用授权<br>致谢<br>个人简历</p><p><img src="/../images/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/1709190804696.png"></p><h2 id="功能："><a href="#功能：" class="headerlink" title="功能："></a>功能：</h2><p>·题目→点睛，文章的极致浓缩;题目信息量≥50%文章的内容·</p><p>·摘要→浓缩的论文（重要程度超过论文主体)</p><p>·关键词→漂流瓶上的GPS(频道要一致)</p><p>·引言→背景（目的) -现状（那个等待修补的重要拼图）-创新性（我了解了拼图的基本信息)-方法（路线图)。</p><p>·材料与方法→我们有什么(有&#x3D;限制，思维、方法、技术)</p><p>·结果与讨论→我发现了什么，我的发现怎么样?</p><p>·结论→有得有失</p><p>·参考文献→一封感谢信（定位)</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>题目的扩写(检查)<br>内容的缩写（方法)<br>四要素全是基本要求<br>摘要是论文主体的浓缩<br>简洁，要有取舍、详略</p><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>·通过对题目拆解得来<br>·题目:通过对关键字组合而来。<br>·准确，过于泛没有针对性。<br>·冷，过于生僻无人认<br>·精准＋宽泛<br>·技术在进步，关键词可能没那么重要了?</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>·引言决定论文的格局</p><p>·以为是套路，其实是逻辑</p><p>·背景</p><p>·进展</p><p>·存在的问题</p><p>·我的解决方案</p><p>·引言是你思考的逻辑顺序</p><h2 id="结果与讨论"><a href="#结果与讨论" class="headerlink" title="结果与讨论"></a>结果与讨论</h2><p>·科技论文中，撰写结果与讨论的目的可总结为:用论据论证论点。<br>·拆分1段完整的结果与讨论，我们会发现，其中一定包括以下几点:</p><p>​1）指出图表;2)结果描述;3)规律总结;4)对比优劣&#x2F;机理阐明;5)给出结论。<br>·以上5部分除了第5部分外，其他4个部分基本上是一定要有的。这5个部分其实也反应了作者在做研究时，对研究本身一个“由表及里”逐步了解的一个过程。</p><p><img src="/../images/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/1709193287719.png"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>·完美的结论应是超出论文本身的内容</p><p>·提炼的、升华的</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>·真正对本研究有用的文献(实事求是)<br>·重量级相当的文献<br>·注意格式<br>·40%的内容来自于参考文献</p><h2 id="方法来源"><a href="#方法来源" class="headerlink" title="方法来源"></a>方法来源</h2><p><strong>三遍阅读法方法</strong>是ACM和IEEE Fellow 剑桥大学计算机教授Srinivasan Keshav的论文阅读技巧</p><h3 id="第一遍：该不该读？"><a href="#第一遍：该不该读？" class="headerlink" title="第一遍：该不该读？"></a>第一遍：该不该读？</h3><p>1.阅读标题、摘要和简介<br>2.忽略内容，读一读文章中的每个小标题<br>3.如果数学内容，先大致浏览，确定其理论基础<br>4.读结论<br>5.浏览参考文献，如果有读过的，勾选出来<br>第一遍阅读后应得出结论：</p><p>文章分类<br>文章背景<br>结论的正确性<br>所做出的主要贡献<br>结构清晰度</p><h3 id="第二遍：抓住要点，暂略细节"><a href="#第二遍：抓住要点，暂略细节" class="headerlink" title="第二遍：抓住要点，暂略细节"></a>第二遍：抓住要点，暂略细节</h3><p>时间：About 1 hour<br>1.过程中，仔细查看论文的图表，关注细节<br>2.标记论文中涉及的、并未读过的参考文献，之后做进一步阅读<br>第二遍阅读后应做到：</p><p>掌握内容，总结主旨</p><h3 id="第三遍：重构论文，注重细节"><a href="#第三遍：重构论文，注重细节" class="headerlink" title="第三遍：重构论文，注重细节"></a>第三遍：重构论文，注重细节</h3><p>跟随作者的思路，在脑海里重现论文内容<br>细节！细节！细节！<br>第三遍阅读后应做到：</p><p>看出论文的创新点<br>找到隐含假设<br>捕捉试验和技术分析中的潜在问题<br>引文缺失</p><h3 id="读，必须要读，不然从哪里开始学习入门呢？"><a href="#读，必须要读，不然从哪里开始学习入门呢？" class="headerlink" title="读，必须要读，不然从哪里开始学习入门呢？"></a>读，必须要读，不然从哪里开始学习入门呢？</h3><p>不过，读文献也要讲方法讲策略，否则读完就忘，也起不到任何作用。个人建议</p><ol><li>开始的时候找一个领域内相关的综述，越新越好，发表的档次越高越好（可以看影响因子）</li><li>仔细读完综述，做笔记，写下自己对该研究领域的认知，包括领域现状、关键原理、重点热点方向、面临的挑战等</li><li>挑一个感兴趣的方向，最好结合自己所在课题组的实际情况，以能完成为前提</li><li>找出该方向上的最新工作，不限于综述里引用的，最好能找到 10-15 篇，档次尽量不要太差</li><li>仔细读完这些文章，总结提炼出每一个工作的 idea，包括研究背景、要解决的问题、前人的方法和局限、作者提出的新方法、新方法为什么能避免前人的问题、关键数据和证明等</li><li>横向比较这十来个工作的 idea，找到其中的共性和不同，尤其是共性的研究背景和要解决的问题，作者提出的不同的新方法</li><li>此时对领域应该已经有了一个较全面的把握，可以开始构思自己的 idea 了，注意依然要包含上面的要素</li><li>拿自己的 idea 去跟导师讨论确认</li></ol><h1 id="time"><a href="#time" class="headerlink" title="{time}"></a>{time}</h1><p>这篇文章主要是想给大家分享一些论文阅读的技巧。网上相关的经验贴其实很多，我主要是看了沈向洋老师和吴恩达老师的两个视频，结合自己日常的一些体会，写下的这篇文章，两位老师的关于论文的视频我就放在文末了。</p><p>本篇文章的目录为</p><blockquote><p><em>论文的常见框架</em><br><em>读论文的四个层次</em><br><em>读论文的三个阶段</em><br><em>读论文的不同部分应该得出的结论</em><br><em>读论文带着的12个问题</em><br><em>读论文的笔记模板</em></p></blockquote><h2 id="论文的常见框架"><a href="#论文的常见框架" class="headerlink" title="论文的常见框架"></a>论文的常见框架</h2><p>一般的论文都会按顺序包含一下几个部分：</p><ul><li>title</li><li>keywords</li><li>introduction</li><li>related work</li><li>method</li><li>experimental results and discussion</li><li>summary&#x2F;conclusion</li><li>reference</li><li>appendix</li></ul><h2 id="读论文的四个层次（沈向洋）"><a href="#读论文的四个层次（沈向洋）" class="headerlink" title="读论文的四个层次（沈向洋）"></a><strong>读论文的四个层次（沈向洋）</strong></h2><ul><li>消极阅读（passive reading），即大概知道文章讲了什么；</li><li>积极阅读（ active reading），主动思考这些知识有什么用；</li><li>批判性阅读（critical reading），思考这篇文章是否言之成理；</li><li>创造性阅读（creative reading），搞清楚文章对接下来的工作有什么帮助。</li></ul><h2 id="读论文的三个阶段"><a href="#读论文的三个阶段" class="headerlink" title="读论文的三个阶段"></a>读论文的三个阶段</h2><p>不是所有的论文一拿到就直接从头读到尾的，特别是现在论文这么多，这样做也不现实，所以读论文其实应该分步骤去读，先粗略地看一下，看看这是不是你感兴趣的文章；再简略地过一下全文，尤其是那些很多数学的部分，可以先跳过，大部分的论文看到这就行了，这个时候就基本上已经了解了论文的创新点；精读论文，还可以看一下开源的代码来帮助理解，知道论文的具体的实现的细节，如果是一些特别经典或者是你的工作主要就是基于这篇论文做的，那是肯定得精读的，即使可能得花掉一个星期甚至一个月的时间。具体的每个阶段看的内容如下：</p><ul><li>第一阶段（速读）：Title、Author、Abstract、Figure and Table(Introduction)(沈向洋觉得是论文的前两页，吴恩达觉得看完摘要要先看图表，这对于计算机来说确实如此）—–（快速知道论文讲了什么）。我个人觉得拿到一篇论文之后，先看题目、摘要、结论、图表会好一点，然后如果你不太了解这个领域，想要了解一下作者的motivation，那就可以把引言也读了。</li><li>第二解决（精读）：Read but skim math，这个解决算是对论文的精读，在这个部分可以对论文进行批判性和创造性地阅读，也就是要对论文进行否定、质疑，仔细挑毛病。在读论文的时候可以带着这些问题：</li></ul><p>1、论文是否正确、真正地解决了问题？</p><p>2、作者论文中所用方法是否有局限性？对论文有了足够的了解之后，如果发现论文中提 到的想法非常优秀，那么要创造性地思考你能用这篇论文做什么</p><p>3、如果所读的论文没有解决问题，那么我能解决么？</p><p>4、我能采用比论文中更简单的方法解决么？</p><ul><li>第三阶段（研读）：论文的每个部分的具体细节包括代码实现，一般论文特别经典的时候才需要。不过需要主要的是，即使论文很经典，也不见得是每个部分都需要研读，论文的一些部分可能发展到现在已经不 make sense了，比如AlexNet论文里面的各种trick，像这种就没有必要读了。</li></ul><h2 id="读论文的不同部分要得到的结论"><a href="#读论文的不同部分要得到的结论" class="headerlink" title="读论文的不同部分要得到的结论"></a>读论文的不同部分要得到的结论</h2><p>1、Abstract</p><ul><li>作者想解决什么问题？ question</li><li>作者通过什么理论&#x2F;模型来解决这个问题？method</li><li>作者给出的答案是什么？ answer</li></ul><p>2、Introduction</p><ul><li>作者为什么研究这个课题？</li><li>目前这个课题的研究进行到了哪一阶段？</li><li>作者使用的理论是基于哪些假设？</li></ul><p>3、Conclusion</p><ul><li>这篇文章存在哪些缺陷？</li><li>作者关于这个课题的构思有哪几点？</li></ul><p>4、Table and Figure</p><ul><li>文章阶段性的成果</li></ul><p>5、Method and experiment</p><ul><li>研究的数据从哪里来？</li><li>研究中用到的重要指标有哪些？</li><li>模型分哪几步？ 每一步分别得出了什么结论？</li></ul><h2 id="读论文带着的12个问题"><a href="#读论文带着的12个问题" class="headerlink" title="读论文带着的12个问题"></a>读论文带着的12个问题</h2><p>我觉得带着论文去读问题效率会高很多。当然不是看所有的论文都是带着这些问题，可能有一些论文你自己看它已经有自己的目的了，那你就根据自己的情况来就好了，下面的是普遍性的。</p><ol><li>What is the problem addressed in the paper? What‘s the input and output? （当然不是每篇论文都有严格的输入输出）</li><li>Is this a new problem? If it is a new problem, why does it matter? If it is not an entirely new problem, why does it still matter?</li><li>What is the scientific hypothesis that the paper is trying to verify? Address what new knowledge is advanced in the pape</li><li>What are the key related works and who are the key people working on this topic? （比如说对于Adam来说，其他的一些优化算法比如说SGD、Adagrad、Rmsprop等就可以稍微回想一下）</li><li>What is the key Of the proposed solution in the paper?</li><li>How are the experiments designed?（虽然一般论文的实验结果都是说自己的结果要好，但是也要注重实验，一来是可以参考别人是怎么设置实验的，还有就是看看作者的实验设置是否合理）</li><li>What datasets are built&#x2F;used for the quantitative evaluation? Is the code open source?</li><li>Is the scientific hypothesis well supported by evidence in the experiments? Are the claims in the paper well supported by the experimental results?</li><li>What are the contributions of the paper?</li><li>What should&#x2F;could be done next? （limitation of this paper）</li><li>Are there important related papers I missed?</li><li>What question should I ask the author( Any query？？？ 比如说你哪里没看懂或者觉得不合理的）</li></ol><h2 id="读论文的笔记模板"><a href="#读论文的笔记模板" class="headerlink" title="读论文的笔记模板"></a>读论文的笔记模板</h2><p>我觉得在阅读论文的过程中，记录一些笔记是非常重要的，包括在论文中进行一些标注，以及自己写成笔记的形式。论文中的标注大家可能自己有自己的方法，这里就不介绍了，这里主要介绍一下我平时写论文笔记的过程中整理的笔记模板，虽然用这些模板记录真的很花时间，但是等到以后你突然回过头再看这篇论文的时候，有了这些笔记就方便很多了，正所谓：“磨刀不误砍柴工”。</p><p><strong>0 论文标题</strong></p><p>一句话概括论文的主要内容（用什么样的方法解决了什么样的问题？）</p><p><strong>1 论文的结构(简要概括)</strong></p><p><strong>按标题的顺序</strong>写一下论文的每个部分大概写了那些内容，每个部分大概用一两句话或者几句话来概括。下面给的每个部分的问题不一定作者都提到了，比如说文章的缺陷，如果没提到大家可以不用在这个部分写，也就是<strong>论文的结构这一部分只写论文里面提到的</strong>，<strong>而且只是一个相对简要的概括，所以可能有些问题会和下面的其他部分重复</strong>。或者大家觉得还有其他重要的问题但是我下面没有提到的大家也可以自己补充。<strong>写这个的主要目的是自己了解一些各种论文结构。</strong></p><p>不一定每篇论文当中都是下面的几个部分，大家根据实际的论文去总结，有些论文包含其他部分的大家就根据自己的理解去总结。</p><p><strong>1.1 Abstract</strong></p><ul><li>作者想解决什么问题？</li><li>作者通过什么理论&#x2F;模型来解决这个问题？</li><li>作者给出的答案是什么？</li></ul><p><strong>1.2 Introduction</strong></p><ul><li>作者为什么研究这个课题？</li><li>目前这个课题的研究进行到了哪一阶段？存在哪些缺陷？作者是想通过本文解决哪个问题？</li><li>作者使用的理论是基于哪些假设？</li></ul><p><strong>1.3 Related work</strong></p><ul><li>和作者这篇论文相关的工作有哪些？</li><li>之前工作的优缺点是什么？</li><li>作者主要是对之前的哪个工作进行改进？</li></ul><p><strong>1.4 Theoretical Analysis</strong></p><ul><li>作者是用什么理论证明了自己的方法在理论上也是有保障的？</li></ul><p><strong>1.5 Experiment</strong></p><ul><li>作者是在哪些数据集或者说场景下进行了测试？</li><li>实验中的重要指标有哪些？</li><li>文章提出的方法在哪些指标上表现好？在哪些指标上表现不好？</li><li>在实验的设置过程中作者有没有提到自己用到了什么trick？</li></ul><p><strong>1.6 Conclusion</strong></p><ul><li>这篇论文最大的贡献是什么？</li><li>论文中的方法还存在什么问题？</li><li>作者觉得还可以怎么改进？</li></ul><p><strong>2 论文想要解决的问题？</strong></p><p><strong>2.1 背景是什么？</strong></p><p><strong>2.2 之前的方法存在哪些问题</strong></p><p><strong>2.3 输入和输出是什么？</strong></p><p><strong>3 论文研究的是否是一个新问题</strong></p><p><strong>4 论文试图验证的科学假设</strong></p><p><strong>5 相关的关键人物与工作</strong></p><p><strong>5.1 之前存在哪些相关的工作</strong></p><p><strong>5.2 本文是对哪个工作进行的改进</strong></p><p><strong>5.3 这个领域的关键研究者</strong></p><p><strong>6 论文提出的解决方案的关键</strong></p><p><strong>7 论文的解决方案有完备的理论证明吗</strong></p><p><strong>8 实验设计</strong></p><p><strong>8.1用到了哪些数据集</strong></p><p><strong>8.2与什么算法进行了比较</strong></p><p><strong>8.3评价指标是什么</strong></p><p><strong>8.4有没有什么独特的实验实验设计？</strong></p><p><strong>9 实验支撑</strong></p><p><strong>9.1 论文的数据集哪里获取</strong></p><p><strong>9.2 源代码哪里可以获取</strong></p><p><strong>9.3 关键代码的讲解</strong></p><p><strong>10 实验结果是否验证了科学假设？</strong></p><p><strong>11 论文最大的贡献</strong></p><p><strong>12 论文的不足之处</strong></p><p><strong>12.1 这篇论文之后的工作有哪些其他的改进</strong></p><p><strong>12.2你觉得可以对这篇论文有什么改进</strong></p><p><strong>13 重要的相关论文</strong></p><p><strong>14 不懂之处</strong></p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>基础部分</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0-Deep Residual Learning for Image Recognition</title>
    <link href="/2024/03/05/0-Deep-Residual-Learning-for-Image-Recognition/"/>
    <url>/2024/03/05/0-Deep-Residual-Learning-for-Image-Recognition/</url>
    
    <content type="html"><![CDATA[<h2 id="用于图像识别的深度残差学习ResNet"><a href="#用于图像识别的深度残差学习ResNet" class="headerlink" title="用于图像识别的深度残差学习ResNet"></a>用于图像识别的深度残差学习ResNet</h2><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305100734044.png" alt="ResNet"></p><blockquote><p>文章发表于2015年</p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>越深的神经网络训练起来越发困难，利用残差学习框架，能够简化深层的的网络训练。根据输入来学习残差函数而非原神函数，在ImageNet数据集使用了152曾的网络来评价残差网络，具有很低的复杂度，并且多个ensemble在测试集上的错误率很低。</p><p>在深度学习神经网络的训练中，层次越深，训练越困难，优化越困难，并且会出现梯度消失&#x2F;爆炸等问题阻碍网络收敛，使用归一初始化（normalized initialization）和中间归一化（intermediate normalization）在很大程度上解决了这一问题，使得在前数十层的网络在反向传播的随机梯度下降（SGD）上能够收敛。</p><p>层数更深后，精度饱和，训练模型迅速变差</p><p>​残差神经网络（也称为残差网络或<strong>ResNet</strong>）是一种深度学习模型，其中权重层参考层输入学习残差函数。</p><p>​残差学习框架通过引入残差学习的概念，使得训练比以往更深的网络变得更加容易。这种框架允许网络学习残差映射，即学习残差函数而不是直接学习底层特征映射。通过这种方式，网络可以更轻松地学习残差，从而减轻了训练深度网络时出现的梯度消失或梯度爆炸等问题。</p><h3 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h3><p>​在ImageNet 2015比赛之前，2012 年 ImageNet 开发的AlexNet模型是一个八层卷积神经网络。牛津大学视觉几何小组 (VGGNet) 于 2014 年开发的神经网络通过堆叠 3×3 卷积层达到了 19 层的深度，然而，堆叠更多层会导致训练精度急剧下降，这被称为“退化”问题。</p><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305110540544.png" alt="梯度下降"></p><p>如上图所示，将20层神经网络加深到56层之后，模型的training error和test error反而更高了。</p><p>论文提出了一个解决方案，就是使用深度残差网络：</p><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305161546348.png" alt="深度残差网络"></p><p>​从深层网络出发，深层网路&#x3D;浅层网络+附加层，如果浅层网络已经做的非常好了，附加层只会进行一些微小的改动，得到的结果就是网络随着深度的增加，准确率会上升，而不是degredation描述的下降。</p><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305162027063.png" alt="残差网络Residual Network"></p><p>​从图中我们可以看到ResNet中的快捷连接有实线和虚线，实线表示输入输出维度相同，虚线表示维度不同。对于 ResNet，当输入维度小于输出维度时，有3 种类型的快捷连接方式：</p><ul><li>(A) Shortcut 执行恒等映射，使用额外的零填充来增加维度。因此，没有额外的参数。</li><li>(B) 投影快捷方式仅用于增加维度，其他快捷方式是恒等映射。需要额外的参数。</li><li>(C) 所有捷径都是投影。额外的参数比（B）的要多。</li></ul><p>实验表明方式C的精度最高，但作者建议使用方式B，因为C的计算量和参数量都有所增加。</p><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305163658461.png" alt="Table 3. Error rates"></p><h3 id="实验方法："><a href="#实验方法：" class="headerlink" title="实验方法："></a>实验方法：</h3><ul><li>将图像扩充到[256,480]之间，再resize为224 × 224</li><li>使用颜色增强</li><li>使用BN</li><li>将学习率通过乘0.1减小(这个方法现在已经不太用了，因为不知道具体在什么时候乘这个0.1，有的时候可能乘早了，在晚一点乘效果会更好，图中断崖式下降的地方就是学习率乘了0.1的地方)</li><li>没有使用dropout操作(dropout对卷积层的正则化作用很小：卷积层的参数必FC少很多，本身不需要正则化；同时，特征图编码的是空间的关系，他们之间是高度相关的，这也导致了dropout的失效)</li><li>在测试中使用了10-crop(10-crop是指在test的时候，从原始图片及翻转后的图片中，从四个corner和一个center各crop一个(224,224)的图片，一次是5张，镜像之后再操作一次就是10张。然后对这10张图片进行分类，对10次预测结果做average)</li><li>使用了{224，256，384，480，640}这5种不同的分辨率</li></ul><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305164121060.png" alt="实验结果"></p><p><img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305164201058-17096281334771.png" alt="与普通网络的对比结果"></p><p>当使用普通网络时，由于退化问题，18 层的结果优于 34 层；使用 ResNet 时，34 层优于 18 层，通过快捷连接解决了梯度消失问题。(比较 18 层普通网络和 18 层 ResNet，没有太大区别。这是因为浅层网络不会出现梯度消失问题。)</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>markdown中的数学公式</title>
    <link href="/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"/>
    <url>/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<p>设置 math: true</p><h3 id="符号大全"><a href="#符号大全" class="headerlink" title="符号大全"></a>符号大全</h3><table><thead><tr><th align="left">写法</th><th align="center">符号</th><th align="left">备注</th></tr></thead><tbody><tr><td align="left">\sin(x)</td><td align="center">$$\sin(x)$$</td><td align="left">正弦函数</td></tr><tr><td align="left">\log(x)</td><td align="center">$$\log(x)$$</td><td align="left">对数函数</td></tr><tr><td align="left">\sum_{i&#x3D;0}^n</td><td align="center">$$\sum_{i&#x3D;0}^n$$</td><td align="left">累加和</td></tr><tr><td align="left">\prod_{i&#x3D;0}^n</td><td align="center">$$\prod_{i&#x3D;0}^n$$</td><td align="left">累积乘</td></tr><tr><td align="left">\displaystyle</td><td align="center">$$\displaystyle$$</td><td align="left">块显示</td></tr><tr><td align="left">\ldots</td><td align="center">$$\ldots$$</td><td align="left">底部省略号</td></tr><tr><td align="left">\cdots</td><td align="center">$$\cdots$$</td><td align="left">中部省略号</td></tr><tr><td align="left">\int_a^b</td><td align="center">$$\int_a^b$$</td><td align="left">积分符号</td></tr><tr><td align="left">\lim</td><td align="center">$$\lim$$</td><td align="left">极限函数</td></tr><tr><td align="left">\to</td><td align="center">$$\to$$</td><td align="left">箭头</td></tr><tr><td align="left">\vec{a}</td><td align="center">$$\vec{a}$$</td><td align="left">矢量a</td></tr><tr><td align="left">90^\circ</td><td align="center">$$90^\circ$$</td><td align="left">度数的圆圈</td></tr><tr><td align="left">\uparrow</td><td align="center">$$\uparrow$$</td><td align="left">上箭头</td></tr><tr><td align="left">\Uparrow</td><td align="center">$$\Uparrow$$</td><td align="left">双上箭头</td></tr><tr><td align="left">\partial y</td><td align="center">$$\partial y$$</td><td align="left">导数&#x2F;偏导</td></tr><tr><td align="left">\infty</td><td align="center">$$\infty$$</td><td align="left">无穷</td></tr><tr><td align="left">\Pi</td><td align="center">$$\Pi$$</td><td align="left">累乘</td></tr><tr><td align="left">\sqrt{x}</td><td align="center">$$\sqrt{x}$$</td><td align="left">求平方根</td></tr><tr><td align="left">\overline{a+b}</td><td align="center">$$\overline{a+b}$$</td><td align="left">上划线</td></tr><tr><td align="left">\underline{a+b}</td><td align="center">$$\underline{a+b}$$</td><td align="left">下划线</td></tr><tr><td align="left">\overbrace{a+b}</td><td align="center">$$\overbrace{a+b}$$</td><td align="left">上括号</td></tr><tr><td align="left">\underbrace{a+b}</td><td align="center">$$\underbrace{a+b}$$</td><td align="left">下括号</td></tr><tr><td align="left">\pm{a}{b}</td><td align="center">$$\pm{a}{b}$$</td><td align="left">正负号</td></tr><tr><td align="left">\mp{a}{b}</td><td align="center">$$\mp{a}{b}$$</td><td align="left">负正号</td></tr><tr><td align="left">\times</td><td align="center">$$\times$$</td><td align="left">乘法</td></tr><tr><td align="left">\cdot</td><td align="center">$$\cdot$$</td><td align="left">点乘</td></tr><tr><td align="left">\ast</td><td align="center">$$\ast$$</td><td align="left">星乘</td></tr><tr><td align="left">\div</td><td align="center">$$\div$$</td><td align="left">除法</td></tr><tr><td align="left">\frac{1}{5}</td><td align="center">$$\frac{1}{5}$$</td><td align="left">分数</td></tr><tr><td align="left">\drac{1}{5}</td><td align="center">$$已废弃$$</td><td align="left">分数，字体更大</td></tr><tr><td align="left">\leq</td><td align="center">$$\leq$$</td><td align="left">小于等于</td></tr><tr><td align="left">\not</td><td align="center">$$\not$$</td><td align="left">非</td></tr><tr><td align="left">\geq</td><td align="center">$$\geq$$</td><td align="left">大于等于</td></tr><tr><td align="left">\neq</td><td align="center">$$\neq$$</td><td align="left">不等于</td></tr><tr><td align="left">\nleq</td><td align="center">$$\nleq$$</td><td align="left">不小于等于</td></tr><tr><td align="left">\ngeq</td><td align="center">$$\ngeq$$</td><td align="left">不大于等于</td></tr><tr><td align="left">\sim</td><td align="center">$$\sim$$</td><td align="left">相关符号</td></tr><tr><td align="left">\approx</td><td align="center">$$\approx$$</td><td align="left">约等于</td></tr><tr><td align="left">\equiv</td><td align="center">$$\equiv$$</td><td align="left">常等于&#x2F;横等于</td></tr><tr><td align="left">\bigodot</td><td align="center">$$\bigodot$$</td><td align="left">加运算符</td></tr><tr><td align="left">\bigotimes</td><td align="center">$$\bigotimes$$</td><td align="left">乘运算符</td></tr><tr><td align="left">\begin{cases}<br />0&amp; \text{x&#x3D;0}\<br />1&amp; \text{x!&#x3D;0}\end{cases}</td><td align="center">$$\begin{cases}0&amp; \text{x&#x3D;0}\1&amp; \text{x!&#x3D;0}\end{cases}$$</td><td align="left">多行公式</td></tr></tbody></table><h3 id="集合符号"><a href="#集合符号" class="headerlink" title="集合符号"></a>集合符号</h3><table><thead><tr><th>写法</th><th align="center">符号</th><th>备注</th></tr></thead><tbody><tr><td>\in</td><td align="center">$$\in$$</td><td>属于</td></tr><tr><td>\notin</td><td align="center">$$\notin$$</td><td>不属于</td></tr><tr><td>\subset</td><td align="center">$$\subset$$</td><td>真子集</td></tr><tr><td>\not \subset</td><td align="center">$$\not \subset$$</td><td>非子集</td></tr><tr><td>\subseteq</td><td align="center">$$\subseteq$$</td><td>子集</td></tr><tr><td>\supset</td><td align="center">$$\supset$$</td><td>超集</td></tr><tr><td>\supseteq</td><td align="center">$$\supseteq$$</td><td>超集</td></tr><tr><td>\cup</td><td align="center">$$\cup$$</td><td>并集</td></tr><tr><td>\cap</td><td align="center">$$\cap$$</td><td>交集</td></tr><tr><td>\mathbb{R}</td><td align="center">$$\mathbb{R}$$</td><td>实数集</td></tr><tr><td>\emptyset</td><td align="center">$$\emptyset$$</td><td>空集</td></tr></tbody></table><h3 id="希腊符号"><a href="#希腊符号" class="headerlink" title="希腊符号"></a>希腊符号</h3><table><thead><tr><th>写法</th><th align="center">符号</th></tr></thead><tbody><tr><td>\alpha</td><td align="center">α</td></tr><tr><td>\beta</td><td align="center">β</td></tr><tr><td>\gamma</td><td align="center">γ</td></tr><tr><td>\Gamma</td><td align="center">Γ</td></tr><tr><td>\theta</td><td align="center">θ</td></tr><tr><td>\Theta</td><td align="center">Θ</td></tr><tr><td>\delta</td><td align="center">δ</td></tr><tr><td>\Delta</td><td align="center">Δ</td></tr><tr><td>\triangledown</td><td align="center">▽</td></tr><tr><td>\epsilon</td><td align="center">ϵ</td></tr><tr><td>\zeta</td><td align="center">ζ</td></tr><tr><td>\eta</td><td align="center">η</td></tr><tr><td>\kappa</td><td align="center">κ</td></tr><tr><td>\lambda</td><td align="center">λ</td></tr><tr><td>\mu</td><td align="center">μ</td></tr><tr><td>\nu</td><td align="center">ν</td></tr><tr><td>\xi</td><td align="center">ξ</td></tr><tr><td>\pi</td><td align="center">π</td></tr><tr><td>\sigma</td><td align="center">σ</td></tr><tr><td>\tau</td><td align="center">τ</td></tr><tr><td>\upsilon</td><td align="center">υ</td></tr><tr><td>\phi</td><td align="center">ϕ</td></tr><tr><td>\omega</td><td align="center">ω</td></tr></tbody></table><p><strong>小写希腊字母：</strong></p><ul><li>$\alpha$: \alpha$</li><li>$\beta$: \beta$</li><li>$\gamma$: \gamma$</li><li>$\delta$: \delta$</li><li>$\epsilon$: \epsilon$</li><li>$\zeta$: \zeta$</li><li>$\eta$: \eta$</li><li>$\theta$: \theta$</li><li>$\iota$: \iota$</li><li>$\kappa$: \kappa$</li><li>$\lambda$: \lambda$</li><li>$\mu$: \mu$</li><li>$\nu$: \nu$</li><li>$\xi$: \xi$</li><li>$\omicron$: \omicron$</li><li>$\pi$: \pi$</li><li>$\rho$: \rho$</li><li>$\sigma$: \sigma$</li><li>$\tau$: \tau$</li><li>$\upsilon$: \upsilon$</li><li>$\phi$: \phi$</li><li>$\chi$: \chi$</li><li>$\psi$: \psi$</li><li>$\omega$: \omega$</li></ul><p><strong>大写希腊字母：</strong></p><ul><li>$\Alpha$: \Alpha</li><li>$\Beta$: \Beta</li><li>$\Gamma$: \Gamma</li><li>$\Delta$: \Delta</li><li>$\Epsilon$: \Epsilon</li><li>$\Zeta$: \Zeta</li><li>$\Eta$: \Eta</li><li>$\Theta$: \Theta</li><li>$\Iota$: \Iota</li><li>$\Kappa$: \Kappa</li><li>$\Lambda$:\Lambda</li><li>$\Mu$: \Mu</li><li>$\Nu$: \Nu</li><li>$\Xi$: \Xi</li><li>$\Omicron$: \Omicron</li><li>$\Pi$: \Pi</li><li>$\Rho$: \Rho</li><li>$\Sigma$: \Sigma</li><li>$\Tau$: \Tau</li><li>$\Upsilon$: \Upsilon</li><li>$\Phi$: \Phi</li><li>$\Chi$: \Chi</li><li>$\Psi$: \Psi</li><li>$\Omega$: \Omega</li></ul>]]></content>
    
    
    <categories>
      
      <category>markdown</category>
      
    </categories>
    
    
    <tags>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HEXO GUIDE</title>
    <link href="/2023/09/08/hello-world/"/>
    <url>/2023/09/08/hello-world/</url>
    
    <content type="html"><![CDATA[<h2 id="HEXO头操作"><a href="#HEXO头操作" class="headerlink" title="HEXO头操作"></a>HEXO头操作</h2><h3 id="分类文章-文章标签"><a href="#分类文章-文章标签" class="headerlink" title="分类文章\文章标签"></a>分类文章\文章标签</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">并列分类，了解一下：</span><br><span class="hljs-attr">categories:</span><br><span class="hljs-bullet">-</span> [<span class="hljs-string">Linux</span>]<br><span class="hljs-bullet">-</span> [<span class="hljs-string">Tools</span>]<br><br><span class="hljs-string">并列+子分类，再了解一下：</span><br><span class="hljs-attr">categories:</span><br><span class="hljs-bullet">-</span> [<span class="hljs-string">Linux</span>, <span class="hljs-string">Hexo</span>]<br><span class="hljs-bullet">-</span> [<span class="hljs-string">Tools</span>, <span class="hljs-string">PHP</span>]<br><br><span class="hljs-attr">categories:</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Diary</span><br><span class="hljs-attr">tags:</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">PS3</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Games</span><br></code></pre></td></tr></table></figure><h3 id="归档文章"><a href="#归档文章" class="headerlink" title="归档文章"></a>归档文章</h3><p>如果只是想让文章在首页隐藏，但仍<strong>需要在归档分类页里展示</strong>，可以在文章开头 <a href="https://hexo.io/zh-cn/docs/front-matter">front-matter (opens new window)</a>中配置 <code>archive: true</code> 属性。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">文章标题</span><br><span class="hljs-attr">index_img:</span> <span class="hljs-string">/img/example.jpg</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2019-10-10 10:00:00</span><br><span class="hljs-attr">archive:</span> <span class="hljs-literal">true</span><br><span class="hljs-meta">---</span><br><span class="hljs-string">以下是文章内容</span><br></code></pre></td></tr></table></figure><h3 id="文章排序"><a href="#文章排序" class="headerlink" title="文章排序"></a>文章排序</h3><p>如果想手动将某些文章固定在首页靠前的位置，可以在安装 <code>hexo-generator-index</code> &gt;&#x3D; 2.0.0 版本的情况下，在文章开头 <a href="https://hexo.io/zh-cn/docs/front-matter">front-matter (opens new window)</a>中配置 <code>sticky</code> 属性：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">文章标题</span><br><span class="hljs-attr">index_img:</span> <span class="hljs-string">/img/example.jpg</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2019-10-10 10:00:00</span><br><span class="hljs-attr">sticky:</span> <span class="hljs-number">100</span><br><span class="hljs-meta">---</span><br><span class="hljs-string">以下是文章内容</span><br></code></pre></td></tr></table></figure><p><code>sticky</code> 数值越大，该文章越靠前，达到类似于置顶的效果，其他未设置的文章依然按默认排序。</p><h3 id="文章在首页的封面图"><a href="#文章在首页的封面图" class="headerlink" title="文章在首页的封面图"></a>文章在首页的封面图</h3><p>对于单篇文章，在文章开头 <a href="https://hexo.io/zh-cn/docs/front-matter">front-matter (opens new window)</a>中配置 <code>index_img</code> 属性。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">文章标题</span><br><span class="hljs-attr">tags:</span> [<span class="hljs-string">Hexo</span>, <span class="hljs-string">Fluid</span>]<br><span class="hljs-attr">index_img:</span> <span class="hljs-string">/img/example.jpg</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2019-10-10 10:00:00</span><br><span class="hljs-meta">---</span><br><span class="hljs-string">以下是文章内容</span><br></code></pre></td></tr></table></figure><p>和 Banner 配置相同，<code>/img/example.jpg</code> 对应的是存放在 <code>/source/img/example.jpg</code> 目录下的图片（目录也可自定义，但必须在 source 目录下）。</p><p>也可以使用外链 Url 的绝对路径。</p><p>如果想统一给文章设置一个默认图片（文章不设置 <code>index_img</code> 则默认使用这张图片），可在<strong>主题配置</strong>中设置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">post:</span><br>  <span class="hljs-attr">default_index_img:</span> <span class="hljs-string">/images/example.jpeg</span><br></code></pre></td></tr></table></figure><p>当 <code>default_index_img</code> 和 <code>index_img</code> 都为空时，该文章在首页将不显示图片。</p><h3 id="文章页顶部大图"><a href="#文章页顶部大图" class="headerlink" title="文章页顶部大图"></a>文章页顶部大图</h3><p>默认显示<strong>主题配置</strong>中的 <code>post.banner_img</code>，如需要设置单个文章的 Banner，在 <a href="https://hexo.io/zh-cn/docs/front-matter">front-matter (opens new window)</a>中指定 <code>banner_img</code> 属性。</p><p>本地图片存放位置同上。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">文章标题</span><br><span class="hljs-attr">tags:</span> [<span class="hljs-string">Hexo</span>, <span class="hljs-string">Fluid</span>]<br><span class="hljs-attr">index_img:</span> <span class="hljs-string">/img/example.jpg</span><br><span class="hljs-attr">banner_img:</span> <span class="hljs-string">/img/post_banner.jpg</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2019-10-10 10:00:00</span><br><span class="hljs-meta">---</span><br><span class="hljs-string">以下是文章内容</span><br></code></pre></td></tr></table></figure><h3 id="Tag-插件"><a href="#Tag-插件" class="headerlink" title="Tag 插件"></a>Tag 插件</h3><h4 id="便签"><a href="#便签" class="headerlink" title="#便签"></a><a href="https://hexo.fluid-dev.com/docs/guide/#%E4%BE%BF%E7%AD%BE">#</a>便签</h4><p>在 markdown 中加入如下的代码来使用便签：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% note success %&#125;<br>文字 或者 <span class="hljs-code">`markdown`</span> 均可<br>&#123;% endnote %&#125;<br></code></pre></td></tr></table></figure><p>或者使用 HTML 形式：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;note note-primary&quot;</span>&gt;</span>标签<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></td></tr></table></figure><p>可选便签：</p><h4 id=""><a href="#" class="headerlink" title=""></a><img src="/../images/hello-world/image-20240306164525216.png" alt="标签"></h4><h4 id="行内标签"><a href="#行内标签" class="headerlink" title="行内标签"></a>行内标签</h4><p>在 markdown 中加入如下的代码来使用 Label：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% label primary @text %&#125;<br></code></pre></td></tr></table></figure><p>或者使用 HTML 形式：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;label label-primary&quot;</span>&gt;</span>Label<span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><br></code></pre></td></tr></table></figure><p>可选 Label：</p><p>primary default info success warning danger</p><h4 id="折叠块"><a href="#折叠块" class="headerlink" title="折叠块"></a>折叠块</h4><p>使用折叠块，可以折叠代码、图片、文字等任何内容，你可以在 markdown 中按如下格式：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% fold info @title %&#125;<br>需要折叠的一段内容，支持 markdown<br>&#123;% endfold %&#125;<br></code></pre></td></tr></table></figure><p>info: 和行内标签类似的可选参数 title: 折叠块上的标题</p><h4 id="勾选框"><a href="#勾选框" class="headerlink" title="勾选框"></a>勾选框</h4><p>在 markdown 中加入如下的代码来使用 Checkbox：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% cb text, checked?, incline? %&#125;<br></code></pre></td></tr></table></figure><p>text：显示的文字<br>checked：默认是否已勾选，默认 false<br>incline: 是否内联（可以理解为后面的文字是否换行），默认 false</p><p>示例：</p><div>            <input type="checkbox" disabled >普通示例          </div><div>            <input type="checkbox" disabled checked="checked">默认选中          </div>            <input type="checkbox" disabled >内联示例           后面文字不换行<input type="checkbox" disabled > 也可以只传入一个参数，文字写在后边（这样不支持外联）<h4 id="按钮"><a href="#按钮" class="headerlink" title="按钮"></a>按钮</h4><p>你可以在 markdown 中加入如下的代码来使用 Button：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% btn url, text, title %&#125;<br></code></pre></td></tr></table></figure><p>或者使用 HTML 形式：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn&quot;</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;url&quot;</span> <span class="hljs-attr">title</span>=<span class="hljs-string">&quot;title&quot;</span>&gt;</span>text<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></td></tr></table></figure><p>url：跳转链接<br>text：显示的文字<br>title：鼠标悬停时显示的文字（可选）</p><p><a href="javascript:;">text</a></p><h4 id="组图"><a href="#组图" class="headerlink" title="组图"></a>组图</h4><p>如果想把多张图片按一定布局组合显示，你可以在 markdown 中按如下格式：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs markdown">&#123;% gi total n1-n2-... %&#125;<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>  ![](<span class="hljs-link">url</span>)<br>&#123;% endgi %&#125;<br></code></pre></td></tr></table></figure><p>total：图片总数量，对应中间包含的图片 url 数量<br>n1-n2-…：每行的图片数量，可以省略，默认单行最多 3 张图，求和必须相等于 total，否则按默认样式</p><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p>*其余没有数字的为杂项，由标签分类</p><h2 id="0-论文-md"><a href="#0-论文-md" class="headerlink" title="0-论文.md"></a>0-论文.md</h2><p>基本格式：</p><p>h2论文标题</p><p>h3背景</p><p>h3实验方法</p><p>h3实验结果</p><p>h3结论</p><p>*h3代码分析</p><h2 id="1-基础部分-md"><a href="#1-基础部分-md" class="headerlink" title="1-基础部分.md"></a>1-基础部分.md</h2><h2 id="2-工具与软件-md"><a href="#2-工具与软件-md" class="headerlink" title="2-工具与软件.md"></a>2-工具与软件.md</h2><h2 id="3-机器学习-md"><a href="#3-机器学习-md" class="headerlink" title="3-机器学习.md"></a>3-机器学习.md</h2><h2 id="4"><a href="#4" class="headerlink" title="4-."></a>4-.</h2><h2 id="5"><a href="#5" class="headerlink" title="5-"></a>5-</h2><h2 id="C-代码分析-md"><a href="#C-代码分析-md" class="headerlink" title="C-代码分析.md"></a>C-代码分析.md</h2><p>基本格式：</p><p>h2论文标题</p><p>h3背景</p><p>h3实验方法</p><p>h3代码分析</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-5-TensorFlow</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/</url>
    
    <content type="html"><![CDATA[<h2 id="环境的安装"><a href="#环境的安装" class="headerlink" title="环境的安装"></a>环境的安装</h2><p>首先去conda官网下载  <a href="https://repo.anaconda.com/">conda</a></p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230912155352950.png" alt="选择合适的版本"></p><p>linux系统先使用bash安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo bash xxx.sh<br></code></pre></td></tr></table></figure><p>安装后在pycharm配置conda环境，然后新建AI项目，选择conda，然后在所选择的解释器中安装tensorflow</p><p>选择pycharm自动安装（会自动安装其他依赖，十分方便）</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230912155649291.png" alt="tensorflow安装"></p><p>所需安装：</p><ul><li>conda</li><li>tensorflow</li></ul><p>如果你是N卡，可继续在项目终端中输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install cudatoolkit<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install cudnn<br></code></pre></td></tr></table></figure><p>安装GUP加速</p><h2 id="1-1-人工智能三学派"><a href="#1-1-人工智能三学派" class="headerlink" title="1.1 人工智能三学派"></a>1.1 人工智能三学派</h2><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240305095606298.png" alt="三学派"></p><p>行为主义：机器人的摔倒预测</p><p>符号主义：用公式描述的人工智能，让PC具有了理性思维</p><p>连接主义：仿造人的感性思维</p><h2 id="1-2-神经网络的设计过程"><a href="#1-2-神经网络的设计过程" class="headerlink" title="1.2 神经网络的设计过程"></a>1.2 神经网络的设计过程</h2><p>用神经网络实现鸢尾花的分类：<strong>梯度下降</strong></p><p>目的：找到一组参数w和b，使得损失函数最小。</p><p>梯度：函数对各参数<strong>求偏导</strong>后的向量。 <u>梯度下降的方向是函数减小的方向</u></p><p>梯度下降法：沿损失函数梯度下降的方向，寻找损失函数的最小值，得到最优参数的方法</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240305095654806.png" alt="学习率"></p><p>学习率（lr）：设置过小，收敛缓慢；设置过大，无法收敛（找不到最小值）</p><p>反向传播：从后向前，逐层求损失函数对每层神经元参数的偏导数，迭代更新所有参数。</p><p>损失函数:<br>$$<br>loss &#x3D; （w + 1 )^2<br>$$</p><p>$$<br>\frac{\part loss}{\part w} &#x3D; 2w +2<br>$$</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>w = tf.Variable(tf.constant(<span class="hljs-number">5</span>, dtype=tf.float32))<br>lr = <span class="hljs-number">0.2</span>  <span class="hljs-comment"># 学习率</span><br>epoch = <span class="hljs-number">40</span>   <span class="hljs-comment"># 循环迭代数</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):  <span class="hljs-comment"># for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环40次迭代。</span><br>    <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:  <span class="hljs-comment"># with结构到grads框起了梯度的计算过程。</span><br>        loss = tf.square(w + <span class="hljs-number">1</span>)<br>    grads = tape.gradient(loss, w)  <span class="hljs-comment"># .gradient函数告知谁对谁求导</span><br><br>    w.assign_sub(lr * grads)  <span class="hljs-comment"># .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;After %s epoch,w is %f,loss is %f&quot;</span> % (epoch, w.numpy(), loss))<br><br><span class="hljs-comment"># lr初始值：0.2   请自改学习率  0.001  0.999 看收敛过程</span><br><span class="hljs-comment"># 最终目的：找到 loss 最小 即 w = -1 的最优参数w</span><br><br></code></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python">After <span class="hljs-number">0</span> epoch,w <span class="hljs-keyword">is</span> <span class="hljs-number">2.600000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">36.000000</span><br>After <span class="hljs-number">1</span> epoch,w <span class="hljs-keyword">is</span> <span class="hljs-number">1.160000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">12.959999</span><br>After <span class="hljs-number">2</span> epoch,w <span class="hljs-keyword">is</span> <span class="hljs-number">0.296000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">4.665599</span><br>After <span class="hljs-number">3</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.222400</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">1.679616</span><br>After <span class="hljs-number">4</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.533440</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.604662</span><br>After <span class="hljs-number">5</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.720064</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.217678</span><br>After <span class="hljs-number">6</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.832038</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.078364</span><br>After <span class="hljs-number">7</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.899223</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.028211</span><br>After <span class="hljs-number">8</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.939534</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.010156</span><br>After <span class="hljs-number">9</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.963720</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.003656</span><br>After <span class="hljs-number">10</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.978232</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.001316</span><br>After <span class="hljs-number">11</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.986939</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000474</span><br>After <span class="hljs-number">12</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.992164</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000171</span><br>After <span class="hljs-number">13</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.995298</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000061</span><br>After <span class="hljs-number">14</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.997179</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000022</span><br>After <span class="hljs-number">15</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.998307</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000008</span><br>After <span class="hljs-number">16</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.998984</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000003</span><br>After <span class="hljs-number">17</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999391</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000001</span><br>After <span class="hljs-number">18</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999634</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">19</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999781</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">20</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999868</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">21</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999921</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">22</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999953</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">23</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999972</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">24</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999983</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">25</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999990</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">26</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999994</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">27</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999996</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">28</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999998</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">29</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999999</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">30</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">0.999999</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">31</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">32</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">33</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">34</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">35</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">36</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">37</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">38</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br>After <span class="hljs-number">39</span> epoch,w <span class="hljs-keyword">is</span> -<span class="hljs-number">1.000000</span>,loss <span class="hljs-keyword">is</span> <span class="hljs-number">0.000000</span><br></code></pre></td></tr></table></figure><h2 id="1-3-张量生成"><a href="#1-3-张量生成" class="headerlink" title="1.3 张量生成"></a>1.3 张量生成</h2><p>张量（Tensor：多维数组 &#x2F;列表  ）        阶 ：张量的维数</p><table><thead><tr><th>维数</th><th>阶</th><th>名</th><th>例</th></tr></thead><tbody><tr><td>0-D</td><td>0</td><td>标量 scalar</td><td>s&#x3D;1</td></tr><tr><td>1-D</td><td>1</td><td>向量 vector</td><td>v&#x3D;[1,2,3]</td></tr><tr><td>2-D</td><td>2</td><td>矩阵 matrix</td><td>m&#x3D;[[1,2],[3,4],[5,6]]</td></tr><tr><td>n-D</td><td>n</td><td>张量 tensor</td><td>t&#x3D;[[[[……]]]] (n个)</td></tr></tbody></table><p>数据类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">·tf.<span class="hljs-built_in">int</span>   tf.<span class="hljs-built_in">float</span> ...<br>tf.<span class="hljs-built_in">int</span> <span class="hljs-number">32</span>  , tf.<span class="hljs-built_in">float</span> <span class="hljs-number">32</span>  , tf.<span class="hljs-built_in">float</span> <span class="hljs-number">64</span><br>·tf.<span class="hljs-built_in">bool</span><br>tf.constant([true, false])<br>·tf.string<br>tf.constant(<span class="hljs-string">&quot;Hello world!&quot;</span>)<br></code></pre></td></tr></table></figure><p>创建Tensor</p><p><code>tf.constant(张量内容，dtype=数据类型(可选))</code></p><p>创建全为0的张量 <code>tf.zeros(维度)</code>  </p><p>​ 纬度:一维直接写个数；二维[行，列]；多维[n,m,j,k,…..]</p><p>创建全为1的张量 <code>tf.ones(纬度)</code></p><p>创建全为指定值的张量 <code>tf.fill(维度，指定值)</code></p><p>正态分部的随机数，默认值为0,标准差为1</p><p><code>tf.random.normal(纬度，mean=均值，stddev=标准差)</code></p><p>生成截断式正态分布的随机数</p><p><code>tf.random.truncated_normal(纬度，mean=均值，stddev=标准差)</code></p><p>在正态分布中如果随机生成的数据的取值在（$\mu\pm2\sigma$)</p><p>生成均匀分布的随机数</p><p><code>tf.random.uniform(纬度，minval=最小值，maxval=最大值)</code></p><h2 id="1-4-TF2常用函数"><a href="#1-4-TF2常用函数" class="headerlink" title="1.4 TF2常用函数"></a>1.4 TF2常用函数</h2><p>强制tensor转换为该数据类型<br><code>tf.cast (张量名，dtype=数据类型)</code><br>计算张量维度上元素的最小值<br><code>tf.reduce_min (张量名)</code><br>计算张量维度上元素的最大值<br><code>tf.reduce_max (张量名)</code></p><p>理解axis<br>在一个二维张量或数组中，可以通过调整 axis 等于0或1 控制执行维度。<br> axis&#x3D;0代表跨行（经度，down)，而axis&#x3D;1代表跨列（纬度，across)<br> 如果不指定axis，则所有元素参与计算。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913093248414.png" alt="理解axis"></p><p>计算张量沿着指定维度的平均值<br><code>tf.reduce_mean (张量名，axis=操作轴)</code>  (不指定axis，则对所有元素进行操作)<br>计算张量沿着指定维度的和<br><code>tf.reduce_sum (张量名，axis=操作轴)</code></p><p><code>tf.Variable () </code>将变量标记为“可训练”，被标记的变量会在反向传播<br>中记录梯度信息。神经网络训练中，常用该函数标记待训练参数。<br><code>tf.Variable(初始值)</code><br><code>w = tf.Variable(tf.random.normal([2, 2], mean=0, stddev=1))</code></p><p>TensorFlow中的数学运算<br>对应元素的四则运算：<code>tf.add</code>，<code>tf.subtract</code>，<code>tf.multiply</code>，<code>tf.divide</code>    </p><p> 只有纬度相同的张量才能做四则运算。<br>平方、次方与开方：<code> tf.square</code>，<code>tf.pow</code>，<code>tf.sqrt</code><br>矩阵乘：<code>tf.matmul</code></p><p>切分传入张量的第一维度，生成输入特征&#x2F;标签对，构建数据集<br><code>data = tf.data.Dataset.from_tensor_slices((输入特征, 标签))</code><br>（Numpy和Tensor格式都可用该语句读入数据）</p><p><code>tf.GradientTape</code><br>with结构记录计算过程，gradient求出张量的梯度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> tf.GradientTape( ) <span class="hljs-keyword">as</span> tape:<br>若干个计算过程<br>grad=tape.gradient(函数，对谁求导)<br></code></pre></td></tr></table></figure><p>enumerate是python的内建函数，它可遍历每个元素(如列表、元组<br>或字符串)，组合为：索引 元素，常在for循环中使用。<br><code>enumerate(列表名)</code></p><p>独热编码：在分类问题中，常用独热码做标签，标记类别：1表示是，0表示非。 <code>tf.one_hot (待转换数据, depth=几分类)</code></p><p>当n分类的n个输出 （y0 ，y1, …… yn-1）通过softmax( ) 函数，<br>便符合概率分布了。也就是说，将多个权重占比划分归为1。<br>$$<br>\forall x \ \ P(X &#x3D; x) \in [0,1] 且 \sum_{x}P(X &#x3D; x) &#x3D; 1<br>$$</p><p>assign_sub 赋值操作，更新参数的值并返回。<br>调用assign_sub前，先用 tf.Variable 定义变量 w 为可训练（可自更新）。<br>w.assign_sub (w要自减的内容)</p><p>返回张量沿指定维度最大值的索引<br>tf.argmax (张量名,axis&#x3D;操作轴)     numpy中也有类似函数</p><h2 id="1-5-鸢尾花数据集的读入"><a href="#1-5-鸢尾花数据集的读入" class="headerlink" title="1.5 鸢尾花数据集的读入"></a>1.5 鸢尾花数据集的读入</h2><p>Setosa Iris（狗尾草鸢尾），Versicolour Iris（杂色鸢尾），Virginica Iris（弗吉尼亚鸢尾）</p><p>鸢尾花数据来源：sklearn框架</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913105626307.png" alt="3种鸢尾花"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets <br><span class="hljs-keyword">from</span> pandas <span class="hljs-keyword">import</span> DataFrame<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>x_data = datasets.load_iris().data  <span class="hljs-comment"># .data返回iris数据集所有输入特征</span><br>y_data = datasets.load_iris().target  <span class="hljs-comment"># .target返回iris数据集所有标签</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_data from datasets: \n&quot;</span>, x_data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y_data from datasets: \n&quot;</span>, y_data)<br><br>x_data = DataFrame(x_data, columns=[<span class="hljs-string">&#x27;花萼长度&#x27;</span>, <span class="hljs-string">&#x27;花萼宽度&#x27;</span>, <span class="hljs-string">&#x27;花瓣长度&#x27;</span>, <span class="hljs-string">&#x27;花瓣宽度&#x27;</span>])  <span class="hljs-comment"># 为表格增加行索引（左侧）和列标签（上方）</span><br>pd.set_option(<span class="hljs-string">&#x27;display.unicode.east_asian_width&#x27;</span>, <span class="hljs-literal">True</span>)  <span class="hljs-comment"># 设置列名对齐</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_data add index: \n&quot;</span>, x_data)<br><br>x_data[<span class="hljs-string">&#x27;类别&#x27;</span>] = y_data  <span class="hljs-comment"># 新加一列，列标签为‘类别’，数据为y_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_data add a column: \n&quot;</span>, x_data)<br><br><span class="hljs-comment"># 类型维度不确定时，建议用print函数打印出来确认效果</span><br></code></pre></td></tr></table></figure><h2 id="1-8-神经网络实现鸢尾花的分类"><a href="#1-8-神经网络实现鸢尾花的分类" class="headerlink" title="1.8 神经网络实现鸢尾花的分类"></a>1.8 神经网络实现鸢尾花的分类</h2><p>1.准备数据</p><p>​数据集读入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 从sklearn包datasets 读入数据集：</span><br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> datasets<br>x_data = datasets.load_iris().data <span class="hljs-comment"># 返回iris数据集所有输入特征</span><br>y_data = datasets.load_iris().target <span class="hljs-comment"># 返回iris数据集所有标签</span><br></code></pre></td></tr></table></figure><p>​数据集乱序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">116</span>) <span class="hljs-comment"># 使用相同的seed，使输入特征/标签一一对应</span><br>np.random.shuffle(x_data)<br>np.random.seed(<span class="hljs-number">116</span>)<br>np.random.shuffle(y_data)<br>tf.random.set_seed(<span class="hljs-number">116</span>)<br></code></pre></td></tr></table></figure><p>​分成用不相见的训练集和测试集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x_train = x_data[:-<span class="hljs-number">30</span>]<br>y_train = y_data[:-<span class="hljs-number">30</span>]<br>x_test = x_data[-<span class="hljs-number">30</span>:]<br>y_test = y_data[-<span class="hljs-number">30</span>:]<br></code></pre></td></tr></table></figure><p>​配成【输入特征，标签】对，每次喂入一个batch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(<span class="hljs-number">32</span>)<br>test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="hljs-number">32</span>)<br></code></pre></td></tr></table></figure><p>2.搭建网络</p><p>​定义神经网络中的所有可训练参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">w1 = tf.Variable(tf.random.truncated_normal([ <span class="hljs-number">4</span>, <span class="hljs-number">3</span> ], stddev=<span class="hljs-number">0.1</span>, seed=<span class="hljs-number">1</span>)) <span class="hljs-comment"># 四种特征，三个结果</span><br>b1 = tf.Variable(tf.random.truncated_normal([ <span class="hljs-number">3</span> ], stddev=<span class="hljs-number">0.1</span>, seed=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913140637316.png" alt="输入层与输出层"></p><p>3.参数优化</p><p>​嵌套循环迭代，with结构更新参数，显示当前loss</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch): <span class="hljs-comment">#数据集级别迭代</span><br><span class="hljs-keyword">for</span> step, (x_train, y_train) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_db): <span class="hljs-comment">#batch级别迭代</span><br><span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape: <span class="hljs-comment"># 记录梯度信息</span><br>前向传播过程计算y<br>计算总loss<br>grads = tape.gradient(loss, [ w1, b1 ])<br>w1.assign_sub(lr * grads[<span class="hljs-number">0</span>]) <span class="hljs-comment">#参数自更新</span><br>b1.assign_sub(lr * grads[<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch &#123;&#125;, loss: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, loss_all/<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><p>4.测试效果</p><p>​计算当前参数前向传播后的准确率，显示当前acc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> x_test, y_test <span class="hljs-keyword">in</span> test_db:<br>y = tf.matmul(h, w) + b <span class="hljs-comment"># y为预测结果</span><br>y = tf.nn.softmax(y)<br><span class="hljs-comment"># y符合概率分布</span><br>pred = tf.argmax(y, axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 返回y中最大值的索引，即预测的分类</span><br>pred = tf.cast(pred, dtype=y_test.dtype) <span class="hljs-comment">#调整数据类型与标签一致</span><br>correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)<br>correct = tf.reduce_sum (correct) <span class="hljs-comment"># 将每个batch的correct数加起来</span><br>total_correct += <span class="hljs-built_in">int</span> (correct) <span class="hljs-comment"># 将所有batch中的correct数加起来</span><br>total_number += x_test.shape [<span class="hljs-number">0</span>]<br>acc = total_correct / total_number<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;test_acc:&quot;</span>, acc)<br></code></pre></td></tr></table></figure><p>5.acc &#x2F; loss 可视化（查看效果）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.title(<span class="hljs-string">&#x27;Acc Curve&#x27;</span>) <span class="hljs-comment"># 图片标题</span><br>plt.xlabel(<span class="hljs-string">&#x27;Epoch&#x27;</span>) <span class="hljs-comment"># x轴名称</span><br>plt.ylabel(<span class="hljs-string">&#x27;Acc&#x27;</span>) <span class="hljs-comment"># y轴名称</span><br>plt.plot(test_acc, label=<span class="hljs-string">&quot;$Accuracy$&quot;</span>) <span class="hljs-comment"># 逐点画出test_acc值并连线</span><br>plt.legend()<br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="2-1-预备知识"><a href="#2-1-预备知识" class="headerlink" title="2.1 预备知识"></a>2.1 预备知识</h2><p>函数：</p><p><code>tf.where()</code>  条件语句真返回A，条件语句假返回B<br><code>tf.where(条件语句，真返回A，假返回B)</code></p><p><code>np.random.RandomState.rand()</code>返回一个[0,1)之间的随机数<br><code>np.random.RandomState.rand(维度) #维度为空，返回标量</code></p><p><code>np.vstack()</code>将两个数组按垂直方向叠加<br><code>np.vstack(数组1，数组2)</code></p><p><code>np.mgrid[ ] </code>返回间隔数值点，可同时返回多组， [起始值 结束值)<br><code>np.mgrid[ 起始值 : 结束值 : 步长 ，起始值 : 结束值 : 步长 , … ]</code></p><p><code> x.ravel( )</code> 将x变为一维数组，“把. 前变量拉直”<br><code>np.c\_[ ] </code>使返回的间隔数值点配对<br><code>np.c\_[ 数组1，数组2， … ]</code></p><h2 id="2-2-复杂度学习率"><a href="#2-2-复杂度学习率" class="headerlink" title="2.2 复杂度学习率"></a>2.2 复杂度学习率</h2><p>NN复杂度：多用NN层数和NN参数的个数表示</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913145516199.png" alt="复杂度"></p><p>空间复杂度：<br>    层数 &#x3D; 隐藏层的层数 + 1个输出层<br>    图为2层NN<br>                总参数 &#x3D; 总w + 总b<br>                图中 3x4+4 + 4x2+2 &#x3D; 26</p><p>时间复杂度：<br>    乘加运算次数<br>    左图 3x4 +  4x2 &#x3D; 20</p><p>学习率：</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913150028635.png" alt="学习率"></p><p>指数衰减学习率：<br>可以先用较大的学习率，快速得到较优解，然后逐步减小学习率，使<br>模型在训练后期稳定。<br><code>指数衰减学习率 = 初始学习率 * 学习率衰减率（ 当前轮数 / 多少轮衰减一次 ）</code></p><h2 id="2-3-激活函数"><a href="#2-3-激活函数" class="headerlink" title="2.3 激活函数"></a>2.3 激活函数</h2><p>优秀的激活函数：<br>• 非线性： 激活函数非线性时，多层神经网络可逼近所有函数<br>• 可微性： 优化器大多用梯度下降更新参数<br>• 单调性： 当激活函数是单调的，能保证单层网络的损失函数是凸函数<br>• 近似恒等性： f(x)≈x当参数初始化为随机小值时，神经网络更稳定</p><p>激活函数输出值的范围：<br>• 激活函数输出为有限值时，基于梯度的优化方法更稳定<br>• 激活函数输出为无限值时，建议调小学习率</p><p>Sigmoid函数：<br>$$<br>f(x) &#x3D; \frac{1}{1 + e ^ {-x}}<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913151017142.png" alt="Sigmoid函数"></p><p>特点<br>（1）易造成梯度消失<br>（2）输出非0均值，收敛慢<br>（3）幂运算复杂，训练时间长<br>目前Sigmoid函数因计算复杂，已接近弃用。</p><p>Tanh函数：<br>$$<br>f(x) &#x3D; \frac{1-e^{-2x}}{1+e^{-2x}}<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913151343657.png" alt="Tanh函数"></p><p>特点<br>（1）输出是0均值<br>（2）易造成梯度消失<br>（3）幂运算复杂，训练时间长</p><p>Relu函数：<br>$$<br>f(x) &#x3D; max(x , 0) &#x3D; \begin{cases}0 \quad x&lt;0 \\ x \quad x\geq0 \end{cases}<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913152152906.png" alt="Relu函数"></p><p>优点：<br>（1） 解决了梯度消失问题 (在正区间)<br>（2） 只需判断输入是否大于0，计算速度快<br>（3） 收敛速度远快于sigmoid和tanh</p><p>缺点：<br>（1） 输出非0均值，收敛慢<br>（2） Dead RelU问题：某些神经元可能永远不会被激活，导致相应的参数永远不能被更新。（神经元死亡）</p><p>Leaky Relu函数：<br>$$<br>f(x) &#x3D; max (ax,x)<br>$$<br><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913152543744.png" alt="Leaky Relu函数"></p><p>理论上来讲，Leaky Relu有Relu的所有优点，外加不会有Dead Relu问题，但是在实际操作当中，并没有完全证明Leaky Relu总是好于Relu。</p><p>对于初学者的建议：<br>首选relu激活函数；<br>学习率设置较小值；<br>输入特征标准化，即让输入特征满足以0为均值，1为标准差的正态分布；<br>初始参数中心化，即让随机生成的参数满足以0为均值,$\sqrt{\frac{2}{当前层输入特征个数}}$为标准差的正态分布。</p><h2 id="2-4-损失函数"><a href="#2-4-损失函数" class="headerlink" title="2.4 损失函数"></a>2.4 损失函数</h2><p>预测值（y）与已知答案（_y）的差距</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913153356947.png" alt="主流的三种计算方法"></p><p>均方误差mse：<br>$$<br>MSE(y_,y)&#x3D;\frac{\sum_{i&#x3D;1}^n (y-y_)^2}{n}<br>$$<br><code>lost_mse = tf.reduce_mean(tf.square(y_-y))</code></p><p>自定义函数：</p><p>可在一定程度上优化实际问题中的预测误差。</p><p>交叉熵CE：</p><p>表明了两个概率分布之间的距离，交叉熵越大，表明两个概率分布越远<br>$$<br>H(y_,y) &#x3D; - \sum y_ \times ln\ y<br>$$<br>交叉熵越小，证明数据距离真实越准确。</p><p>softmax与交叉熵的结合：</p><p>在TensorFlow中提供了函数<code>tf.nn.softmax_cross_entropy_with_logits(y_，y)</code>输出先过softmax函数，再计算y与y_的交叉熵损失函数。</p><h2 id="2-5-缓解过拟合"><a href="#2-5-缓解过拟合" class="headerlink" title="2.5 缓解过拟合"></a>2.5 缓解过拟合</h2><p>欠拟合与过拟合</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913162344502.png" alt="欠拟合与过拟合"></p><table><thead><tr><th>欠拟合的解决方法：<br/>增加输入特征项<br/>增加网络参数<br/>减少正则化参数</th><th>过拟合的解决方法：<br/>数据清洗<br/>增大训练集<br/>采用正则化<br/>增大正则化参数</th></tr></thead></table><p>正则化缓解过拟合：</p><p>正则化在损失函数中引入模型复杂度指标，利用给W加权值，弱化了训练<br>数据的噪声（一般不正则化b）</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913162811491.png" alt="正则化"></p><p>正则化的选择<br>L1正则化大概率会使很多参数变为零，因此该方法可通过稀疏参数，即减少参数的数量，降低复杂度。<br>L2正则化会使参数很接近零但不为零，因此该方法可通过减小参数值的大小降低复杂度。</p><p>使用L2正则化缓解过拟合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:  <span class="hljs-comment"># 记录梯度信息</span><br><br>           h1 = tf.matmul(x_train, w1) + b1  <span class="hljs-comment"># 记录神经网络乘加运算</span><br>           h1 = tf.nn.relu(h1)<br>           y = tf.matmul(h1, w2) + b2<br><br>           <span class="hljs-comment"># 采用均方误差损失函数mse = mean(sum(y-out)^2)</span><br>           loss_mse = tf.reduce_mean(tf.square(y_train - y))<br>           <span class="hljs-comment"># 添加l2正则化</span><br>           loss_regularization = []<br>           <span class="hljs-comment"># tf.nn.l2_loss(w)=sum(w ** 2) / 2</span><br>           loss_regularization.append(tf.nn.l2_loss(w1))<br>           loss_regularization.append(tf.nn.l2_loss(w2))<br>           <span class="hljs-comment"># 求和</span><br>           <span class="hljs-comment"># 例：x=tf.constant(([1,1,1],[1,1,1]))</span><br>           <span class="hljs-comment">#   tf.reduce_sum(x)</span><br>           <span class="hljs-comment"># &gt;&gt;&gt;6</span><br>           loss_regularization = tf.reduce_sum(loss_regularization)<br>           loss = loss_mse + <span class="hljs-number">0.03</span> * loss_regularization  <span class="hljs-comment"># REGULARIZER = 0.03</span><br><br>       <span class="hljs-comment"># 计算loss对各个参数的梯度</span><br>       variables = [w1, b1, w2, b2]<br>       grads = tape.gradient(loss, variables)<br></code></pre></td></tr></table></figure><p>下表可以看出，L2正则化函数可有效的缓解过饱和现象</p><table><thead><tr><th><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913170454005.png" alt="未填加L2正则化"></th><th><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230913170523568.png" alt="加入了L2正则化"></th></tr></thead></table><h2 id="2-6-优化器"><a href="#2-6-优化器" class="headerlink" title="2.6 优化器"></a>2.6 优化器</h2><p>是引导神经网络更新参数的工具。</p><p>神经网络参数优化器：<br>待优化参数𝒘，损失函数loss，学习率lr，每次迭代一个batch，t表示当前batch迭代的总次数：</p><ol><li>计算t时刻损失函数关于当前参数的梯度 $g_t&#x3D;\triangledown loss &#x3D; \frac{\partial loss}{\partial (w_t)} $</li><li>计算t时刻一阶动量 $m_t$ 和二阶动量$V_t$</li><li>计算t时刻下降梯度：$\eta_t &#x3D;\frac{lr·m_t}{\sqrt{V_t}}$</li><li>计算t+1时刻参数：$w_{t+1} &#x3D; w_t - \eta_t &#x3D; w_t - \frac{lr·m_t}{\sqrt{V_t}}$</li></ol><p>一阶动量：与梯度相关的函数<br>二阶动量：与梯度平方相关的函数</p><p>SGD(无momentum)，常用的梯度下降算法：</p><p>$m_t &#x3D; g_t $ $V_t &#x3D; 1$</p><p>$\eta_t &#x3D; \frac{lr·m_t}{\sqrt{V_t}} $</p><p>$w_{t+1} &#x3D; w_t -\eta_t &#x3D; w_t - \frac{lr·m_t}{\sqrt{V_t}} \ &#x3D;w_t - lr·g_t $</p><p>$w_{t+1} &#x3D; w_t -lr \ast \frac{\partial loss}{\partial w_t}  \ 参数更新公式$</p><p>SGDM(含momentum的SGD)，在SGD的基础上增加了一阶动量:</p><p>$m_{t-1}$表示上一时刻的一阶动量。</p><p>$m_t &#x3D; \beta · m_{t-1} + (1-\beta )·g_t $      $V_t&#x3D;1$</p><p>$\eta_t&#x3D;  \frac{lr·m_t}{\sqrt{V_t}} &#x3D; lr· m_t &#x3D;lr·(\beta · m_{t-1}+(1-\beta)·g_t)$</p><p>$w_{t+1}&#x3D;w_t -\eta_t &#x3D; w_t - lr · (\beta · m_{t-1}+(1-\beta)·g_t)$</p><p>Adagrad，在SGD基础上增加二阶动量:</p><p>$m_t&#x3D;g_t$     $V_t&#x3D;\sum_{\tau&#x3D;1}^t g_\tau^2$</p><p>$\eta_t&#x3D;\frac{lr·m_t}{\sqrt{V_t}} &#x3D;\frac{lr·g_t}{\sqrt{\sum_{\tau&#x3D;1}^t g_\tau^2}} $</p><p>$w_{t+1}&#x3D;w_t-\eta_t&#x3D;w_t-\frac{lr·g_t}{\sqrt{\sum_{\tau&#x3D;1}^t g_\tau^2}}$</p><p>RMSProp，SGD基础上增加二阶动量:</p><p>$m_t&#x3D;g_t$      $V_t &#x3D; \beta · V_{t-1} + (1-\beta)·g_t^2 $</p><p>$\eta_t&#x3D;\frac{lr·m_t}{\sqrt{V_t}} &#x3D;\frac{lr·g_t}{\sqrt{ \beta · V_{t-1} + (1-\beta)·g_t^2}} $</p><p>$w_{t+1}&#x3D;w_t-\eta_t&#x3D;w_t-\frac{lr·g_t}{\sqrt{ \beta · V_{t-1} + (1-\beta)·g_t^2}}$</p><p>Adam, 同时结合SGDM一阶动量和RMSProp二阶动量:</p><p>$m_t&#x3D;\beta_1 ·m_{t-1}+(1-\beta_1)·g_t$</p><p>修正一阶动量的偏差：$\widehat{m_t}&#x3D;\frac{m_t}{1-\beta_1^t}$</p><p>$V_t&#x3D;\beta_2 · V_{step-1}+(1-\beta_2)·g_t^2$</p><p>修正二阶动量的偏差：$ \widehat{V_t}&#x3D; \frac{V_t} {1-\beta_2^t} $</p><p>$\eta_t&#x3D;\frac{lr·\widehat{m_t} }{\sqrt{\widehat{V_t} } } &#x3D; lr \cdot \frac{lr{\frac{m_t}{1-\beta_1^t} } }{\sqrt{ {\frac{V_t} {1-\beta_2^t} } } } $</p><p>$w_{t+1}&#x3D;w_t-\eta_t&#x3D;w_t-\frac{lr\cdot{\frac{m_t}{1-\beta_1^t} } }{\sqrt{ {\frac{V_t}{1-\beta_2^t} } } } $</p><h2 id="3-1-搭建网络八股Sequential"><a href="#3-1-搭建网络八股Sequential" class="headerlink" title="3.1 搭建网络八股Sequential"></a>3.1 搭建网络八股Sequential</h2><p>用Tensorflow API：<code>tf.keras</code>搭建网络八股<br>六步法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span>    <span class="hljs-comment">#引入相关模块</span><br>train, test  <span class="hljs-comment">#告知喂入网络的训练集和测试集    特征x_train和标签y_train </span><br>model = tf.keras.models.Sequential <span class="hljs-comment">#搭建网络解构</span><br>model.<span class="hljs-built_in">compile</span> <span class="hljs-comment"># 配置训练方法（选择优化器、损失函数、评测指标）</span><br>model.fit <span class="hljs-comment"># 训练过程，告知train、test，告知batch、迭代次数</span><br>model.summary <span class="hljs-comment"># 打印网络解构、参数统计</span><br></code></pre></td></tr></table></figure><p><code>model = tf.keras.models.Sequential ([ 网络结构 ]) #描述各层网络</code><br>Sequential是容器，给出从输入层到输出层的各层网络解构</p><p>拉直层： tf.keras.layers.Flatten( )</p><p>全连接层： <code>tf.keras.layers.Dense(神经元个数, activation= &quot;激活函数“ ,kernel_regularizer=哪种正则化)</code><br>activation（字符串给出）可选: relu、 softmax、 sigmoid 、 tanh<br>kernel_regularizer可选:tf.keras.regularizers.l1()tf.keras.regularizers.l2()</p><p>卷积层： tf.keras.layers.Conv2D(filters &#x3D; 卷积核个数, kernel_size &#x3D; 卷积核尺寸,<br>strides &#x3D; 卷积步长， padding &#x3D; “ valid” or “same”)</p><p>LSTM层： tf.keras.layers.LSTM()</p><p><code>model.compile(optimizer = 优化器,loss = 损失函数 metrics = [“准确率”] )</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Optimizer可选:</span><br>‘sgd’ <span class="hljs-keyword">or</span> tf.keras.optimizers.SGD (lr=学习率,momentum=动量参数)<br>‘adagrad’ <span class="hljs-keyword">or</span> tf.keras.optimizers.Adagrad (lr=学习率)<br>‘adadelta’ <span class="hljs-keyword">or</span> tf.keras.optimizers.Adadelta (lr=学习率)<br>‘adam’ <span class="hljs-keyword">or</span> tf.keras.optimizers.Adam (lr=学习率, beta_1=<span class="hljs-number">0.9</span>, beta_2=<span class="hljs-number">0.999</span>)<br><span class="hljs-comment">#　loss可选:</span><br>‘mse’ <span class="hljs-keyword">or</span> tf.keras.losses.MeanSquaredError()<br>‘sparse_categorical_crossentropy’ <span class="hljs-keyword">or</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># Metrics可选:</span><br>‘accuracy’ ：y_和y都是数值，如y_=[<span class="hljs-number">1</span>] y=[<span class="hljs-number">1</span>]<br>‘categorical_accuracy’ ：y_和y都是独热码(概率分布)，如y_=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>] y=[<span class="hljs-number">0.256</span>,<span class="hljs-number">0.695</span>,<span class="hljs-number">0.048</span>]<br>‘sparse_categorical_accuracy’ ：y_是数值，y是独热码(概率分布),如y_=[<span class="hljs-number">1</span>] y=[<span class="hljs-number">0.256</span>,<span class="hljs-number">0.695</span>,<span class="hljs-number">0.048</span>]<br></code></pre></td></tr></table></figure><p><code>model.fit (训练集的输入特征, 训练集的标签, batch_size= , epochs= , validation_data=(测试集的输入特征，测试集的标签), validation_split=从训练集划分多少比例给测试集， validation_freq = 多少次epoch测试一次)</code></p><p>使用sequential可以搭建出上层输出就是下层输入的下层网络机构，但无法写出一些带有跳连的非顺序网络结构，这时候可以选择用类Class搭建神经网络解构。</p><h2 id="3-2-搭建网络八股Class"><a href="#3-2-搭建网络八股Class" class="headerlink" title="3.2 搭建网络八股Class"></a>3.2 搭建网络八股Class</h2><p>在六步法中，将第三部的Model改为<code>class MyModel(Model) model=MyModel</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(<span class="hljs-title class_ inherited__">Model</span>): <span class="hljs-comment"># 继承了Tensorflow的model类</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br><span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>定义网络结构块<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">call</span>(<span class="hljs-params">self, x</span>):<br>调用网络结构块，实现前向传播<br><span class="hljs-keyword">return</span> y<br>model = MyModel()<br><br><br><span class="hljs-comment">#__init__( )  定义所需网络结构块</span><br><span class="hljs-comment">#call( )  写出前向传播 实现钱前向传播</span><br><br></code></pre></td></tr></table></figure><h2 id="3-3-MNIST数据集"><a href="#3-3-MNIST数据集" class="headerlink" title="3.3 MNIST数据集"></a>3.3 MNIST数据集</h2><p>手写数字的数据集-上万张</p><p>导入MNIST数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"> mnist = tf.keras.datasets.mnist<br>(x_train, y_train) , (x_test, y_test) = mnist.load_data()<br></code></pre></td></tr></table></figure><p>为输入特征，输入神经网络时，将数据拉伸为一维数组：<br><code>tf.keras.layers.Flatten( )</code></p><h2 id="3-4-FASHION数据集"><a href="#3-4-FASHION数据集" class="headerlink" title="3.4 FASHION数据集"></a>3.4 FASHION数据集</h2><p>提供 6万张 28X28 像素点的衣裤等图片和标签，用于训练。<br>提供 1万张 28X28 像素点的衣裤等图片和标签，用于测试。</p><p>导入FASHION数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">fashion = tf.keras.datasets.fashion_mnist<br>(x_train, y_train),(x_test, y_test) = fashion.load_data()<br></code></pre></td></tr></table></figure><h2 id="4-1-搭建网络八股总览"><a href="#4-1-搭建网络八股总览" class="headerlink" title="4.1 搭建网络八股总览"></a>4.1 搭建网络八股总览</h2><p>① 自制数据集，解决本领域应用<br>② 数据增强，扩充数据集<br>③ 断点续训，存取模型<br>④ 参数提取，把参数存入文本<br>⑤ acc&#x2F;loss可视化，查看训练效果<br>⑥ 应用程序，给图识物</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230916150852673.png" alt="六步法八股总览"></p><h2 id="4-2-自制数据集"><a href="#4-2-自制数据集" class="headerlink" title="4.2 自制数据集"></a>4.2 自制数据集</h2><p>使用Py，目的是将文件夹内的图片读入，返回输入特征、标签。</p><p>标签文件txt</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> os<br><span class="hljs-comment">### import</span><br><br><br>train_path = <span class="hljs-string">&#x27;./mnist_image_label/mnist_train_jpg_60000/&#x27;</span><br>train_txt = <span class="hljs-string">&#x27;./mnist_image_label/mnist_train_jpg_60000.txt&#x27;</span><br>x_train_savepath = <span class="hljs-string">&#x27;./mnist_image_label/mnist_x_train.npy&#x27;</span><br>y_train_savepath = <span class="hljs-string">&#x27;./mnist_image_label/mnist_y_train.npy&#x27;</span><br><span class="hljs-comment">### 训练集</span><br><br><br>test_path = <span class="hljs-string">&#x27;./mnist_image_label/mnist_test_jpg_10000/&#x27;</span><br>test_txt = <span class="hljs-string">&#x27;./mnist_image_label/mnist_test_jpg_10000.txt&#x27;</span><br>x_test_savepath = <span class="hljs-string">&#x27;./mnist_image_label/mnist_x_test.npy&#x27;</span><br>y_test_savepath = <span class="hljs-string">&#x27;./mnist_image_label/mnist_y_test.npy&#x27;</span><br><br><span class="hljs-comment">### 测试集</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generateds</span>(<span class="hljs-params">path, txt</span>):<br>    f = <span class="hljs-built_in">open</span>(txt, <span class="hljs-string">&#x27;r&#x27;</span>)  <span class="hljs-comment"># 以只读形式打开txt文件</span><br>    contents = f.readlines()  <span class="hljs-comment"># 读取文件中所有行</span><br>    f.close()  <span class="hljs-comment"># 关闭txt文件</span><br>    x, y_ = [], []  <span class="hljs-comment"># 建立空列表</span><br>    <span class="hljs-keyword">for</span> content <span class="hljs-keyword">in</span> contents:  <span class="hljs-comment"># 逐行取出</span><br>        value = content.split()  <span class="hljs-comment"># 以空格分开，图片路径为value[0] , 标签为value[1] , 存入列表</span><br>        img_path = path + value[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 拼出图片路径和文件名</span><br>        img = Image.<span class="hljs-built_in">open</span>(img_path)  <span class="hljs-comment"># 读入图片</span><br>        img = np.array(img.convert(<span class="hljs-string">&#x27;L&#x27;</span>))  <span class="hljs-comment"># 图片变为8位宽灰度值的np.array格式</span><br>        img = img / <span class="hljs-number">255.</span>  <span class="hljs-comment"># 数据归一化 （实现预处理）</span><br>        x.append(img)  <span class="hljs-comment"># 归一化后的数据，贴到列表x</span><br>        y_.append(value[<span class="hljs-number">1</span>])  <span class="hljs-comment"># 标签贴到列表y_</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;loading : &#x27;</span> + content)  <span class="hljs-comment"># 打印状态提示</span><br><br>    x = np.array(x)  <span class="hljs-comment"># 变为np.array格式</span><br>    y_ = np.array(y_)  <span class="hljs-comment"># 变为np.array格式</span><br>    y_ = y_.astype(np.int64)  <span class="hljs-comment"># 变为64位整型</span><br>    <span class="hljs-keyword">return</span> x, y_  <span class="hljs-comment"># 返回输入特征x，返回标签y_</span><br><br><span class="hljs-comment">### generateds函数</span><br><br><br><span class="hljs-keyword">if</span> os.path.exists(x_train_savepath) <span class="hljs-keyword">and</span> os.path.exists(y_train_savepath) <span class="hljs-keyword">and</span> os.path.exists(<br>        x_test_savepath) <span class="hljs-keyword">and</span> os.path.exists(y_test_savepath):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-------------Load Datasets-----------------&#x27;</span>)<br>    x_train_save = np.load(x_train_savepath)<br>    y_train = np.load(y_train_savepath)<br>    x_test_save = np.load(x_test_savepath)<br>    y_test = np.load(y_test_savepath)<br>    x_train = np.reshape(x_train_save, (<span class="hljs-built_in">len</span>(x_train_save), <span class="hljs-number">28</span>, <span class="hljs-number">28</span>))<br>    x_test = np.reshape(x_test_save, (<span class="hljs-built_in">len</span>(x_test_save), <span class="hljs-number">28</span>, <span class="hljs-number">28</span>))<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-------------Generate Datasets-----------------&#x27;</span>)<br>    x_train, y_train = generateds(train_path, train_txt)<br>    x_test, y_test = generateds(test_path, test_txt)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-------------Save Datasets-----------------&#x27;</span>)<br>    x_train_save = np.reshape(x_train, (<span class="hljs-built_in">len</span>(x_train), -<span class="hljs-number">1</span>))<br>    x_test_save = np.reshape(x_test, (<span class="hljs-built_in">len</span>(x_test), -<span class="hljs-number">1</span>))<br>    np.save(x_train_savepath, x_train_save)<br>    np.save(y_train_savepath, y_train)<br>    np.save(x_test_savepath, x_test_save)<br>    np.save(y_test_savepath, y_test)<br><br><span class="hljs-comment">### train test</span><br>    <br>    <br>    <br>model = tf.keras.models.Sequential([<br>    tf.keras.layers.Flatten(),<br>    tf.keras.layers.Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br>    tf.keras.layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>)<br>])<br><br><span class="hljs-comment">### models.sequential</span><br><br>model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>,<br>              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">False</span>),<br>              metrics=[<span class="hljs-string">&#x27;sparse_categorical_accuracy&#x27;</span>])<br><br><span class="hljs-comment">### model.compile</span><br><br>model.fit(x_train, y_train, batch_size=<span class="hljs-number">32</span>, epochs=<span class="hljs-number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment">### model.fit</span><br><br>model.summary()<br><br><span class="hljs-comment">### model.summary</span><br></code></pre></td></tr></table></figure><p>第一次运行生成了npy格式的数据集。</p><p>第二次会加载数据集，执行训练过程。</p><h2 id="4-3-数据增强"><a href="#4-3-数据增强" class="headerlink" title="4.3 数据增强"></a>4.3 数据增强</h2><p>增大数据量,扩充数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">image_gen_train =tf.keras.preprocessing.image.ImageDataGenerator(<br>rescale = 所有数据将乘以该数值<br>rotation_range = 随机旋转角度数范围<br>width_shift_range = 随机宽度偏移量<br>height_shift_range = 随机高度偏移量<br>水平翻转：horizontal_flip = 是否随机水平翻转<br>随机缩放：zoom_range = 随机缩放的范围 [<span class="hljs-number">1</span>-n，<span class="hljs-number">1</span>+n] )<br>image_gen_train.fit(x_train)<br></code></pre></td></tr></table></figure><h2 id="4-4-断点续训"><a href="#4-4-断点续训" class="headerlink" title="4.4 断点续训"></a>4.4 断点续训</h2><p>可以存取模型</p><p>读取模型：<br><code>load_weights(路径文件名）</code></p><p>可以先检查是否存在断点，如有则加载模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">cheakpoint_save_path= <span class="hljs-string">&quot;./cheakpoint/mnist.ckpt&quot;</span><br><span class="hljs-keyword">if</span> os.path.exists(checkpoint_save_path + <span class="hljs-string">&#x27;.index&#x27;</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;--------load the model-------&#x27;</span>)<br>    model.load_weights(checkpoint_save_path)<br></code></pre></td></tr></table></figure><p><code>保存模型： tf.keras.callbacks.ModelCheckpoint(filepath=路径文件名,save_weights_only=True/False,save_best_only=True/False) history = model.fit（ callbacks=[cp_callback] ）</code></p><h2 id="4-5-参数提取"><a href="#4-5-参数提取" class="headerlink" title="4.5 参数提取"></a>4.5 参数提取</h2><p>把参数存入文本</p><p>提取可训练参数<br>model.trainable_variables 返回模型中可训练的参数<br>设置print输出格式<br>np.set_printoptions(threshold&#x3D;超过多少省略显示)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">np.set_printoptions(threshold=np.inf)<br><span class="hljs-comment"># np.inf表示无限大</span><br><br><br><span class="hljs-built_in">print</span>(model.trainable_variables)<br>file = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./weights.txt&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>)<br><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> model.trainable_variables:<br>file.write(<span class="hljs-built_in">str</span>(v.name) + <span class="hljs-string">&#x27;\n&#x27;</span>)<br>file.write(<span class="hljs-built_in">str</span>(v.shape) + <span class="hljs-string">&#x27;\n&#x27;</span>)<br>file.write(<span class="hljs-built_in">str</span>(v.numpy()) + <span class="hljs-string">&#x27;\n&#x27;</span>)<br>file.close()<br></code></pre></td></tr></table></figure><h2 id="4-6-acc-loss可视化"><a href="#4-6-acc-loss可视化" class="headerlink" title="4.6 acc&#x2F;loss可视化"></a>4.6 acc&#x2F;loss可视化</h2><p>acc曲线与loss曲线</p><p><code>history=model.fit(训练集数据, 训练集标签, batch_size=, epochs=,validation_split=用作测试数据的比例,validation_data=测试集,validation_freq=测试频率)</code></p><p>只是一段画图程序代码。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230916164058968.png" alt="添加的画图代码"></p><h2 id="4-7-图片识别"><a href="#4-7-图片识别" class="headerlink" title="4.7 图片识别"></a>4.7 图片识别</h2><p>给图识物</p><p><code>predict（输入特征，batch_size=整数）</code>返回向前传播的计算结果</p><p>复现模型（前向传播）:</p><p><code>model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation=&#39;relu&#39;), tf.keras.layers.Dense(10, activation=&#39;softmax’)])</code></p><p>加载参数:</p><p><code>model.load_weights(model_save_path</code></p><p>预测结果:</p><p><code>result = model.predict(x_predict)</code></p><h2 id="5-1-卷积的计算过程-Convolutional"><a href="#5-1-卷积的计算过程-Convolutional" class="headerlink" title="5.1 卷积的计算过程 Convolutional"></a>5.1 卷积的计算过程 Convolutional</h2><p>全连接 NN 特点：每个神经元与前后相邻层的每一个神经元都有连接关系。（可以实<br>现分类和预测）</p><p>全连接网络参数的个数为：$\sum(前层\times 后层 + 后层)$</p><p>卷积的概念：卷积可以认为是一种有效提取图像特征的方法。一般会用一个正方形的<br>卷积核，按指定步长，在输入特征图上滑动，遍历输入特征图中的每个像素点。每一个步长，<br>卷积核会与输入特征图出现重合区域，重合区域对应元素相乘、求和再加上偏置项得到输出<br>特征的一个像素点。</p><p>对于彩色图像（多通道）来说，卷积核通道数与输入特征一致，套接后在对应位置上进行乘加和操作，如果是彩色图片（RGB）利用三通道卷积核对三通道的彩色特征图做卷积计算。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230916171743300.png" alt="输出特征尺寸计算"></p><h2 id="5-2-感受野"><a href="#5-2-感受野" class="headerlink" title="5.2 感受野"></a>5.2 感受野</h2><p>感受野（Receptive Field）：卷积神经网络各输出特征图中的每个像素点，在原始输入图片上映射区域的大小。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230916173848124.png" alt="黄-绿为两次3*3 蓝色为一次5*5"></p><p>通常用两层3*3卷积核替换一层5*5卷积核</p><h2 id="5-3-全零填充-Padding"><a href="#5-3-全零填充-Padding" class="headerlink" title="5.3 全零填充 Padding"></a>5.3 全零填充 Padding</h2><p>将图的四周加上一圈零填充。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20230916174816575.png" alt="padding"></p><p>TF描述全零填充<br>用参数padding &#x3D; ‘SAME’ 或 padding &#x3D; ‘VALID’表示</p><p>SAME：5X5X1  –&gt;  5X5X1      VALID：5X5X1–&gt;3X3X1</p><p>可以让输出特征图和输出特征图的尺寸不变。</p><h2 id="5-4-TF描述卷积计算层"><a href="#5-4-TF描述卷积计算层" class="headerlink" title="5.4 TF描述卷积计算层"></a>5.4 TF描述卷积计算层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.keras.layers.Conv2D (<br>filters = 卷积核个数,<br>kernel_size = 卷积核尺寸, <span class="hljs-comment">#正方形写核长整数，或（核高h，核宽w）</span><br>strides = 滑动步长, <span class="hljs-comment">#横纵向相同写步长整数，或(纵向步长h，横向步长w)，默认1</span><br>padding = “same” <span class="hljs-keyword">or</span> “valid”, <span class="hljs-comment">#使用全零填充是“same”，不使用是“valid”（默认）</span><br>activation = “ relu ” <span class="hljs-keyword">or</span> “ sigmoid ” <span class="hljs-keyword">or</span> “ tanh ” <span class="hljs-keyword">or</span> “ softmax”等 , <span class="hljs-comment">#如有BN此处不写</span><br>input_shape = (高, 宽 , 通道数) <span class="hljs-comment">#输入特征图维度，可省略</span><br>)<br></code></pre></td></tr></table></figure><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228211041340.png" alt="TF描述卷积层"></p><p>例如可以使用关键字传递参数的方法。</p><h2 id="5-5-批标准化-BN"><a href="#5-5-批标准化-BN" class="headerlink" title="5.5 批标准化 BN"></a>5.5 批标准化 BN</h2><p>标准化：使数据符合0均值，1为标准差的分布。</p><p>批标准化：对一小批数据（batch），做标准化处理 。</p><p>批标准化后，第 k个卷积核的输出特征图（feature map）中第 i 个像素点</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228211544435.png" alt="BN层位于卷积层之后，激活层之前。"></p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228211600833.png" alt="批标准化"></p><h2 id="5-6-池化-Pooling"><a href="#5-6-池化-Pooling" class="headerlink" title="5.6 池化 Pooling"></a>5.6 池化 Pooling</h2><p>池化用于减少特征数据量。平均池化和最大池化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.keras.layers.MaxPool2D(<br>pool_size=池化核尺寸，<span class="hljs-comment">#正方形写核长整数，或（核高h，核宽w）</span><br>strides=池化步长，<span class="hljs-comment">#步长整数， 或(纵向步长h，横向步长w)，默认为pool_size</span><br>padding=‘valid’<span class="hljs-keyword">or</span>‘same’ <span class="hljs-comment">#使用全零填充是“same”，不使用是“valid”（默认）</span><br>)<br>tf.keras.layers.AveragePooling2D(<br>pool_size=池化核尺寸，<span class="hljs-comment">#正方形写核长整数，或（核高h，核宽w）</span><br>strides=池化步长，<span class="hljs-comment">#步长整数， 或(纵向步长h，横向步长w)，默认为pool_size</span><br>padding=‘valid’<span class="hljs-keyword">or</span>‘same’ <span class="hljs-comment">#使用全零填充是“same”，不使用是“valid”（默认）</span><br>)<br></code></pre></td></tr></table></figure><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228211847780.png" alt="池化"></p><h2 id="5-7-舍弃-Dropout"><a href="#5-7-舍弃-Dropout" class="headerlink" title="5.7 舍弃 Dropout"></a>5.7 舍弃 Dropout</h2><p>在神经网络训练时，将一部分神经元按照一定概率从神经网络中暂时舍弃。神经网络使用时，被舍弃的神经元恢复链接。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228212108454.png" alt="舍弃"></p><h2 id="5-8-卷积神经网络"><a href="#5-8-卷积神经网络" class="headerlink" title="5.8 卷积神经网络"></a>5.8 卷积神经网络</h2><p>卷积是什么？ 卷积就是特征提取器，就是CBAPD</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228214733104.png" alt="CBAPD"></p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240228214753084.png" alt="CNN"></p><h2 id="5-9-Cifar10数据集-卷积神经网络搭建示例"><a href="#5-9-Cifar10数据集-卷积神经网络搭建示例" class="headerlink" title="5.9 Cifar10数据集 卷积神经网络搭建示例"></a>5.9 Cifar10数据集 卷积神经网络搭建示例</h2><p>提供 5万张 32*32 像素点的十分类彩色图片和标签，用于训练。<br>提供 1万张 32*32 像素点的十分类彩色图片和标签，用于测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#导入cifar10数据集：</span><br>cifar10 = tf.keras.datasets.cifar10<br>(x_train, y_train),(x_test, y_test) = cifar10.load_data()<br><br>plt.imshow(x_train[<span class="hljs-number">0</span>])<br><span class="hljs-comment">#绘制图片</span><br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_train[0]:\n&quot;</span> , x_train[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y_train[0]:&quot;</span>, y_train[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x_test.shape:&quot;</span>, x_test.shape)<br></code></pre></td></tr></table></figure><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240302132316265.png" alt="卷积神经网络搭建示例"></p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240302132135165.png" alt="搭建示例"></p><h2 id="5-10-LeNet-AlexNet-VGGNet-InceptionNet-ResNet"><a href="#5-10-LeNet-AlexNet-VGGNet-InceptionNet-ResNet" class="headerlink" title="5.10 LeNet AlexNet VGGNet InceptionNet ResNet"></a>5.10 LeNet AlexNet VGGNet InceptionNet ResNet</h2><p>LeNet由Yann LeCun于1998年提出，卷积网络开篇之作。</p><p>AlexNet网络诞生于2012年，当年ImageNet竞赛的冠军，Top5错误率为16.4%。</p><p>VGGNet诞生于2014年，当年ImageNet竞赛的亚军，Top5错误率减小到7.3%。</p><p>InceptionNet诞生于2014年，当年ImageNet竞赛冠军，Top5错误率为6.67%</p><p>ResNet诞生于2015年，当年ImageNet竞赛冠军，Top5错误率为3.57%</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240302153943645.png" alt="经典卷积网络"></p><h2 id="6-1-循环核"><a href="#6-1-循环核" class="headerlink" title="6.1 循环核"></a>6.1 循环核</h2><p>循环核：参数时间共享，循环层提取时间信息。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240302180849506.png" alt="循环核"></p><h2 id="6-2-循环核按时间步展开"><a href="#6-2-循环核按时间步展开" class="headerlink" title="6.2 循环核按时间步展开"></a>6.2 循环核按时间步展开</h2><p>循环神经网络：借助循环核提取时间特征后，送入全连接网络。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240302181058519.png" alt="循环神经网络"></p><p>循环计算层：向输出方向生长。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/image-20240302181218194.png" alt="循环计算层"></p><h2 id="6-3-TF描述循环计算层"><a href="#6-3-TF描述循环计算层" class="headerlink" title="6.3 TF描述循环计算层"></a>6.3 TF描述循环计算层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.keras.layers.SimpleRNN(记忆体个数，activation=‘激活函数’ ，<br>return_sequences=是否每个时刻输出ht到下一层)<br>activation=‘激活函数’ （不写，默认使用tanh）<br>return_sequences=<span class="hljs-literal">True</span> 各时间步输出ht<br>return_sequences=<span class="hljs-literal">False</span> 仅最后时间步输出ht（默认）<br>例：SimpleRNN(<span class="hljs-number">3</span>, return_sequences=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>入RNN时， x_train维度：<br>[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]</p><h2 id="6-4-循环计算过程-字母输入预测"><a href="#6-4-循环计算过程-字母输入预测" class="headerlink" title="6.4 循环计算过程-字母输入预测"></a>6.4 循环计算过程-字母输入预测</h2><p>字母预测：输入a预测出b，输入b预测出c，<br>输入c预测出d，输入d预测出e，输入e预测出a</p><p>用RNN实现输入一个字母，预测下一个字母<br>（One hot 编码）独热码</p><p>用RNN实现输入连续四个字母，预测下一个字母<br>（One hot 编码）</p><p>用RNN实现输入一个字母，预测下一个字母<br>（Embedding 编码）</p><p>用RNN实现输入连续四个字母，预测下一个字母<br>（Embedding 编码）</p><h2 id="6-5-股票预测"><a href="#6-5-股票预测" class="headerlink" title="6.5 股票预测"></a>6.5 股票预测</h2><p>用RNN实现股票预测</p><p>用LSTM实现股票预测</p><p>LSTM 由Hochreiter &amp; Schmidhuber 于1997年提出，通过门控单元改善了RNN长期依赖问题。</p><p>用GRU实现股票预测</p><p>GRU由Cho等人于2014年提出，优化LSTM结构。</p><p>更新于：2024 </p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>工具与软件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TensorFlow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-4-PyTorch</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/</url>
    
    <content type="html"><![CDATA[<p>安装CUDA</p><p>UPDATEｔｉｍｅ；</p><p>９．２２　１８：００</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>工具与软件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-3-数据分析实战</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[<blockquote><p>使用Python进行数据分析，对其编程、库，以及⽤于数据分析的⼯具的相关学习与研究。</p></blockquote><h2 id="一-准备工作"><a href="#一-准备工作" class="headerlink" title="一.准备工作"></a>一.准备工作</h2><h2 id="1-重要的Python库"><a href="#1-重要的Python库" class="headerlink" title="1 重要的Python库"></a>1 重要的Python库</h2><h3 id="NumPy"><a href="#NumPy" class="headerlink" title="NumPy"></a>NumPy</h3><p>NumPy（Numerical Python的简称）是Python科学计算的基础包。<a href="https://cnwuyueyu.github.io/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/">详见</a>它提供了以下功能（不限于此）：</p><ul><li>快速⾼效的多维数组对象ndarray。</li><li>⽤于对数组执⾏元素级计算以及直接对数组执⾏数学运算的函数。</li><li>⽤于读写硬盘上基于数组的数据集的⼯具。</li><li>线性代数运算、傅⾥叶变换，以及随机数⽣成。-成熟的C API， ⽤于Python插件和原⽣CC++、Fortran代码访问NumPy的数据结构和计算⼯具。</li></ul><p>除了为Python提供快速的数组处理能⼒，NumPy在数据分析⽅⾯还有另外⼀个主要作⽤，即作为在算法和库之间传递数据的容器。对于数值型数据，NumPy数组在存储和处理数据时要⽐内<br>置的Python数据结构⾼效得多。此外，由低级语⾔（⽐如C和Fortran）编写的库可以直接操作NumPy数组中的数据，⽆需进⾏任何数据复制⼯作。因此，许多Python的数值计算⼯具要么使<br>⽤NumPy数组作为主要的数据结构，要么可以与NumPy进⾏⽆缝交互操作。</p><h3 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h3><p>pandas提供了快速便捷处理结构化数据的⼤量数据结构和函数。⾃从2010年出现以来，它助使Python成为强⼤⽽⾼效的数据分析环境。⽤得最多的pandas对象是DataFrame，它是⼀个⾯向列（column-oriented）的⼆维表结构，另⼀个是Series，⼀个⼀维的标签化数组对象。<a href="https://cnwuyueyu.github.io/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/">详见</a></p><p>pandas兼具NumPy⾼性能的数组计算功能以及电⼦表格和关系型数据库（如SQL）灵活的数据处理功能。它提供了复杂精细的索引功能，以便更为便捷地完成重塑、切⽚和切块、聚合以及选取数据⼦集等操作。因为数据操作、准备、清洗是数据分析最重要的技能。</p><p>pandas这个名字源于panel data（⾯板数据，这是多维结构化数据集在计量经济学中的术语）以及Python dataanalysis（Python数据分析）。</p><h3 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h3><p>matplotlib是最流⾏的⽤于绘制图表和其它⼆维数据可视化的Python库。它⾮常适合创建出版物上⽤的图表。虽然还有其它的Python可视化库，matplotlib却是使⽤最⼴泛的，并且它和其它⽣态⼯具配合也⾮常完美。</p><h3 id="IPython和Jupyter"><a href="#IPython和Jupyter" class="headerlink" title="IPython和Jupyter"></a>IPython和Jupyter</h3><p>IPython项⽬起初是Fernando Pérez在2001年的⼀个⽤以加强和Python交互的⼦项⽬。在随后的16年中，它成为了Python数据栈最重要的⼯具之⼀。虽然IPython本身没有提供计算和数据分析的⼯具，它却可以⼤⼤提⾼交互式计算和软件开发的⽣产率。IPython⿎励“执⾏-探索”的⼯作流，区别于其它编程软件的“编辑-编译-运⾏”的⼯作流。它还可以⽅便地访问系统的shell和⽂件系统。因为⼤部分的数据分析代码包括探索、试错和重复，IPython可以使⼯作更快。IPython shell 和Jupyter notebooks特别适合进⾏数据探索和可视化。</p><p>⼤部分Python都要⽤到IPython，包括运⾏、调试和测试代码。</p><h3 id="SciPy"><a href="#SciPy" class="headerlink" title="SciPy"></a>SciPy</h3><p>SciPy是⼀组专⻔解决科学计算中各种标准问题域的包的集合，主要包括下⾯这些包：</p><ul><li>scipy.integrate：数值积分例程和微分⽅程求解器。</li><li>scipy.linalg：扩展了由numpy.linalg提供的线性代数例程和矩阵分解功能。</li><li>scipy.optimize：函数优化器（最⼩化器）以及根查找算法。</li><li>scipy.signal：信号处理⼯具。</li><li>scipy.sparse：稀疏矩阵和稀疏线性系统求解器。</li><li>scipy.special：SPECFUN（这是⼀个实现了许多常⽤数学函数（如伽玛函数）的Fortran库）的包装器。</li><li>scipy.stats：标准连续和离散概率分布（如密度函数、采样器、连续分布函数等）、各种统计检验⽅法，以及更好的描述统计法。</li></ul><p>NumPy和SciPy结合使⽤，便形成了⼀个相当完备和成熟的计算平台，可以处理多种传统的科学计算问题。</p><h3 id="scikit-learn"><a href="#scikit-learn" class="headerlink" title="scikit-learn"></a>scikit-learn</h3><p>2010年诞⽣以来，scikit-learn成为了Python的通⽤机器学习⼯具包。它的⼦模块包括：</p><ul><li>分类：SVM、近邻、随机森林、逻辑回归等等。</li><li>回归：Lasso、岭回归等等。</li><li>聚类：k-均值、谱聚类等等。</li><li>降维：PCA、特征选择、矩阵分解等等。</li><li>选型：⽹格搜索、交叉验证、度量。</li><li>预处理：特征提取、标准化。</li></ul><p>与pandas、statsmodels和IPython⼀起，scikit-learn对于Python成为⾼效数据科学编程语⾔起到了关键作⽤。</p><h3 id="statsmodels"><a href="#statsmodels" class="headerlink" title="statsmodels"></a>statsmodels</h3><p>statsmodels是⼀个统计分析包，与scikit-learn⽐较，statsmodels包含经典统计学和经济计量学的算法。包括如下⼦模块：</p><ul><li>回归模型：线性回归，⼴义线性模型，健壮线性模型，线性混合效应模型等等。</li><li>⽅差分析（ANOVA）。</li><li>时间序列分析：AR，ARMA，ARIMA，VAR和其它模型。</li><li>⾮参数⽅法： 核密度估计，核回归。</li><li>统计模型结果可视化。</li></ul><p>statsmodels更关注与统计推断，提供不确定估计和参数p-值。相反的，scikit-learn注重预测。</p><h1 id="二-Python语法基础"><a href="#二-Python语法基础" class="headerlink" title="二.Python语法基础"></a>二.Python语法基础</h1><h2 id="1-IPython"><a href="#1-IPython" class="headerlink" title="1.IPython"></a>1.IPython</h2><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><p>有许多键盘快捷键进⾏导航提示（类似Emacs⽂本编辑器或UNIX bash Shell）和交互shell的历史命令。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/image.ZUBJB2-16953667317141.png" alt="IPython sheel的快捷键"></p><p>魔术命令</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/image.LEO7A2.png" alt="IPython魔术命令"></p><p>IPython同时集成了Matplotlib</p><p>三.Python的数据结构、函数和⽂件</p><p>P85</p><p>update time:</p><p>2023-09-22 16:57:38.877910</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>工具与软件</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-2-Pandas</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/</url>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>在pycharm中对应的python解释器内安装pandas。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/image-20230919175623027.png" alt="pandas的安装"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas<br><br><span class="hljs-built_in">print</span>(pandas.__version__)<br></code></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">2.1</span><span class="hljs-number">.0</span><br><br>进程已结束,退出代码<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><h2 id="Pandas-数据结构-Series"><a href="#Pandas-数据结构-Series" class="headerlink" title="Pandas 数据结构 - Series"></a>Pandas 数据结构 - Series</h2><p>Series 相当于表格中的一个列，函数如下：</p><p><code>pandas.Series( data, index, dtype, name, copy)</code></p><ul><li><strong>data</strong>：一组数据(ndarray 类型)。</li><li><strong>index</strong>：数据索引标签，如果不指定，默认从 0 开始。</li><li><strong>dtype</strong>：数据类型，默认会自己判断。</li><li><strong>name</strong>：设置名称。</li><li><strong>copy</strong>：拷贝数据，默认为 False。</li></ul><p>也可以使用Map来创建Series：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>sites = &#123;<span class="hljs-number">1</span>: <span class="hljs-string">&quot;Google&quot;</span>, <span class="hljs-number">2</span>: <span class="hljs-string">&quot;Runoob&quot;</span>, <span class="hljs-number">3</span>: <span class="hljs-string">&quot;Wiki&quot;</span>&#125;<br><br>myvar = pd.Series(sites)<br><br><span class="hljs-built_in">print</span>(myvar)<br></code></pre></td></tr></table></figure><p>这样Key就变为了索引值。</p><h2 id="Pandas-数据结构-DataFrame"><a href="#Pandas-数据结构-DataFrame" class="headerlink" title="Pandas 数据结构 - DataFrame"></a>Pandas 数据结构 - DataFrame</h2><p>DataFrame 是一个表格型的数据结构，由一个index组成的第0列和DataFrame组成的n列构成，相当于Series组成的字典（共用一个index）。</p><p><img src="/../images/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/image-20230919182139779.png" alt="Series与DataFrame"></p><p>函数如下：</p><p><code>pandas.DataFrame( data, index, columns, dtype, copy)</code></p><ul><li><strong>data</strong>：一组数据(ndarray、series, map, lists, dict 等类型)。</li><li><strong>index</strong>：索引值，或者可以称为行标签。</li><li><strong>columns</strong>：列标签，默认为 RangeIndex (0, 1, 2, …, n) 。</li><li><strong>dtype</strong>：数据类型。</li><li><strong>copy</strong>：拷贝数据，默认为 False。</li></ul><p>使用ndarrays创建DataFrame对象:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>data = &#123;<span class="hljs-string">&#x27;Site&#x27;</span>:[<span class="hljs-string">&#x27;Google&#x27;</span>, <span class="hljs-string">&#x27;Runoob&#x27;</span>, <span class="hljs-string">&#x27;Wiki&#x27;</span>], <span class="hljs-string">&#x27;Age&#x27;</span>:[<span class="hljs-number">10</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>]&#125;<br><br>df = pd.DataFrame(data)<br><br><span class="hljs-built_in">print</span> (df)<br></code></pre></td></tr></table></figure><p>Site Age为列名，0、1、2为行标。</p><p>使用Map创建与Series同理。</p><h2 id="Pandas-CSV-文件"><a href="#Pandas-CSV-文件" class="headerlink" title="Pandas CSV 文件"></a>Pandas CSV 文件</h2><p>Pandas 可以很方便的处理 CSV 文件</p><p><code>df = pd.read_csv(&#39;nba.csv&#39;)</code>读取CSV文件。</p><p><code>df.to_csv(&#39;site.csv&#39;)</code>将DataFrame储存为csv文件。</p><p>数据处理</p><p><strong>head( n )</strong> 方法用于读取前面的 n 行，如果不填参数 n ，默认返回 5 行。</p><p><strong>tail( n )</strong> 方法用于读取尾部的 n 行，如果不填参数 n ，默认返回 5 行，空行各个字段的值返回 <strong>NaN</strong>。</p><p><strong>info()</strong> 方法返回表格的一些基本信息：</p><h2 id="Pandas-JSON-文件"><a href="#Pandas-JSON-文件" class="headerlink" title="Pandas JSON 文件"></a>Pandas JSON 文件</h2><p>Pandas 可以很方便的处理 JSON 数据</p><p><strong>to_string()</strong> 用于返回 <strong>DataFrame</strong>(表格) 类型的数据，我们也可以直接处理 JSON 字符串。</p><p>如果是字符串格式的 JSON 可以直接将Python字典转为DataFrame数据（json对象与Map有相同的格式）</p><p><strong>Json数据的解析</strong></p><p>直接加载一个print一个json文件打印出的并不直观。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">          school_name   <span class="hljs-keyword">class</span>                                           <span class="hljs-title class_">students</span><br><span class="hljs-number">0</span>  ABC primary school  Year <span class="hljs-number">1</span>  &#123;<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;A001&#x27;</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;Tom&#x27;</span>, <span class="hljs-string">&#x27;math&#x27;</span>: <span class="hljs-number">60</span>, <span class="hljs-string">&#x27;phy...</span><br><span class="hljs-string">1  ABC primary school  Year 1  &#123;&#x27;</span><span class="hljs-built_in">id</span><span class="hljs-string">&#x27;: &#x27;</span>A002<span class="hljs-string">&#x27;, &#x27;</span>name<span class="hljs-string">&#x27;: &#x27;</span>James<span class="hljs-string">&#x27;, &#x27;</span>math<span class="hljs-string">&#x27;: 89, &#x27;</span>p...<br><span class="hljs-number">2</span>  ABC primary school  Year <span class="hljs-number">1</span>  &#123;<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;A003&#x27;</span>, <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;Jenny&#x27;</span>, <span class="hljs-string">&#x27;math&#x27;</span>: <span class="hljs-number">79</span>, <span class="hljs-string">&#x27;p...</span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure><p>用到 <strong>json_normalize()</strong> 方法将内嵌的数据完整的解析出来</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-comment"># 使用 Python JSON 模块载入数据</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;nested_list.json&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data = json.loads(f.read()) <br>    <span class="hljs-comment">#data = json.loads(f.read()) 使用 Python JSON 模块载入数据。</span><br><br><span class="hljs-comment"># 展平数据</span><br>df_nested_list = pd.json_normalize(data, record_path =[<span class="hljs-string">&#x27;students&#x27;</span>])<br><span class="hljs-built_in">print</span>(df_nested_list)<br></code></pre></td></tr></table></figure><p>Output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">     <span class="hljs-built_in">id</span>   name  math  physics  chemistry<br><span class="hljs-number">0</span>  A001    Tom    <span class="hljs-number">60</span>       <span class="hljs-number">66</span>         <span class="hljs-number">61</span><br><span class="hljs-number">1</span>  A002  James    <span class="hljs-number">89</span>       <span class="hljs-number">76</span>         <span class="hljs-number">51</span><br><span class="hljs-number">2</span>  A003  Jenny    <span class="hljs-number">79</span>       <span class="hljs-number">90</span>         <span class="hljs-number">78</span><br></code></pre></td></tr></table></figure><p><strong>读取一组数据glom</strong></p><p><strong>import</strong> pandas <strong>as</strong> pd<br><strong>from</strong> glom <strong>import</strong> glom   glom模块准许使用“.”来获取内嵌对象的属性</p><p><code>data = df[&#39;students&#39;].apply(**lambda** row: glom(row, &#39;grade.math&#39;))</code></p><p>效果类似于查找。</p><h2 id="Pandas-数据清洗"><a href="#Pandas-数据清洗" class="headerlink" title="Pandas 数据清洗"></a>Pandas 数据清洗</h2><p>很多数据集存在数据缺失、数据格式错误、错误数据或重复数据的情况，如果要使数据分析更加准确，就需要对这些没有用的数据进行处理（清洗）。</p><p>例如数据中的“n&#x2F;a  NA  –  na”，或者空值等。</p><p>清洗空值：dropna（）方法</p><p><code>DataFrame.dropna(axis=0, how=&#39;any&#39;, thresh=None, subset=None, inplace=False)</code></p><ul><li>axis：默认为 <strong>0</strong>，表示逢空值剔除整行，如果设置参数 <strong>axis＝1</strong> 表示逢空值去掉整列。</li><li>how：默认为 <strong>‘any’</strong> 如果一行（或一列）里任何一个数据有出现 NA 就去掉整行，如果设置 <strong>how&#x3D;’all’</strong> 一行（或列）都是 NA 才去掉这整行。</li><li>thresh：设置需要多少非空值的数据才可以保留下来的。</li><li>subset：设置想要检查的列。如果是多个列，可以使用列名的 list 作为参数。</li><li>inplace：如果设置 True，将计算得到的值直接覆盖之前的值并返回 None，修改的是源数据。</li></ul><p>可以先用isnull()判断是否为空。</p><p>可以在read_csv（）方法中指定空数据的数据类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>missing_values = [<span class="hljs-string">&quot;n/a&quot;</span>, <span class="hljs-string">&quot;na&quot;</span>, <span class="hljs-string">&quot;--&quot;</span>]<br>df = pd.read_csv(<span class="hljs-string">&#x27;property-data.csv&#x27;</span>, na_values = missing_values)<br></code></pre></td></tr></table></figure><p>dropna会返回一个新的Dataframe不会修改源数据。如果需要修改在inplace设置为True。</p><p>移除指定列有空值的行（移除 ST_NUM 列值为空）<code>df.dropna(subset=[&#39;ST_NUM&#39;], inplace = True)</code></p><p>我们也可以 <strong>fillna()</strong> 方法来替换一些空字段<code>df.fillna(12345, inplace = True)</code></p><p>指定某一个列来替换数据<code>df[&#39;PID&#39;].fillna(12345, inplace = True)</code></p><p>替换空单元格的常用方法是计算列的均值、中值或众数。</p><p>Pandas使用 <strong>mean()<strong>、</strong>median()</strong> 和 <strong>mode()</strong> 方法计算列的均值（所有值加起来的平均值）、中位数值（排序后排在中间的数）和众数（出现频率最高的数）。</p><p>比如mode() 方法计算列的众数并替换空单元格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>df = pd.read_csv(<span class="hljs-string">&#x27;property-data.csv&#x27;</span>)<br><br>x = df[<span class="hljs-string">&quot;ST_NUM&quot;</span>].mode()<br><br>df[<span class="hljs-string">&quot;ST_NUM&quot;</span>].fillna(x, inplace = <span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(df.to_string())<br></code></pre></td></tr></table></figure><p><strong>清洗格式错误数据:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># 第三个日期格式错误</span><br>data = &#123;<br>  <span class="hljs-string">&quot;Date&quot;</span>: [<span class="hljs-string">&#x27;2020/12/01&#x27;</span>, <span class="hljs-string">&#x27;2020/12/02&#x27;</span> , <span class="hljs-string">&#x27;20201226&#x27;</span>],<br>  <span class="hljs-string">&quot;duration&quot;</span>: [<span class="hljs-number">50</span>, <span class="hljs-number">40</span>, <span class="hljs-number">45</span>]<br>&#125;<br><br>df = pd.DataFrame(data, index = [<span class="hljs-string">&quot;day1&quot;</span>, <span class="hljs-string">&quot;day2&quot;</span>, <span class="hljs-string">&quot;day3&quot;</span>])<br><br>df[<span class="hljs-string">&#x27;Date&#x27;</span>] = pd.to_datetime(df[<span class="hljs-string">&#x27;Date&#x27;</span>])<br><br><span class="hljs-built_in">print</span>(df.to_string())<br><br><br><span class="hljs-comment">#output：</span><br>           Date  duration<br>day1 <span class="hljs-number">2020</span>-<span class="hljs-number">12</span>-01        <span class="hljs-number">50</span><br>day2 <span class="hljs-number">2020</span>-<span class="hljs-number">12</span>-02        <span class="hljs-number">40</span><br>day3 <span class="hljs-number">2020</span>-<span class="hljs-number">12</span>-<span class="hljs-number">26</span>        <span class="hljs-number">45</span><br></code></pre></td></tr></table></figure><p><strong>清洗错误数据：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>person = &#123;<br>  <span class="hljs-string">&quot;name&quot;</span>: [<span class="hljs-string">&#x27;Google&#x27;</span>, <span class="hljs-string">&#x27;Runoob&#x27;</span> , <span class="hljs-string">&#x27;Taobao&#x27;</span>],<br>  <span class="hljs-string">&quot;age&quot;</span>: [<span class="hljs-number">50</span>, <span class="hljs-number">40</span>, <span class="hljs-number">12345</span>]    <span class="hljs-comment"># 12345 年龄数据是错误的</span><br>&#125;<br><br>df = pd.DataFrame(person)<br><br>df.loc[<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;age&#x27;</span>] = <span class="hljs-number">30</span> <span class="hljs-comment"># 修改数据  对错误的数据进行替换或移除。也可以使用if来判断if df.loc[x, &quot;age&quot;] &gt; ?: df.drop(x, inplaced = True)</span><br><br><span class="hljs-built_in">print</span>(df.to_string())<br><br><span class="hljs-comment">#output:</span><br>     name  age<br><span class="hljs-number">0</span>  Google   <span class="hljs-number">50</span><br><span class="hljs-number">1</span>  Runoob   <span class="hljs-number">40</span><br><span class="hljs-number">2</span>  Taobao   <span class="hljs-number">30</span><br></code></pre></td></tr></table></figure><p><strong>清洗重复数据:</strong></p><p>如果我们要清洗重复数据，可以使用 <strong>duplicated()</strong> 和 <strong>drop_duplicates()</strong> 方法。</p><p>如果对应的数据是重复的，<strong>duplicated()</strong> 会返回 True，否则返回 False。</p><h2 id="Pandas-常用函数"><a href="#Pandas-常用函数" class="headerlink" title="Pandas 常用函数"></a>Pandas 常用函数</h2><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">pd.read_csv(filename)</td><td align="left">读取 CSV 文件；</td></tr><tr><td align="left">pd.read_excel(filename)</td><td align="left">读取 Excel 文件；</td></tr><tr><td align="left">pd.read_sql(query, connection_object)</td><td align="left">从 SQL 数据库读取数据；</td></tr><tr><td align="left">pd.read_json(json_string)</td><td align="left">从 JSON 字符串中读取数据；</td></tr><tr><td align="left">pd.read_html(url)</td><td align="left">从 HTML 页面中读取数据。</td></tr></tbody></table><h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df.head(n)</td><td align="left">显示前 n 行数据；</td></tr><tr><td align="left">df.tail(n)</td><td align="left">显示后 n 行数据；</td></tr><tr><td align="left">df.info()</td><td align="left">显示数据的信息，包括列名、数据类型、缺失值等；</td></tr><tr><td align="left">df.describe()</td><td align="left">显示数据的基本统计信息，包括均值、方差、最大值、最小值等；</td></tr><tr><td align="left">df.shape</td><td align="left">显示数据的行数和列数。</td></tr></tbody></table><h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df.dropna()</td><td align="left">删除包含缺失值的行或列；</td></tr><tr><td align="left">df.fillna(value)</td><td align="left">将缺失值替换为指定的值；</td></tr><tr><td align="left">df.replace(old_value, new_value)</td><td align="left">将指定值替换为新值；</td></tr><tr><td align="left">df.duplicated()</td><td align="left">检查是否有重复的数据；</td></tr><tr><td align="left">df.drop_duplicates()</td><td align="left">删除重复的数据。</td></tr></tbody></table><h3 id="数据选择和切片"><a href="#数据选择和切片" class="headerlink" title="数据选择和切片"></a>数据选择和切片</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df[column_name]</td><td align="left">选择指定的列；</td></tr><tr><td align="left">df.loc[row_index, column_name]</td><td align="left">通过标签选择数据；</td></tr><tr><td align="left">df.iloc[row_index, column_index]</td><td align="left">通过位置选择数据；</td></tr><tr><td align="left">df.ix[row_index, column_name]</td><td align="left">通过标签或位置选择数据；</td></tr><tr><td align="left">df.filter(items&#x3D;[column_name1, column_name2])</td><td align="left">选择指定的列；</td></tr><tr><td align="left">df.filter(regex&#x3D;’regex’)</td><td align="left">选择列名匹配正则表达式的列；</td></tr><tr><td align="left">df.sample(n)</td><td align="left">随机选择 n 行数据。</td></tr></tbody></table><h3 id="数据排序"><a href="#数据排序" class="headerlink" title="数据排序"></a>数据排序</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df.sort_values(column_name)</td><td align="left">按照指定列的值排序；</td></tr><tr><td align="left">df.sort_values([column_name1, column_name2], ascending&#x3D;[True, False])</td><td align="left">按照多个列的值排序；</td></tr><tr><td align="left">df.sort_index()</td><td align="left">按照索引排序。</td></tr></tbody></table><h3 id="数据分组和聚合"><a href="#数据分组和聚合" class="headerlink" title="数据分组和聚合"></a>数据分组和聚合</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df.groupby(column_name)</td><td align="left">按照指定列进行分组；</td></tr><tr><td align="left">df.aggregate(function_name)</td><td align="left">对分组后的数据进行聚合操作；</td></tr><tr><td align="left">df.pivot_table(values, index, columns, aggfunc)</td><td align="left">生成透视表。</td></tr></tbody></table><h3 id="数据合并"><a href="#数据合并" class="headerlink" title="数据合并"></a>数据合并</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">pd.concat([df1, df2])</td><td align="left">将多个数据框按照行或列进行合并；</td></tr><tr><td align="left">pd.merge(df1, df2, on&#x3D;column_name)</td><td align="left">按照指定列将两个数据框进行合并。</td></tr></tbody></table><h3 id="数据选择和过滤"><a href="#数据选择和过滤" class="headerlink" title="数据选择和过滤"></a>数据选择和过滤</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df.loc[row_indexer, column_indexer]</td><td align="left">按标签选择行和列。</td></tr><tr><td align="left">df.iloc[row_indexer, column_indexer]</td><td align="left">按位置选择行和列。</td></tr><tr><td align="left">df[df[‘column_name’] &gt; value]</td><td align="left">选择列中满足条件的行。</td></tr><tr><td align="left">df.query(‘column_name &gt; value’)</td><td align="left">使用字符串表达式选择列中满足条件的行。</td></tr></tbody></table><h3 id="数据统计和描述"><a href="#数据统计和描述" class="headerlink" title="数据统计和描述"></a>数据统计和描述</h3><table><thead><tr><th align="left">函数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">df.describe()</td><td align="left">计算基本统计信息，如均值、标准差、最小值、最大值等。</td></tr><tr><td align="left">df.mean()</td><td align="left">计算每列的平均值。</td></tr><tr><td align="left">df.median()</td><td align="left">计算每列的中位数。</td></tr><tr><td align="left">df.mode()</td><td align="left">计算每列的众数。</td></tr><tr><td align="left">df.count()</td><td align="left">计算每列非缺失值的数量。</td></tr></tbody></table><p>UPDATE TIME: 星期二 2023年9月19日</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>工具与软件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pandas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2-工具与软件-1-Numpy</title>
    <link href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/"/>
    <url>/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/</url>
    
    <content type="html"><![CDATA[<p>NumPy用于数据分析，提供了大量的维度数组与矩阵运算，NumPy 通常与 SciPy（Scientific Python）和 Matplotlib（绘图库）一起使用。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><code>sudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose</code></p><p>或使用pycharm在import numpy后自动导入。</p><h3 id="N-维数组对象-ndarray"><a href="#N-维数组对象-ndarray" class="headerlink" title="N 维数组对象 ndarray"></a>N 维数组对象 ndarray</h3><p>ndarray 中的每个元素在内存中都有相同存储大小的区域</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.array(<span class="hljs-built_in">object</span>, dtype = <span class="hljs-literal">None</span>, copy = <span class="hljs-literal">True</span>, order = <span class="hljs-literal">None</span>, subok = <span class="hljs-literal">False</span>, ndmin = <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">object</td><td align="left">数组或嵌套的数列</td></tr><tr><td align="left">dtype</td><td align="left">数组元素的数据类型，可选</td></tr><tr><td align="left">copy</td><td align="left">对象是否需要复制，可选</td></tr><tr><td align="left">order</td><td align="left">创建数组的样式，C为行方向，F为列方向，A为任意方向（默认）</td></tr><tr><td align="left">subok</td><td align="left">默认返回一个与基类类型一致的数组</td></tr><tr><td align="left">ndmin</td><td align="left">指定生成数组的最小维度</td></tr></tbody></table><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>int8, int16, int32, int64 四种数据类型可以使用字符串 ‘i1’, ‘i2’,’i4’,’i8’ 代替</p><table><thead><tr><th align="left">名称</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">bool_</td><td align="left">布尔型数据类型（True 或者 False）</td></tr><tr><td align="left">int_</td><td align="left">默认的整数类型（类似于 C 语言中的 long，int32 或 int64）</td></tr><tr><td align="left">intc</td><td align="left">与 C 的 int 类型一样，一般是 int32 或 int 64</td></tr><tr><td align="left">intp</td><td align="left">用于索引的整数类型（类似于 C 的 ssize_t，一般情况下仍然是 int32 或 int64）</td></tr><tr><td align="left">int8</td><td align="left">字节（-128 to 127）</td></tr><tr><td align="left">int16</td><td align="left">整数（-32768 to 32767）</td></tr><tr><td align="left">int32</td><td align="left">整数（-2147483648 to 2147483647）</td></tr><tr><td align="left">int64</td><td align="left">整数（-9223372036854775808 to 9223372036854775807）</td></tr><tr><td align="left">uint8</td><td align="left">无符号整数（0 to 255）</td></tr><tr><td align="left">uint16</td><td align="left">无符号整数（0 to 65535）</td></tr><tr><td align="left">uint32</td><td align="left">无符号整数（0 to 4294967295）</td></tr><tr><td align="left">uint64</td><td align="left">无符号整数（0 to 18446744073709551615）</td></tr><tr><td align="left">float_</td><td align="left">float64 类型的简写</td></tr><tr><td align="left">float16</td><td align="left">半精度浮点数，包括：1 个符号位，5 个指数位，10 个尾数位</td></tr><tr><td align="left">float32</td><td align="left">单精度浮点数，包括：1 个符号位，8 个指数位，23 个尾数位</td></tr><tr><td align="left">float64</td><td align="left">双精度浮点数，包括：1 个符号位，11 个指数位，52 个尾数位</td></tr><tr><td align="left">complex_</td><td align="left">complex128 类型的简写，即 128 位复数</td></tr><tr><td align="left">complex64</td><td align="left">复数，表示双 32 位浮点数（实数部分和虚数部分）</td></tr><tr><td align="left">complex128</td><td align="left">复数，表示双 64 位浮点数（实数部分和虚数部分）</td></tr></tbody></table><p>在创建dtype中（数据类型对象），每个内建类型都有一个唯一定义它的字符代码</p><table><thead><tr><th align="left">字符</th><th align="left">对应类型</th></tr></thead><tbody><tr><td align="left">b</td><td align="left">布尔型</td></tr><tr><td align="left">i</td><td align="left">(有符号) 整型</td></tr><tr><td align="left">u</td><td align="left">无符号整型 integer</td></tr><tr><td align="left">f</td><td align="left">浮点型</td></tr><tr><td align="left">c</td><td align="left">复数浮点型</td></tr><tr><td align="left">m</td><td align="left">timedelta（时间间隔）</td></tr><tr><td align="left">M</td><td align="left">datetime（日期时间）</td></tr><tr><td align="left">O</td><td align="left">(Python) 对象</td></tr><tr><td align="left">S, a</td><td align="left">(byte-)字符串</td></tr><tr><td align="left">U</td><td align="left">Unicode</td></tr><tr><td align="left">V</td><td align="left">原始数据 (void)</td></tr></tbody></table><h3 id="Numpy数组"><a href="#Numpy数组" class="headerlink" title="Numpy数组"></a>Numpy数组</h3><p>维数——秩（rank），维度——轴（axis）</p><table><thead><tr><th align="left">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">ndarray.ndim</td><td align="left">秩，即轴的数量或维度的数量</td></tr><tr><td align="left">ndarray.shape</td><td align="left">数组的维度，对于矩阵，n 行 m 列</td></tr><tr><td align="left">ndarray.size</td><td align="left">数组元素的总个数，相当于 .shape 中 n*m 的值</td></tr><tr><td align="left">ndarray.dtype</td><td align="left">ndarray 对象的元素类型</td></tr><tr><td align="left">ndarray.itemsize</td><td align="left">ndarray 对象中每个元素的大小，以字节为单位</td></tr><tr><td align="left">ndarray.flags</td><td align="left">ndarray 对象的内存信息</td></tr><tr><td align="left">ndarray.real</td><td align="left">ndarray元素的实部</td></tr><tr><td align="left">ndarray.imag</td><td align="left">ndarray 元素的虚部</td></tr><tr><td align="left">ndarray.data</td><td align="left">包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。</td></tr></tbody></table><p>数组的创建</p><p><code>numpy.empty</code> 方法用来创建一个指定形状（shape）、数据类型（dtype）且未初始化的数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.empty(shape, dtype = <span class="hljs-built_in">float</span>, order = <span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">shape</td><td align="left">数组形状</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选</td></tr><tr><td align="left">order</td><td align="left">有”C”和”F”两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序。</td></tr></tbody></table><p><code>numpy.zeros</code> 创建指定大小的数组，数组元素以 0 来填充：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.zeros(shape, dtype = <span class="hljs-built_in">float</span>, order = <span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">shape</td><td align="left">数组形状</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选 默认为浮点数</td></tr><tr><td align="left">order</td><td align="left">‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组</td></tr></tbody></table><p><code>numpy.ones</code> 创建指定形状的数组，数组元素以 1 来填充：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.ones(shape, dtype = <span class="hljs-literal">None</span>, order = <span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">shape</td><td align="left">数组形状</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选 默认为浮点数</td></tr><tr><td align="left">order</td><td align="left">‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组</td></tr></tbody></table><p><code>numpy.zeros_like</code>  <code>numpy.ones_like</code> 创建一个模仿数组，以1或者0进行填充。</p><p>numpy.asarray 类似 numpy.array，但 numpy.asarray 参数只有三个，比 numpy.array 少两个。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">numpy.asarray(a, dtype = None, <span class="hljs-keyword">order</span> <span class="hljs-title">= None</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">a</td><td align="left">任意形式的输入参数，可以是，列表, 列表的元组, 元组, 元组的元组, 元组的列表，多维数组</td></tr><tr><td align="left">dtype</td><td align="left">数据类型，可选</td></tr><tr><td align="left">order</td><td align="left">可选，有”C”和”F”两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序。</td></tr></tbody></table><p>例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>x = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>a = np.asarray(x)<br><span class="hljs-built_in">print</span>(x)<br><span class="hljs-built_in">print</span>(a)<br></code></pre></td></tr></table></figure><h6 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br><span class="hljs-comment">#由此可以看出list和array的区别</span><br></code></pre></td></tr></table></figure><p><code>numpy.frombuffer</code> 用于实现动态数组。</p><p><code>numpy.frombuffer</code> 接受 buffer 输入参数，以流的形式读入转化成 ndarray 对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.frombuffer(buffer, dtype = <span class="hljs-built_in">float</span>, count = -<span class="hljs-number">1</span>, offset = <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">buffer</td><td align="left">可以是任意对象，会以流的形式读入。</td></tr><tr><td align="left">dtype</td><td align="left">返回数组的数据类型，可选</td></tr><tr><td align="left">count</td><td align="left">读取的数据数量，默认为-1，读取所有数据。</td></tr><tr><td align="left">offset</td><td align="left">读取的起始位置，默认为0。</td></tr></tbody></table><p><code>numpy.fromiter</code> 方法从可迭代对象中建立 ndarray 对象，返回一维数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.fromiter(iterable, dtype, count=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">iterable</td><td align="left">可迭代对象</td></tr><tr><td align="left">dtype</td><td align="left">返回数组的数据类型</td></tr><tr><td align="left">count</td><td align="left">读取的数据数量，默认为-1，读取所有数据</td></tr></tbody></table><p>从数值范围创建数组</p><p>numpy 包中的使用 arange 函数创建数值范围并返回 ndarray 对象，函数格式如下：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">numpy.<span class="hljs-built_in">arange</span>(start, stop, step, dtype)<br></code></pre></td></tr></table></figure><p>根据 start 与 stop 指定的范围以及 step 设定的步长，生成一个 ndarray。</p><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>start</code></td><td align="left">起始值，默认为<code>0</code></td></tr><tr><td align="left"><code>stop</code></td><td align="left">终止值（不包含）</td></tr><tr><td align="left"><code>step</code></td><td align="left">步长，默认为<code>1</code></td></tr><tr><td align="left"><code>dtype</code></td><td align="left">返回<code>ndarray</code>的数据类型，如果没有提供，则会使用输入数据的类型。</td></tr></tbody></table><p><code>numpy.linspace</code> 函数用于创建一个一维数组，数组是一个等<strong>差数列构</strong>成的，格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">np.linspace(start, stop, <span class="hljs-attribute">num</span>=50, <span class="hljs-attribute">endpoint</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">retstep</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">dtype</span>=None)<br></code></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>start</code></td><td align="left">序列的起始值</td></tr><tr><td align="left"><code>stop</code></td><td align="left">序列的终止值，如果<code>endpoint</code>为<code>true</code>，该值包含于数列中</td></tr><tr><td align="left"><code>num</code></td><td align="left">要生成的等步长的样本数量，默认为<code>50</code></td></tr><tr><td align="left"><code>endpoint</code></td><td align="left">该值为 <code>true</code> 时，数列中包含<code>stop</code>值，反之不包含，默认是True。</td></tr><tr><td align="left"><code>retstep</code></td><td align="left">如果为 True 时，生成的数组中会显示间距，反之不显示。</td></tr><tr><td align="left"><code>dtype</code></td><td align="left"><code>ndarray</code> 的数据类型</td></tr></tbody></table><p><code>numpy.logspace</code> 函数用于创建一个于<strong>等比数列</strong>。格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">np.logspace(start, stop, <span class="hljs-attribute">num</span>=50, <span class="hljs-attribute">endpoint</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">base</span>=10.0, <span class="hljs-attribute">dtype</span>=None)<br></code></pre></td></tr></table></figure><p>base 参数意思是取对数的时候 log 的下标。</p><table><thead><tr><th align="left">参数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>start</code></td><td align="left">序列的起始值为：base ** start</td></tr><tr><td align="left"><code>stop</code></td><td align="left">序列的终止值为：base ** stop。如果<code>endpoint</code>为<code>true</code>，该值包含于数列中</td></tr><tr><td align="left"><code>num</code></td><td align="left">要生成的等步长的样本数量，默认为<code>50</code></td></tr><tr><td align="left"><code>endpoint</code></td><td align="left">该值为 <code>true</code> 时，数列中中包含<code>stop</code>值，反之不包含，默认是True。</td></tr><tr><td align="left"><code>base</code></td><td align="left">对数 log 的底数。</td></tr><tr><td align="left"><code>dtype</code></td><td align="left"><code>ndarray</code> 的数据类型</td></tr></tbody></table><h3 id="切片和索引"><a href="#切片和索引" class="headerlink" title="切片和索引"></a>切片和索引</h3><p>与list的切片相差不大，使用slice方法或者[:::] (start:finish:step)即可，另外对于多维数组的切分，可使用省略号<code>...</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br><span class="hljs-built_in">print</span>(a[..., <span class="hljs-number">1</span>])  <span class="hljs-comment"># 第2列元素</span><br><span class="hljs-built_in">print</span>(a[<span class="hljs-number">1</span>, ...])  <span class="hljs-comment"># 第2行元素</span><br><span class="hljs-built_in">print</span>(a[..., <span class="hljs-number">1</span>:])  <span class="hljs-comment"># 第2列及剩下的所有元素</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">[[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br> [<span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br> [<span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span>]]<br>---------------------<br>[<span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br>---------------------<br>[<span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br>---------------------<br>[[<span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br> [<span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br> [<span class="hljs-number">5</span> <span class="hljs-number">6</span>]]<br></code></pre></td></tr></table></figure><p>整数数组索引是指使用一个数组来访问另一个数组的元素。这个数组中的每个元素都是目标数组中某个维度上的索引值。</p><p>以下实例获取了 4X3 数组中的四个角的元素。 行索引是 [0,0] 和 [3,3]，而列索引是 [0,2] 和 [0,2]。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br> <br>x = np.array([[  <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>],[  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>],[  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],[  <span class="hljs-number">9</span>,  <span class="hljs-number">10</span>,  <span class="hljs-number">11</span>]])  <br><span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;我们的数组是：&#x27;</span> )<br><span class="hljs-built_in">print</span> (x)<br><span class="hljs-built_in">print</span> (<span class="hljs-string">&#x27;\n&#x27;</span>)<br>rows = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]]) <br>cols = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]]) <br><span class="hljs-comment">#这里的索引是0 0,0 2,3 0,3 2</span><br>y = x[rows,cols]  <br><span class="hljs-built_in">print</span>  (<span class="hljs-string">&#x27;这个数组的四个角元素是：&#x27;</span>)<br><span class="hljs-built_in">print</span> (y)<br><br></code></pre></td></tr></table></figure><h6 id="Output-1"><a href="#Output-1" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">我们的数组是：<br>[[ <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>]<br> [ <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">5</span>]<br> [ <span class="hljs-number">6</span>  <span class="hljs-number">7</span>  <span class="hljs-number">8</span>]<br> [ <span class="hljs-number">9</span> <span class="hljs-number">10</span> <span class="hljs-number">11</span>]]<br><br><br>这个数组的四个角元素是：<br>[[ <span class="hljs-number">0</span>  <span class="hljs-number">2</span>]<br> [ <span class="hljs-number">9</span> <span class="hljs-number">11</span>]]<br></code></pre></td></tr></table></figure><p>关于 np.ix_ 的具体使用：</p><p><code>x[np.ix_([1,5,7,2],[0,3,1,2])]</code> 这句话会输出一个4*4的矩阵，其中的元素分别是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]<br>x[<span class="hljs-number">5</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">5</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">5</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">5</span>,<span class="hljs-number">2</span>]<br>x[<span class="hljs-number">7</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">7</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">7</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">7</span>,<span class="hljs-number">2</span>]<br>x[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>] x[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>] x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>] x[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure><p>相当于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">y=np.array([[x[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], x[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], x[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]],\<br>            [x[<span class="hljs-number">5</span>,<span class="hljs-number">0</span>], x[<span class="hljs-number">5</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">5</span>,<span class="hljs-number">1</span>],x[<span class="hljs-number">5</span>,<span class="hljs-number">2</span>]],\<br>            [x[<span class="hljs-number">7</span>,<span class="hljs-number">0</span>] ,x[<span class="hljs-number">7</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">7</span>,<span class="hljs-number">1</span>], x[<span class="hljs-number">7</span>,<span class="hljs-number">2</span>]],\<br>            [x[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>], x[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], x[<span class="hljs-number">2</span>,<span class="hljs-number">1</span>], x[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]]])<br></code></pre></td></tr></table></figure><p>就是说，如果 np.xi_ 中输入两个列表，则第一个列表存的是待提取元素的行标，第二个列表存的是待提取元素的列标，第一个列表中的每个元素都会遍历第二个列表中的每个值，构成新矩阵的一行元素。</p><h3 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h3><p>广播(Broadcast)是 numpy 对不同形状(shape)的数组进行数值计算的方式， 对数组的算术运算通常在相应的元素上进行。</p><p>如果两个数组 a 和 b 形状相同，即满足 <strong>a.shape &#x3D;&#x3D; b.shape</strong>，那么 a*b 的结果就是 a 与 b 数组对应位相乘。这要求维数相同，且各维度的长度相同。</p><p>但是两个数组形状不同时，numpy就触发了广播机制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>a = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>              [<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>],<br>              [<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">20</span>],<br>              [<span class="hljs-number">30</span>, <span class="hljs-number">30</span>, <span class="hljs-number">30</span>]])<br>b = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<br><span class="hljs-built_in">print</span>(a + b)<br></code></pre></td></tr></table></figure><p><img src="https://www.runoob.com/wp-content/uploads/2018/10/image0020619.gif" alt="img"></p><h6 id="Output-2"><a href="#Output-2" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">[[ <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>]<br> [<span class="hljs-number">10</span> <span class="hljs-number">11</span> <span class="hljs-number">12</span>]<br> [<span class="hljs-number">20</span> <span class="hljs-number">21</span> <span class="hljs-number">22</span>]<br> [<span class="hljs-number">30</span> <span class="hljs-number">31</span> <span class="hljs-number">32</span>]]<br></code></pre></td></tr></table></figure><h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><p>NumPy 迭代器对象<code>numpy.nditer</code>提供了一种灵活访问一个或者多个数组元素的方式。</p><p><code>for x in np.nditer(a, order=&#39;F&#39;):</code>Fortran order，即是列序优先；</p><p><code>for x in np.nditer(a.T, order=&#39;C&#39;):</code>C order，即是行序优先；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.nditer(a, op_flags=[<span class="hljs-string">&#x27;readwrite&#x27;</span>]): <br>    x[...]=<span class="hljs-number">2</span>*x <br></code></pre></td></tr></table></figure><p><strong>x[…]</strong> 是修改原 numpy 元素，x 只是个拷贝。</p><p>order &#x3D; ‘C’，numpy 实例（也就是一个多维数组）本身的存储顺序不会因为转置或 order &#x3D; ‘C’ 或 ‘F’ 而改变。</p><p>只是 numpy 实例中，存储了一个默认的访问顺序的字段。</p><p>numpy.copy 做了特殊处理，它拷贝的时候不是直接把对方的内存复制，而是按照上面 order 指定的顺序逐一拷贝。</p><p><strong>for x in np.nditer(a, order &#x3D; ‘C’)</strong>: 可以在循环中另外指定顺序，如果未指定，则按照上面数组的order顺序访问。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.nditer(a, flags = [<span class="hljs-string">&#x27;external_loop&#x27;</span>], order = <span class="hljs-string">&#x27;F&#x27;</span>): <br>    <span class="hljs-built_in">print</span> (x, end=<span class="hljs-string">&quot;, &quot;</span> )<br></code></pre></td></tr></table></figure><p>**flags &#x3D; [‘external_loop’]**，当数组的 order 与在循环中指定的 order 顺序不同时，打印为多个一维数组，当相同时，是整个一个一维数组。</p><h3 id="数组操作"><a href="#数组操作" class="headerlink" title="数组操作"></a>数组操作</h3><p>这一部分基本上一些方法，这里只对方法的函数名和描述给出。</p><p><strong>修改数组形状</strong></p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>reshape</code></td><td align="left">不改变数据的条件下修改形状 numpy.reshape(arr, newshape, order&#x3D;’C’)</td></tr><tr><td align="left"><code>flat</code></td><td align="left">数组元素迭代器</td></tr><tr><td align="left"><code>flatten</code></td><td align="left">返回一份数组拷贝，对拷贝所做的修改不会影响原始数组 ndarray.flatten(order&#x3D;’C’)</td></tr><tr><td align="left"><code>ravel</code></td><td align="left">返回展开数组 numpy.ravel(a, order&#x3D;’C’)</td></tr></tbody></table><p><strong>翻转数组</strong></p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>transpose</code></td><td align="left">对换数组的维度 numpy.transpose(arr, axes)</td></tr><tr><td align="left"><code>ndarray.T</code></td><td align="left">和 <code>self.transpose()</code> 相同</td></tr><tr><td align="left"><code>rollaxis</code></td><td align="left">向后滚动指定的轴 numpy.rollaxis(arr, axis, start)</td></tr><tr><td align="left"><code>swapaxes</code></td><td align="left">对换数组的两个轴 numpy.swapaxes(arr, axis1, axis2)</td></tr></tbody></table><p><strong>修改数组维度</strong></p><table><thead><tr><th align="left">维度</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>broadcast</code></td><td align="left">产生模仿广播的对象</td></tr><tr><td align="left"><code>broadcast_to</code></td><td align="left">将数组广播到新形状 numpy.broadcast_to(array, shape, subok)</td></tr><tr><td align="left"><code>expand_dims</code></td><td align="left">扩展数组的形状  numpy.expand_dims(arr, axis)</td></tr><tr><td align="left"><code>squeeze</code></td><td align="left">从数组的形状中删除一维条目 numpy.squeeze(arr, axis)</td></tr></tbody></table><p><strong>连接数组</strong></p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>concatenate</code></td><td align="left">连接沿现有轴的数组序列 numpy.concatenate((a1, a2, …), axis)</td></tr><tr><td align="left"><code>stack</code></td><td align="left">沿着新的轴加入一系列数组。 numpy.stack(arrays, axis)</td></tr><tr><td align="left"><code>hstack</code></td><td align="left">水平堆叠序列中的数组（列方向）</td></tr><tr><td align="left"><code>vstack</code></td><td align="left">竖直堆叠序列中的数组（行方向）</td></tr></tbody></table><p><strong>分割数组</strong></p><table><thead><tr><th align="left">函数</th><th align="left">数组及操作</th></tr></thead><tbody><tr><td align="left"><code>split</code></td><td align="left">将一个数组分割为多个子数组 numpy.split(ary, indices_or_sections, axis)</td></tr><tr><td align="left"><code>hsplit</code></td><td align="left">将一个数组水平分割为多个子数组（按列）</td></tr><tr><td align="left"><code>vsplit</code></td><td align="left">将一个数组垂直分割为多个子数组（按行）</td></tr></tbody></table><p><strong>数组元素的添加与删除</strong></p><table><thead><tr><th align="left">函数</th><th align="left">元素及描述</th></tr></thead><tbody><tr><td align="left"><code>resize</code></td><td align="left">返回指定形状的新数组 numpy.resize(arr, shape)</td></tr><tr><td align="left"><code>append</code></td><td align="left">将值添加到数组末尾 numpy.append(arr, values, axis&#x3D;None)</td></tr><tr><td align="left"><code>insert</code></td><td align="left">沿指定轴将值插入到指定下标之前 numpy.insert(arr, obj, values, axis)</td></tr><tr><td align="left"><code>delete</code></td><td align="left">删掉某个轴的子数组，并返回删除后的新数组 Numpy.delete(arr, obj, axis)</td></tr><tr><td align="left"><code>unique</code></td><td align="left">查找数组内的唯一元素 numpy.unique(arr, return_index, return_inverse, return_counts)</td></tr></tbody></table><h3 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h3><p>Numpy也是内置位运算函数的，我认为这部分了解即可</p><p><a href="https://www.runoob.com/numpy/numpy-binary-operators.html">菜鸟教程-NumPy 位运算</a></p><p>NumPy <strong>“bitwise_”</strong> 开头的函数是位运算函数。</p><p>NumPy 位运算包括以下几个函数：</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>bitwise_and</code></td><td align="left">对数组元素执行位与操作</td></tr><tr><td align="left"><code>bitwise_or</code></td><td align="left">对数组元素执行位或操作</td></tr><tr><td align="left"><code>invert</code></td><td align="left">按位取反</td></tr><tr><td align="left"><code>left_shift</code></td><td align="left">向左移动二进制表示的位</td></tr><tr><td align="left"><code>right_shift</code></td><td align="left">向右移动二进制表示的位</td></tr></tbody></table><p><strong>注：</strong>也可以使用 “&amp;”、 “~”、 “|” 和 “^” 等操作符进行计算。</p><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>Numpy的字符串函数是基于Python内置库中的标准字符串函数。</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>add()</code></td><td align="left">对两个数组的逐个字符串元素进行连接</td></tr><tr><td align="left"><code>multiply()</code></td><td align="left">返回按元素多重连接后的字符串</td></tr><tr><td align="left"><code>center()</code></td><td align="left">居中字符串</td></tr><tr><td align="left"><code>capitalize()</code></td><td align="left">将字符串第一个字母转换为大写</td></tr><tr><td align="left"><code>title()</code></td><td align="left">将字符串的每个单词的第一个字母转换为大写</td></tr><tr><td align="left"><code>lower()</code></td><td align="left">数组元素转换为小写</td></tr><tr><td align="left"><code>upper()</code></td><td align="left">数组元素转换为大写</td></tr><tr><td align="left"><code>split()</code></td><td align="left">指定分隔符对字符串进行分割，并返回数组列表</td></tr><tr><td align="left"><code>splitlines()</code></td><td align="left">返回元素中的行列表，以换行符分割</td></tr><tr><td align="left"><code>strip()</code></td><td align="left">移除元素开头或者结尾处的特定字符</td></tr><tr><td align="left"><code>join()</code></td><td align="left">通过指定分隔符来连接数组中的元素</td></tr><tr><td align="left"><code>replace()</code></td><td align="left">使用新字符串替换字符串中的所有子字符串</td></tr><tr><td align="left"><code>decode()</code></td><td align="left">数组元素依次调用<code>str.decode</code></td></tr><tr><td align="left"><code>encode()</code></td><td align="left">数组元素依次调用<code>str.encode</code></td></tr></tbody></table><h3 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h3><p>提供了标准的三角函数：**sin()、cos()、tan()**。</p><p><strong>arcsin，arccos，和 arctan</strong> 函数返回给定角度的 sin，cos 和 tan 的反三角函数。</p><p>这些函数的结果可以通过<code>numpy.degrees()</code>函数将弧度转换为角度。</p><p><code>numpy.around()</code> 函数返回指定数字的四舍五入值。<br><code>numpy.around(a,decimals)</code> decimals: 舍入的小数位数。 默认值为0。 如果为负，整数将四舍五入到小数点左侧的位置</p><p><code>numpy.floor()</code> 返回小于或者等于指定表达式的最大整数，即向下取整。</p><p><code>numpy.ceil()</code> 返回大于或者等于指定表达式的最小整数，即向上取整。</p><p>NumPy 算术函数包含简单的加减乘除: <strong>add()<strong>，</strong>subtract()<strong>，</strong>multiply()</strong> 和 **divide()**。</p><p><code>numpy.reciprocal() </code>函数返回参数逐元素的<strong>倒数</strong>。如 <strong>1&#x2F;4</strong> 倒数为 <strong>4&#x2F;1</strong>。</p><p><code>numpy.power() </code>函数将第一个输入数组中的元素作为底数，计算它与第二个输入数组中相应元素的幂。</p><p><code>numpy.mod() </code>计算输入数组中相应元素的相除后的余数。函数<code>numpy.remainder()</code>也产生相同的结果。</p><h3 id="统计学"><a href="#统计学" class="headerlink" title="统计学"></a>统计学</h3><p>NumPy 提供了很多统计函数，用于从数组中查找最小元素，最大元素，百分位标准差和方差等。</p><p>这些统计学函数通常带有较多的传入参数，详见<a href="https://www.runoob.com/numpy/numpy-statistical-functions.html">统计学函数</a></p><p><code>numpy.amin()</code> 用于计算数组中的元素沿指定轴的最小值。</p><p><code>numpy.amax() </code>用于计算数组中的元素沿指定轴的最大值。</p><p><code>numpy.ptp()</code>函数计算数组中元素最大值与最小值的差（最大值 - 最小值）。</p><p><code>numpy.percentile()</code>百分位数是统计中使用的度量，表示小于这个值的观察值的百分比。 </p><p><code>numpy.median() </code>函数用于计算数组 a 中元素的中位数（中值）</p><p><code>numpy.mean()</code> 函数返回数组中元素的算术平均值，如果提供了轴，则沿其计算。</p><p><code>numpy.average() </code>函数根据在另一个数组中给出的各自的权重计算数组中元素的加权平均值。</p><p>标准差是一组数据平均值分散程度的一种度量。标准差是方差的算术平方根。</p><p>标准差公式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">std = sqrt(mean((x - x.mean())**<span class="hljs-number">2</span>))<br><span class="hljs-comment">#使用例：</span><br><span class="hljs-built_in">print</span> (np.std([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]))<br>&gt;&gt; <span class="hljs-number">1.1180339887498949</span><br></code></pre></td></tr></table></figure><p>统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数，</p><p>即 <code>mean((x - x.mean())** 2)</code></p><p>换句话说，标准差是方差的平方根。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#使用例：</span><br><span class="hljs-built_in">print</span> (np.var([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]))<br>&gt;&gt; <span class="hljs-number">1.25</span><br></code></pre></td></tr></table></figure><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><table><thead><tr><th align="left">种类</th><th align="left">速度</th><th align="left">最坏情况</th></tr></thead><tbody><tr><td align="left"><code>quicksort</code>（快速排序）</td><td align="left">1</td><td align="left"><code>O(n^2)</code></td></tr><tr><td align="left"><code>mergesort</code>（归并排序）</td><td align="left">2</td><td align="left"><code>O(n*log(n))</code></td></tr><tr><td align="left"><code>heapsort</code>（堆排序）</td><td align="left">3</td><td align="left"><code>O(n*log(n))</code></td></tr></tbody></table><p><code>numpy.sort() </code>函数返回输入数组的排序副本，numpy中还能以字段关键字排序。</p><p>倒序使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = <span class="hljs-built_in">abs</span>(np.sort(-x)) <br></code></pre></td></tr></table></figure><p><code>numpy.argsort() </code>函数返回的是数组值从小到大的索引值。</p><p><code>numpy.lexsort() </code>用于对多个序列进行排序。把它想象成对电子表格进行排序，每一列代表一个序列，排序时优先照顾靠后的列。</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>msort(a)</code></td><td align="left">数组按第一个轴排序，返回排序后的数组副本。np.msort(a) 相等于 np.sort(a, axis&#x3D;0)。</td></tr><tr><td align="left"><code>sort_complex(a)</code></td><td align="left">对复数按照先实部后虚部的顺序进行排序。</td></tr><tr><td align="left"><code>partition(a, kth[, axis, kind, order])</code></td><td align="left">指定一个数，对数组进行分区</td></tr><tr><td align="left"><code>argpartition(a, kth[, axis, kind, order])</code></td><td align="left">可以通过关键字 kind 指定算法沿着指定轴对数组进行分区</td></tr></tbody></table><p><code>numpy.argmax()</code> 和 <code>numpy.argmin()</code>函数分别沿给定轴返回最大和最小元素的索引。</p><p><code>numpy.nonzero() </code>函数返回输入数组中非零元素的索引。</p><p><code>numpy.where() </code>函数返回输入数组中满足给定条件的元素的索引。</p><p><code>numpy.extract()</code>函数根据某个条件从数组中抽取元素，返回满条件的元素。</p><h3 id="字节交换"><a href="#字节交换" class="headerlink" title="字节交换"></a>字节交换</h3><ul><li><strong>大端模式：</strong>指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中，这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放；这和我们的阅读习惯一致。</li><li><strong>小端模式：</strong>指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低。</li></ul><p><code>numpy.ndarray.byteswap() </code>函数将 ndarray 中每个元素中的字节进行大小端转换。</p><p>(我并不知道这样做这有什么用)</p><h3 id="副本和视图"><a href="#副本和视图" class="headerlink" title="副本和视图"></a>副本和视图</h3><p>和数据库语言的副本、视图类似。</p><p>视图或浅拷贝：<code>ndarray.view() </code>方会创建一个新的数组对象，该方法创建的新数组的维数变化不会改变原始数据的维数。</p><p>副本或深拷贝：<code>ndarray.copy() </code>函数创建一个副本。 对副本数据进行修改，不会影响到原始数据，它们物理内存不在同一位置。</p><h3 id="矩阵（matrix）与线性代数"><a href="#矩阵（matrix）与线性代数" class="headerlink" title="矩阵（matrix）与线性代数"></a>矩阵（matrix）与线性代数</h3><p>一个 m * n 的矩阵</p><p>转置： numpy.transpose 函数来对换数组的维度，还可以使用 <strong>T</strong> 属性。例如有个 m 行 n 列的矩阵，使用 t() 函数就能转换为 n 行 m 列的矩阵。</p><p><code>matlib.empty() </code>函数返回一个新的矩阵。</p><p><code>numpy.matlib.zeros() </code>函数创建一个以 0 填充的矩阵。</p><p><code>numpy.matlib.ones()</code>函数创建一个以 1 填充的矩阵。</p><p><code>numpy.matlib.eye()</code> 函数返回一个矩阵，对角线元素为 1，其他位置为零。</p><p><code>numpy.matlib.identity() </code>函数返回给定大小的单位矩阵。</p><p><code>numpy.matlib.rand() </code>函数创建一个给定大小的矩阵，数据是随机填充的。</p><p><strong>线性代数</strong>函数库 <strong>linalg</strong>，该库包含了线性代数所需的所有功能</p><table><thead><tr><th align="left">函数</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left"><code>dot</code></td><td align="left">两个数组的点积，即元素对应相乘。numpy.dot(a, b, out&#x3D;None)</td></tr><tr><td align="left"><code>vdot</code></td><td align="left">两个向量的点积</td></tr><tr><td align="left"><code>inner</code></td><td align="left">两个数组的内积</td></tr><tr><td align="left"><code>matmul</code></td><td align="left">两个数组的矩阵积</td></tr><tr><td align="left"><code>determinant</code></td><td align="left">数组的行列式</td></tr><tr><td align="left"><code>solve</code></td><td align="left">求解线性矩阵方程</td></tr><tr><td align="left"><code>inv</code></td><td align="left">计算矩阵的乘法逆矩阵</td></tr></tbody></table><p><code>numpy.linalg.det() </code>函数计算输入矩阵的行列式。</p><p><code>numpy.linalg.solve() </code>函数给出了矩阵形式的线性方程的解。</p><p><a href="https://www.runoob.com/numpy/numpy-linear-algebra.html">详见</a></p><h3 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h3><p>NumPy 为 ndarray 对象引入了一个简单的文件格式：<strong>npy</strong>。</p><p>npy 文件用于存储重建 ndarray 所需的数据、图形、dtype 和其他信息。</p><p><code>numpy.save() </code>函数将数组保存到以 .npy 为扩展名的文件中。</p><p><code>numpy.savez() </code>函数将多个数组保存到以 npz 为扩展名的文件中。</p><p><code>savetxt()</code> 函数是以简单的文本文件格式存储数据，对应的使用<code> loadtxt()</code> 函数来获取数据。</p><h3 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h3><p>Matplotlib 是 Python 的绘图库。 它可与 NumPy 一起使用，提供了一种有效的 MatLab 开源替代方案。 它也可以和图形工具包一起使用，如 PyQt 和 wxPython。</p><p><a href="https://search.bilibili.com/all?keyword=Matplotlib&from_source=webtop_search&spm_id_from=333.1007&search_source=5">详见</a></p><p>UPDATE TIME ： </p><p>2023年9月12日星期二</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>工具与软件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Numpy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1-基础部分-2-数学基础</title>
    <link href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <url>/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><h3 id="最优化问题"><a href="#最优化问题" class="headerlink" title="最优化问题"></a>最优化问题</h3><p>目标函数Error:<br>$$<br>E(\theta)&#x3D;\frac{1}{2} \sum_{i&#x3D;1}^n(y_i-f_\theta(x_i))^2<br>$$<br>i是指第 i 个训练数据.对每个训练数据的误差取平方之后，全部相加，然后乘以0.5 。这么做是为了找到使 E(θ) 的值最小的 θ。这样的问题称为最优化问题。</p><h3 id="最速下降法："><a href="#最速下降法：" class="headerlink" title="最速下降法："></a>最速下降法：</h3><p>$$<br>\theta_0 :&#x3D;\theta_0 - \eta\sum_{i&#x3D;1}^n(f_\theta(x_i)-y_i)<br>$$</p><p>$$<br>\theta_1 :&#x3D;\theta_1 - \eta\sum_{i&#x3D;1}^n(f_\theta(x_i)-y_i) x_i<br>$$</p><h3 id="多项式回归："><a href="#多项式回归：" class="headerlink" title="多项式回归："></a>多项式回归：</h3>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>基础部分</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1-基础部分-1-Python</title>
    <link href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/"/>
    <url>/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/</url>
    
    <content type="html"><![CDATA[<h1>Chapter 1</h1><h2 id="1-1-分解序列"><a href="#1-1-分解序列" class="headerlink" title="1.1 分解序列"></a>1.1 分解序列</h2><p>需要元素数量匹配，除了元组和列表，其余可迭代也可执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data = [<span class="hljs-string">&#x27;ACME&#x27;</span>, <span class="hljs-number">50</span>, <span class="hljs-number">91.9</span>, (<span class="hljs-number">2023</span>, <span class="hljs-number">9</span>, <span class="hljs-number">9</span>)]<br>name, shares, price, data = data<br><br><span class="hljs-built_in">print</span>(name, data)<br><br></code></pre></td></tr></table></figure><h6 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">ACME (<span class="hljs-number">2023</span>, <span class="hljs-number">9</span>, <span class="hljs-number">9</span>)<br></code></pre></td></tr></table></figure><h2 id="1-2-从可迭代对象中分解元素"><a href="#1-2-从可迭代对象中分解元素" class="headerlink" title="1.2 从可迭代对象中分解元素"></a>1.2 从可迭代对象中分解元素</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">avg</span>(<span class="hljs-params">nums</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(nums)/<span class="hljs-built_in">len</span>(nums)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">drop_fst_and_lst</span>(<span class="hljs-params">self</span>):<br>    fst, *mid, lst = self<br>    <span class="hljs-keyword">return</span> avg(mid)<br><br><br>grades = [<span class="hljs-number">100</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(drop_fst_and_lst(grades))<br></code></pre></td></tr></table></figure><h6 id="Output-1"><a href="#Output-1" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">10.0</span><br></code></pre></td></tr></table></figure><p>Tips:</p><p>将函数传入值改为self可避免暴露函数内的变量名。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">line = <span class="hljs-string">&#x27;gting:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false&#x27;</span><br><br>unmae, *fields, homedir, sh = line<span class="hljs-selector-class">.split</span>(<span class="hljs-string">&#x27;:&#x27;</span>)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(unmae)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(homedir)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(sh)</span></span><br></code></pre></td></tr></table></figure><h6 id="Output-2"><a href="#Output-2" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">gting<br>/var/empty<br>/usr/<span class="hljs-built_in">bin</span>/false<br></code></pre></td></tr></table></figure><h2 id="1-3-双向队列"><a href="#1-3-双向队列" class="headerlink" title="1.3 双向队列"></a>1.3 双向队列</h2><p>初始化：<code>q = deque(maxlen=?)</code></p><p><code>q.append(?)</code> 右侧插入元素</p><p><code>q.appendleft(?)</code> 左侧插入元素</p><p><code>q.pop()</code> 弹出右侧元素</p><p><code>q.popleft()</code> 弹出左侧元素</p><p>如果不指定队列的大小就是一个无限的队列，可在两段进行插入和弹出，并且都是O(1)，而列表是O(n)</p><h2 id="1-4-堆heapq"><a href="#1-4-堆heapq" class="headerlink" title="1.4 堆heapq"></a>1.4 堆<code>heapq</code></h2><p>找到最大或者最小的N个元素。</p><p><code>imort heapq</code></p><p><code>heapq</code>中有两个函数 <code>nlargest()</code> 和 <code>nsmallest()</code> </p><p><code>heapq.nlargest(?, ?list, key)</code> 取出最大的前三项，最小同理。</p><p><code>heapq.heapify(?list)</code>将list排序为小顶堆</p><p><code>heapq.heappop()</code> 获取弹出对顶元素，O(logn)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> heapq<br><br>portfolio = [<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;IBM&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">100</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">91.1</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;AAPL&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">50</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">543.22</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;FB&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">200</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">21.09</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;HPQ&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">31.75</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;YHOO&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">16.35</span>&#125;,<br>   &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;ACME&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">75</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">115.65</span>&#125;<br>]<br><br>cheap = heapq.nsmallest(<span class="hljs-number">3</span>, portfolio, key=<span class="hljs-keyword">lambda</span> s: s[<span class="hljs-string">&#x27;price&#x27;</span>])<br>expensive = heapq.nlargest(<span class="hljs-number">3</span>, portfolio, key=<span class="hljs-keyword">lambda</span> s: s[<span class="hljs-string">&#x27;price&#x27;</span>])<br><br><span class="hljs-built_in">print</span>(cheap)<br><span class="hljs-built_in">print</span>(expensive)<br></code></pre></td></tr></table></figure><h6 id="Output-3"><a href="#Output-3" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">[&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;YHOO&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">16.35</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;FB&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">200</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">21.09</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;HPQ&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">31.75</span>&#125;]<br>[&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;AAPL&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">50</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">543.22</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;ACME&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">75</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">115.65</span>&#125;, &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;IBM&#x27;</span>, <span class="hljs-string">&#x27;shares&#x27;</span>: <span class="hljs-number">100</span>, <span class="hljs-string">&#x27;price&#x27;</span>: <span class="hljs-number">91.1</span>&#125;]<br></code></pre></td></tr></table></figure><h2 id="1-5-优先队列"><a href="#1-5-优先队列" class="headerlink" title="1.5 优先队列"></a>1.5 优先队列</h2><p>使用 <code>heap</code>实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># example.py</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Example of a priority queue</span><br><br><span class="hljs-keyword">import</span> heapq<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PriorityQueue</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._queue = []<br>        self._index = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">push</span>(<span class="hljs-params">self, item, priority</span>):<br>        heapq.heappush(self._queue, (-priority, self._index, item))<br>        self._index += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pop</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> heapq.heappop(self._queue)[-<span class="hljs-number">1</span>]<br><br><br><span class="hljs-comment"># Example use</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Item</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name</span>):<br>        self.name = name<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Item(&#123;!r&#125;)&#x27;</span>.<span class="hljs-built_in">format</span>(self.name)<br><br><br>q = PriorityQueue()<br>q.push(Item(<span class="hljs-string">&#x27;foo&#x27;</span>), <span class="hljs-number">1</span>)<br>q.push(Item(<span class="hljs-string">&#x27;bar&#x27;</span>), <span class="hljs-number">5</span>)<br>q.push(Item(<span class="hljs-string">&#x27;spam&#x27;</span>), <span class="hljs-number">4</span>)<br>q.push(Item(<span class="hljs-string">&#x27;grok&#x27;</span>), <span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be bar:&quot;</span>, q.pop())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be spam:&quot;</span>, q.pop())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be foo:&quot;</span>, q.pop())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Should be grok:&quot;</span>, q.pop())<br></code></pre></td></tr></table></figure><h6 id="Output-4"><a href="#Output-4" class="headerlink" title="Output"></a>Output</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">Should be bar: Item(<span class="hljs-string">&#x27;bar&#x27;</span>)<br>Should be spam: Item(<span class="hljs-string">&#x27;spam&#x27;</span>)<br>Should be foo: Item(<span class="hljs-string">&#x27;foo&#x27;</span>)<br>Should be grok: Item(<span class="hljs-string">&#x27;grok&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="1-6-一键多值字典multdct"><a href="#1-6-一键多值字典multdct" class="headerlink" title="1.6 一键多值字典multdct"></a>1.6 一键多值字典<code>multdct</code></h2><p>使用<code>from collections import defaultdict</code></p><p>使用例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">d = defaultdict(<span class="hljs-built_in">list</span>)<br>d[<span class="hljs-string">&#x27;a&#x27;</span>].append(<span class="hljs-number">1</span>)<br>d[<span class="hljs-string">&#x27;a&#x27;</span>].append(<span class="hljs-number">2</span>)<br><br>d2 = defaultdict(<span class="hljs-built_in">set</span>)<br>d2[<span class="hljs-string">&#x27;a&#x27;</span>].add(<span class="hljs-number">1</span>)<br>d2[<span class="hljs-string">&#x27;a&#x27;</span>].add(<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><h2 id="1-7-有序字典"><a href="#1-7-有序字典" class="headerlink" title="1.7 有序字典"></a>1.7 有序字典</h2><p>使用<code>from collections import OrderedDict</code> 会严格按照字典添加的顺序进行。</p><p>可在JSON编码中控制各字段的顺序。</p><p>1.8 字典中的计算</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>基础部分</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3-机器学习-1-理论</title>
    <link href="/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/"/>
    <url>/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux下的锐捷认证</title>
    <link href="/2023/09/08/Linux%E4%B8%8B%E7%9A%84%E9%94%90%E6%8D%B7%E8%AE%A4%E8%AF%81/"/>
    <url>/2023/09/08/Linux%E4%B8%8B%E7%9A%84%E9%94%90%E6%8D%B7%E8%AE%A4%E8%AF%81/</url>
    
    <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">ping baidu.com -n 100|foreach -<span class="hljs-string">&quot; -f (Get-Date),<span class="hljs-variable">$_</span>&#125;</span><br><span class="hljs-string">#显示时间的PING指令</span><br></code></pre></td></tr></table></figure><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>第一次使用校园网，才知道校园网原来需要登录认证①，并且限制设备②，在没有办理校内校园流量卡的情况下，原来的流量卡只有100kb&#x2F;s速度（办了校园卡之后，速度也仅有2M&#x2F;s），已经严重影响使用，另外校园全覆盖WiFi，同样需要登录认证，速度大概在2mb&#x2F;s，但是无线传输的弊端就是不稳定，间断性断网已经成为常态。</p><p>①：wifi使用学号+密码网页认证登录，有线网需要锐捷客户端v6.84多运营商版本。</p><p>②：wifi+有线，同一帐号仅能支持两个设备登录，这对于联网终端多的人是无法使用的。</p><p>另外，最重要的是常用的编码环境Linux，官方并没有提供对应的linux的认证客户端，所以这也使linux设备的有线网络连接设下了障碍。</p><p>通过网络上前人的研究了解到，使用mentohust或者其迭代版本minieap可以实现linux系统认证通过锐捷，甚至可以将其交叉编译到软路由上；</p><p>那么，理论可行，实践开始。</p><h2 id="1-mentohust"><a href="#1-mentohust" class="headerlink" title="1.mentohust"></a>1.mentohust</h2><p>首先做提前准备，准备mentohust必须的文件。</p><p>gh源码：<code>gh repo clone hyrathb/mentohust</code></p><p>3个客户端源文件和1个mpf抓包</p><p>W32N55.dll0821x.exeSuConfig.datmentohust.mpf</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> /etc/mentohust<br>sudo <span class="hljs-built_in">cp</span> ./8021x.exe  /etc/mentohust<br>sudo <span class="hljs-built_in">cp</span> ./W32N55.dll /etc/mentohust<br>sudo <span class="hljs-built_in">cp</span> ./SuConfig.dat /etc/mentohust<br>sudo <span class="hljs-built_in">cp</span> ./mentohust.mpf /etc/mentohust<br></code></pre></td></tr></table></figure><p>mpf文件使用MentoHUSTTool进行获取</p><p>可能因为该项目过于久远，最后没能成功认证，换为minieap</p><h2 id="2-minieap"><a href="#2-minieap" class="headerlink" title="2.minieap"></a>2.minieap</h2><p>其原理和mentohust类似，不过需要手动编译两个文件——minieap和libpcap</p><p><a href="https://github.com/updateing/minieap">Minieap</a></p><p>可能由于多运营商的问题，无法获取运营商的id，这个版本的minieap也没能通过认证，所以让linux连接有线网络以失败告终。（其实是学校不准许出了windows端的任何客户端连接，以上两种方法都是基于准许linux客户端的前提下）</p><h2>最终解决思路</h2><p>一次偶然的机会，联系上了一位学长，他给出了重要的点拨提示。为什么要仿造锐捷进行认证呢？直接使用路由器仿造电脑不就行了。所以在路由器后台管理端仿造通过验证的电脑MAC即可，具体步骤：</p><ol><li>准备工作：网线至少1,路由器（千兆&#x2F;百兆），win系统电脑</li><li>电脑连接网线连接面板，正常进行锐捷认证。</li><li>认证通过后可以在锐捷软件或者本地网络属性查看链接速度（1000MBPS，100MBPS）</li><li>直接拔出面板端网线，插入路由器的LAN口。</li><li>根据路由器的本地网络进入路由器管理界面，设置仿造当前设备MAC地址，WAN口设置自动获取IP地址。</li><li>拔出电脑端网线和路由器端网线，分别插入路由器WAN口和面板，即可实现路由器上网。此时可使用第二根网线连接LAN口和电脑实现最优网络，也可以连接wifi使用。</li></ol><p>注意事项：面板一段时间没有流量会掉认证，重新认证需要重复上述步骤比较麻烦，可以一直连接用网设备来保活（比如wifi台灯）。过多设备会封号，请谨慎连接2个以上的设备。网口可能有千兆的，这也是为什么会提到千兆百兆的原因，如果你速度达不到，可能是出现木桶效应。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>不过我一直怀疑寝室里的网存在环路，导致广播风暴时常发生，只能期待校方有朝一日能够解决这个严重的问题。</p><p>另一种可能是网络大面积中毒，可以通过交换机的是否存在端口数量进行查看，不过真的有人在局域网内放蠕虫来偷取pcdn流量吗？</p><p>2024秋季更：锐捷客户端新加了5分钟一次的心跳包，这让仿造MAC地址成为无效化，所以<strong>以上方法均不可用</strong>。</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
