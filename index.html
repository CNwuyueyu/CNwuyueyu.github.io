

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Wuyueyu">
  <meta name="keywords" content="">
  
    <meta property="og:type" content="website">
<meta property="og:title" content="Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Wuyueyu">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />





<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":"3028c6400adaaa4521a5b772ad242a5e","google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 100vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>CV</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="A learning record website of SAUer"></span>
          
        </div>

        
      </div>

      
        <div class="scroll-down-bar">
          <i class="iconfont icon-arrowdown"></i>
        </div>
      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      <div class="container nopadding-x-md">
        <div id="board"
          style="margin-top: 0">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/05/08/0-MedficientSAM-A-Robust-Medical-Segmentation-Model-with-Optimized-Inference-Pipeline-for-Limited-Clinical-Settings/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-MedficientSAM: A Robust Medical Segmentation Model with Optimized Inference Pipeline for Limited Clinical Settings">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/05/08/0-MedficientSAM-A-Robust-Medical-Segmentation-Model-with-Optimized-Inference-Pipeline-for-Limited-Clinical-Settings/" target="_blank">
          0-MedficientSAM: A Robust Medical Segmentation Model with Optimized Inference Pipeline for Limited Clinical Settings
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/05/08/0-MedficientSAM-A-Robust-Medical-Segmentation-Model-with-Optimized-Inference-Pipeline-for-Limited-Clinical-Settings/" target="_blank">
        <div>
          MedficientsAM：具有优化推理管道的强大医学分割模型，用于有限的临床环境 背景SAM的出现使通用医学图像分割模型的开发跨越了不同的模式。但是，临床环境中这种深度学习模型的推理仍然受到对强大计算设备的依赖的限制。 医学图像的早期分割模型通常基于nnUNET结构。尽管有效，但这些模型仅限于特定数据集，每个模型都针对特定的分割任务量身定制。SAM的出现标志着分割任务的显着范式移动。这些努力的重
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/05/08/0-EfficientViT-SAM-AcceleratedSegmentAnythingModel-WithoutAccuracyLoss/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-EfficientViT-SAM:AcceleratedSegmentAnythingModel WithoutAccuracyLoss">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/05/08/0-EfficientViT-SAM-AcceleratedSegmentAnythingModel-WithoutAccuracyLoss/" target="_blank">
          0-EfficientViT-SAM:AcceleratedSegmentAnythingModel WithoutAccuracyLoss
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/05/08/0-EfficientViT-SAM-AcceleratedSegmentAnythingModel-WithoutAccuracyLoss/" target="_blank">
        <div>
          EfficientViT-SAM:无损加速SAM   arXiv:2402.05008v2  [cs.CV]  16 May 2024 https://github.com/mit-han-lab/efficientvit  背景尽管SAM有良好的效果，但是SAM计算却极其密集，这限制了它在时间敏感场景中的适用性。特别是，SAM的主要计算瓶颈是其图像编码器，它在推理时每张图像需要2973GMAC的
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/05/08/0-EfficientViT-Lightweight-Multi-Scale-Attention-for-High-Resolution-Dense-Prediction/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-EfficientViT: Lightweight Multi-Scale Attention for High-Resolution Dense Prediction">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/05/08/0-EfficientViT-Lightweight-Multi-Scale-Attention-for-High-Resolution-Dense-Prediction/" target="_blank">
          0-EfficientViT: Lightweight Multi-Scale Attention for High-Resolution Dense Prediction
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/05/08/0-EfficientViT-Lightweight-Multi-Scale-Attention-for-High-Resolution-Dense-Prediction/" target="_blank">
        <div>
          EfficientViT:轻量级多尺度注意力用于高分辨率密集预测 背景巨大的计算成本使得在硬件设备上部署最先进的高分辨率密集预测模型变得困难。本文提出了EfficientViT，通过创新的轻量级多尺度注意力机制，显著提升了高分辨率密集预测任务的效率与实用性：其核心贡献在于将传统Transformer的二次复杂度自注意力替换为ReLU线性注意力，结合硬件友好的小核卷积实现线性计算复杂度，同时通过多尺
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/07/0-Diffusion-empowered-AutoPrompt-MedSAM/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Diffusion-empowered AutoPrompt MedSAM">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/07/0-Diffusion-empowered-AutoPrompt-MedSAM/" target="_blank">
          0-Diffusion-empowered AutoPrompt MedSAM
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/07/0-Diffusion-empowered-AutoPrompt-MedSAM/" target="_blank">
        <div>
          扩散赋能的 AutoPrompt MedSAM  arXiv：2502.06817v1 [eess.IV] 2025 年 2 月 5 日 Code is available at https://github.com/HP-ML/AutoPromptMedSAM.git.  背景MedSAM 目前还存在两大挑战限制：一是依赖劳动密集型的人工提示；二是生成的器官或病变掩码缺乏语义标记，限制非专家用户
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/06/0-TP-DRSeg-Improving-Diabetic-Retinopathy-Lesion-Segmentation-with-Explicit-Text-Prompts-Assisted-SAM/" target="_blank">
          <img src="/../images/0-TP-DRSeg-Improving-Diabetic-Retinopathy-Lesion-Segmentation-with-Explicit-Text-Prompts-Assisted-SAM/image-20250315165815618.png" srcset="/img/loading.gif" lazyload alt="0-TP-DRSeg: Improving Diabetic Retinopathy Lesion Segmentation with Explicit Text-Prompts Assisted SAM">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/06/0-TP-DRSeg-Improving-Diabetic-Retinopathy-Lesion-Segmentation-with-Explicit-Text-Prompts-Assisted-SAM/" target="_blank">
          0-TP-DRSeg: Improving Diabetic Retinopathy Lesion Segmentation with Explicit Text-Prompts Assisted SAM
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/06/0-TP-DRSeg-Improving-Diabetic-Retinopathy-Lesion-Segmentation-with-Explicit-Text-Prompts-Assisted-SAM/" target="_blank">
        <div>
          TP-DRSeg：使用显式文本提示辅助 SAM 改进糖尿病视网膜病变病变分割    MICCAI 2024, LNCS 15008, pp. 743–753, 2024.        https://doi.org/10.1007/978-3-031-72111-3_70  背景SAM在识别糖尿病视网膜病变 （DR） 病变分割有一定挑战。本文提出了一种将 SAM 用于文本提示的 DR 病变分割的
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/06/0-Self-Prompting-Large-Vision-Models-for-Few-Shot-Medical-Image-Segmentation/" target="_blank">
          <img src="/../images/0-Self-Prompting-Large-Vision-Models-for-Few-Shot-Medical-Image-Segmentation/image-20250314211445612.png" srcset="/img/loading.gif" lazyload alt="0-Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/06/0-Self-Prompting-Large-Vision-Models-for-Few-Shot-Medical-Image-Segmentation/" target="_blank">
          0-Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/06/0-Self-Prompting-Large-Vision-Models-for-Few-Shot-Medical-Image-Segmentation/" target="_blank">
        <div>
          用于少量医学图像分割的自提示大型视觉模型   arXiv:2308.07624v1  [cs.CV]  15 Aug 2023  背景现有方法依赖于调整策略，这需要大量数据或针对特定任务量身定制的事先提示，这使得当只有有限数量的数据样本可用时具有挑战性。本文提出了一种关于医疗视觉应用中自我提示的新方法。利用 SAM 的嵌入空间通过一个简单而有效的线性像素分类器进行自我提示。通过保留大型模型的编码能
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/06/0-SAM-U-Multi-box-prompts-triggered-uncertainty-estimation-for-reliable-SAM-in-medical-image/" target="_blank">
          <img src="/../images/0-SAM-U-Multi-box-prompts-triggered-uncertainty-estimation-for-reliable-SAM-in-medical-image/image-20250314205905325.png" srcset="/img/loading.gif" lazyload alt="0-SAM-U: Multi-box prompts triggered uncertainty estimation for reliable SAM in medical image">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/06/0-SAM-U-Multi-box-prompts-triggered-uncertainty-estimation-for-reliable-SAM-in-medical-image/" target="_blank">
          0-SAM-U: Multi-box prompts triggered uncertainty estimation for reliable SAM in medical image
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/06/0-SAM-U-Multi-box-prompts-triggered-uncertainty-estimation-for-reliable-SAM-in-medical-image/" target="_blank">
        <div>
          SAM-U：多框提示触发医学图像中可靠 SAM 的不确定性估计   arXiv:2307.04973v1  [cs.CV]  11 Jul 2023  背景本文提出了一种 SAM 线索的多框提示触发不确定性估计，以证明分割病灶或组织的可靠性，使用具有先验分布参数的蒙特卡洛估计 SAM 预测的分布，使用不同的提示作为测试时间增强的公式。多框提示增强增强了 SAM 性能并为每个像素提供了不确定性。为
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/06/0-SAM-SP-Self-Prompting-Makes-SAM-Great-Again/" target="_blank">
          <img src="/../images/0-SAM-SP-Self-Prompting-Makes-SAM-Great-Again/image-20250312221914241.png" srcset="/img/loading.gif" lazyload alt="0-SAM-SP: Self-Prompting Makes SAM Great Again">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/06/0-SAM-SP-Self-Prompting-Makes-SAM-Great-Again/" target="_blank">
          0-SAM-SP: Self-Prompting Makes SAM Great Again
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/06/0-SAM-SP-Self-Prompting-Makes-SAM-Great-Again/" target="_blank">
        <div>
          Makes SAM Great Again  arXiv:2408.12364v1  [cs.CV]  22 Aug 2024 浙江大学  背景视觉基础模型 （VFM）SAM在跨不同自然图像数据集的零镜头分割取得了成功，但 SAM 在医学图像上的性能会明显下降。目前解决这个问题的努力涉及微调策略，增强原版 SAM 通用型。然而专家级提示限制了模型的实用性。本文引入了一种新的基于自我提示的微调方法，
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/06/0-Sam2Rad-A-Segmentation-Model-for-Medical-Images-with-Learnable-Prompts/" target="_blank">
          <img src="/../images/0-Sam2Rad-A-Segmentation-Model-for-Medical-Images-with-Learnable-Prompts/image-20250306171640559.png" srcset="/img/loading.gif" lazyload alt="0-Sam2Rad: A Segmentation Model for Medical Images with Learnable Prompts">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/06/0-Sam2Rad-A-Segmentation-Model-for-Medical-Images-with-Learnable-Prompts/" target="_blank">
          0-Sam2Rad: A Segmentation Model for Medical Images with Learnable Prompts
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/06/0-Sam2Rad-A-Segmentation-Model-for-Medical-Images-with-Learnable-Prompts/" target="_blank">
        <div>
          Sam2Rad：具有可学习提示的医学图像分割模型  arXiv:2409.06821v1  [cs.CV]  10 Sep 2024 加拿大麦吉尔大学计算机科学学院  背景SAM 和其系列医学图像分割模型无法分割超声图像(US)中的分割目标，这可能是由于在US看到的成像伪影的独特性质，例如当相邻散射之间的距离小于细胞分辨率时发生的散斑干涉图案。因此作者引入了一种带有轻量级交叉注意力模块的提示预测器
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/04/0-TriSAM-Tri-Plane-SAM-for-zero-shot-cortical-blood-vessel-segmentation-in-VEM-images/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/04/0-TriSAM-Tri-Plane-SAM-for-zero-shot-cortical-blood-vessel-segmentation-in-VEM-images/" target="_blank">
          0-TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/04/0-TriSAM-Tri-Plane-SAM-for-zero-shot-cortical-blood-vessel-segmentation-in-VEM-images/" target="_blank">
        <div>
          TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images  用于 VEM 图像中零样本皮质血管分割的 TriSAM arXiv:2401.13961v4  [cs.CV]  15 Aug 2024 IEEE TRANSACTIONS ON MEDICAL IMAGING  背景能够揭示复
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/04/0-SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/04/0-SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT/" target="_blank">
          0-SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/04/0-SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT/" target="_blank">
        <div>
          SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT  arXiv:2308.09331v2  [eess.IV]  31 Aug 2023  背景SAM 已经在各个领域进行了广泛的评估，但它对视网膜 OCT （光学相干断层扫描）的适应性仍有待探索，因此本文作者改进了SAM，让其改编后的 SAM 成为在视网膜 OCT 扫描中
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2025/03/03/Latex%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="Latex常用语法">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2025/03/03/Latex%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/" target="_blank">
          Latex常用语法
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2025/03/03/Latex%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/" target="_blank">
        <div>
          INSTALL使用Vscode（编辑）+TeX Liv（编译）实现。 Vscode需要Latex workshop扩展。 Main目录结构 123456789101112parper-&gt;	assets	bst	build	Chapter		Chapter1			Chapter1.tex		Chapter2			Chapter2.tex		Chapter3			Chapter3.tex	mai
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/Latex/">#Latex</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/12/04/0-One-Prompt-to-Segment-All-Medical-Images/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-One-Prompt to Segment All Medical Images">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/12/04/0-One-Prompt-to-Segment-All-Medical-Images/" target="_blank">
          0-One-Prompt to Segment All Medical Images
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/12/04/0-One-Prompt-to-Segment-All-Medical-Images/" target="_blank">
        <div>
          One-Prompt to Segment All Medical Images 背景分割大模型SAM在医学图像分割领域取得了很好的进展，但是仍然依赖人工手动提示，故本文中，作者介绍了一种通用医学图像分割的新范式，称为 One-Prompt。这种方法结合了一次性和交互式模型的优势，以满足实际的临床要求。具体来说，给定一个看不见的任务，用户只需要向训练好的模型提供一个提示样本，然后它就可以在这个新任
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/12/04/0-Generalized-SAM-Efficient-Fine-Tuning-of-SAM-for-Variable-Input-Image-Sizes/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Generalized SAM: Efficient Fine-Tuning of SAM for Variable Input Image Sizes">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/12/04/0-Generalized-SAM-Efficient-Fine-Tuning-of-SAM-for-Variable-Input-Image-Sizes/" target="_blank">
          0-Generalized SAM: Efficient Fine-Tuning of SAM for Variable Input Image Sizes
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/12/04/0-Generalized-SAM-Efficient-Fine-Tuning-of-SAM-for-Variable-Input-Image-Sizes/" target="_blank">
        <div>
          Generalized SAM：用于可变输入图像尺寸的 SAM 高效微调   arXiv:2408.12406v1  [cs.CV]  22 Aug 2024  https://github.com/usagisukisuki/G-SAM  背景深度学习在图像识别领域成果斐然，基础模型虽具强大泛化能力，但在特定任务中需微调。SAM 作为图像分割基础模型，零样本性能佳，可对自然图像高精度分割，但识别
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/12/04/0-DS-TransUNet-Dual-Swin-Transformer-U-Net-for-Medical-Image-Segmentation/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-DS-TransUNet: Dual Swin Transformer U-Net for Medical Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/12/04/0-DS-TransUNet-Dual-Swin-Transformer-U-Net-for-Medical-Image-Segmentation/" target="_blank">
          0-DS-TransUNet: Dual Swin Transformer U-Net for Medical Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/12/04/0-DS-TransUNet-Dual-Swin-Transformer-U-Net-for-Medical-Image-Segmentation/" target="_blank">
        <div>
          DS - TransUNet：用于医学图像分割的双 Swin Transformer U - Net  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, JUNE 2021 arXiv:2106.06716v1  [cs.CV]  12 Jun 2021  背景医学图像分割是临床应用关键环节，如息肉、病变、细胞分割等，对辅助诊断和病理研究意义重大。深度学习
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/12/03/0-Dr-SAM-U-Shape-Structure-Segment-Anything-Model-for-Generalizable-Medical-Image-Segmentation/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Dr-SAM: U-Shape Structure Segment Anything Model for Generalizable Medical Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/12/03/0-Dr-SAM-U-Shape-Structure-Segment-Anything-Model-for-Generalizable-Medical-Image-Segmentation/" target="_blank">
          0-Dr-SAM: U-Shape Structure Segment Anything Model for Generalizable Medical Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/12/03/0-Dr-SAM-U-Shape-Structure-Segment-Anything-Model-for-Generalizable-Medical-Image-Segmentation/" target="_blank">
        <div>
          https://doi.org/10.1007/978-981-97-5600-1_17  注：此文与Link所指向的Dr-SAM不同  背景医学图像分割在现代医疗诊断中占据关键地位，精准的分割能够助力医师精确判别病情、规划治疗策略以及监测病症演进。然而，医学领域获取大规模标注图像数据困难重重，致使既有方法多依赖特定任务定制模型，普适性欠佳。 自然语言与视觉领域的基础模型成效斐然，但迁移至医
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/12/02/0-Hiera-A-Hierarchical-Vision-Transformer-without-the-Bells-and-Whistles/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/12/02/0-Hiera-A-Hierarchical-Vision-Transformer-without-the-Bells-and-Whistles/" target="_blank">
          0-Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/12/02/0-Hiera-A-Hierarchical-Vision-Transformer-without-the-Bells-and-Whistles/" target="_blank">
        <div>
          Hiera：一种去除繁杂结构的分层视觉 Transformer  Facebook Meat 2023  背景Vision Transformers（ViTs）在计算机视觉领域广泛应用，但存在参数利用效率低的问题。分层设计的 Vision Transformers 虽提高了参数效率，但为追求 ImageNet - 1K 上的监督分类性能，添加了许多复杂组件，导致模型变慢。掩码自编码器（MAE）等自
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/12/02/0-SAM2-UNet-Segment-Anything-2-Makes-Strong-Encoder-for-Natural-and-Medical-Image-Segmentation/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/12/02/0-SAM2-UNet-Segment-Anything-2-Makes-Strong-Encoder-for-Natural-and-Medical-Image-Segmentation/" target="_blank">
          0-SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/12/02/0-SAM2-UNet-Segment-Anything-2-Makes-Strong-Encoder-for-Natural-and-Medical-Image-Segmentation/" target="_blank">
        <div>
          SAM2 - UNet：利用 Segment Anything 2 为自然和医学图像分割打造强大编码器总结  arXiv:2408.08870v1  [cs.CV]  16 Aug 2024  https://github.com/WZH0120/SAM2-UNet.  背景图像分割是计算机视觉重要任务，多种下游任务依赖于它，但设计统一架构处理不同分割任务仍是挑战。视觉基础模型（VFMs）如 SA
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/30/0-Efficient-and-Robust-Medical-Image-Segmentation-Using-Lightweight-ViT-Tiny-based-SAM-and-Model-Quantization/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Efficient and Robust Medical Image Segmentation Using Lightweight ViT-Tiny based SAM and Model Quantization&gt;">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/30/0-Efficient-and-Robust-Medical-Image-Segmentation-Using-Lightweight-ViT-Tiny-based-SAM-and-Model-Quantization/" target="_blank">
          0-Efficient and Robust Medical Image Segmentation Using Lightweight ViT-Tiny based SAM and Model Quantization&gt;
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/30/0-Efficient-and-Robust-Medical-Image-Segmentation-Using-Lightweight-ViT-Tiny-based-SAM-and-Model-Quantization/" target="_blank">
        <div>
          使用基于 Lightweight ViT - Tiny 的 SAM 和模型量化进行高效、稳健的医学图像分割  01 Jun 2024 (modified: 11 Oct 2024)Submitted to CVPR24 MedSAMonLapto 等待major revision
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/30/0-MAFE-Net-retinal-vessel-segmentation-based-on-a-multiple-attention-guided-fusion-mechanism-and-ensemble-learning-network/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-MAFE-Net: retinal vessel segmentation based on a multiple attention-guided fusion mechanism and ensemble learning network">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/30/0-MAFE-Net-retinal-vessel-segmentation-based-on-a-multiple-attention-guided-fusion-mechanism-and-ensemble-learning-network/" target="_blank">
          0-MAFE-Net: retinal vessel segmentation based on a multiple attention-guided fusion mechanism and ensemble learning network
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/30/0-MAFE-Net-retinal-vessel-segmentation-based-on-a-multiple-attention-guided-fusion-mechanism-and-ensemble-learning-network/" target="_blank">
        <div>
          MAFE - Net：用于眼底血管图像分割的多注意力引导融合网络  Biomedical Optics Vol. 15, No. 2&#x2F;1 Feb 2024&#x2F;Biomedical Optics Express   背景视网膜血管的精确自动识别对眼病预防、诊断和评估至关重要，但因血管形状复杂、病理变形和对比度不均等因素，分割极具挑战。现有视网膜血管分割方法分为手动设计特征提取层、深
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/30/0-LeSAM-Adapt-Segment-Anything-Model-for-Medical-Lesion-Segmentation/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-LeSAM: Adapt Segment Anything Model for Medical Lesion Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/30/0-LeSAM-Adapt-Segment-Anything-Model-for-Medical-Lesion-Segmentation/" target="_blank">
          0-LeSAM: Adapt Segment Anything Model for Medical Lesion Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/30/0-LeSAM-Adapt-Segment-Anything-Model-for-Medical-Lesion-Segmentation/" target="_blank">
        <div>
          LeSAM：将 Segment Anything 模型应用于医学损伤分割  IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 28, NO. 10, OCTOBER 2024  背景病变分割在医学图像分析中至关重要，但由于医学图像的复杂性和多样性，准确分割具有挑战性。现有深度学习算法受限于训练数据和模型特异性，难以通用。SAM 在自然图
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/30/0-GlanceSeg-Real-time-microangioma-lesion-segmentation-with-gaze-map-guided-foundation-model-for-early-detection-of-diabetic-retinopathy/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-GlanceSeg: Real-time microangioma lesion segmentation with gaze map-guided foundation model for early detection of diabetic retinopathy">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/30/0-GlanceSeg-Real-time-microangioma-lesion-segmentation-with-gaze-map-guided-foundation-model-for-early-detection-of-diabetic-retinopathy/" target="_blank">
          0-GlanceSeg: Real-time microangioma lesion segmentation with gaze map-guided foundation model for early detection of diabetic retinopathy
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/30/0-GlanceSeg-Real-time-microangioma-lesion-segmentation-with-gaze-map-guided-foundation-model-for-early-detection-of-diabetic-retinopathy/" target="_blank">
        <div>
          GlanceSeg：利用凝视图引导基础模型进行实时微动脉瘤病变分割，用于早期检测糖尿病视网膜病变    arXiv:2311.08075v1  [eess.IV]  14 Nov 2023  背景早期糖尿病视网膜病变（DR）因微动脉瘤病变不明显且微小，临床诊断困难，相关研究有限。现有计算机辅助诊断（CAD）系统虽诊断性能好，但推理过程缺乏透明度，且早期检测能力不足，对标注数据依赖大。眼科医生诊断过
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/27/0-RevSAM2-Prompt-SAM2-for-Medical-Image-Segmentation-via-Reverse-Propagation-without-Fine-tuning/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-RevSAM2: Prompt SAM2 for Medical Image Segmentation via Reverse-Propagation without Fine-tuning">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/27/0-RevSAM2-Prompt-SAM2-for-Medical-Image-Segmentation-via-Reverse-Propagation-without-Fine-tuning/" target="_blank">
          0-RevSAM2: Prompt SAM2 for Medical Image Segmentation via Reverse-Propagation without Fine-tuning
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/27/0-RevSAM2-Prompt-SAM2-for-Medical-Image-Segmentation-via-Reverse-Propagation-without-Fine-tuning/" target="_blank">
        <div>
          RevSAM2：通过反向传播无微调提示 SAM2 进行医学图像分割  arXiv:2409.04298v1  [cs.CV]  6 Sep 2024 V1 link_here arXiv:2409.04298v2  [cs.CV]  25 Nov 2024 V2   背景SAM2 在自然图像和视频零样本提示分割中表现优异，但应用于医学图像时，因训练数据缺乏医学图像，难以通过语义特征精确分割器官等结
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/27/0-FS-MedSAM2-Exploring-the-Potential-of-SAM2-for-Few-Shot-Medical-Image-Segmentation-without-Fine-tuning/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-FS-MedSAM2: Exploring the Potential of SAM2 for Few-Shot Medical Image Segmentation without Fine-tuning">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/27/0-FS-MedSAM2-Exploring-the-Potential-of-SAM2-for-Few-Shot-Medical-Image-Segmentation-without-Fine-tuning/" target="_blank">
          0-FS-MedSAM2: Exploring the Potential of SAM2 for Few-Shot Medical Image Segmentation without Fine-tuning
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/27/0-FS-MedSAM2-Exploring-the-Potential-of-SAM2-for-Few-Shot-Medical-Image-Segmentation-without-Fine-tuning/" target="_blank">
        <div>
          FS-MedSAM2：探索 SAM2 在无需微调的情况下进行小样本医学图像分割的潜力  arXiv:2409.04298v1  [cs.CV]  6 Sep 2024 V1 arXiv:2409.04298v2  [cs.CV]  25 Nov 2024 V2 link_here  背景SAM2 在自然图像和视频的零样本提示分割中表现出色，但应用于医学图像时面临挑战，因其训练数据缺乏医学图像，导致
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/27/0-Dr-SAM-An-End-to-End-Framework-for-Vascular-Segmentation-Diameter-Estimation-and-Anomaly-Detection-on-Angiography-Images/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Dr-SAM: An End-to-End Framework for Vascular Segmentation, Diameter Estimation, and Anomaly Detection on Angiography Images.">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/27/0-Dr-SAM-An-End-to-End-Framework-for-Vascular-Segmentation-Diameter-Estimation-and-Anomaly-Detection-on-Angiography-Images/" target="_blank">
          0-Dr-SAM: An End-to-End Framework for Vascular Segmentation, Diameter Estimation, and Anomaly Detection on Angiography Images.
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/27/0-Dr-SAM-An-End-to-End-Framework-for-Vascular-Segmentation-Diameter-Estimation-and-Anomaly-Detection-on-Angiography-Images/" target="_blank">
        <div>
          Dr-SAM：用于血管分割、直径估计和血管造影图像异常检测的端到端框架 背景下肢及盆腔器官供血依赖肾下主动脉和盆腔动脉，血管狭窄或扩张会引发健康问题。血管造影技术利用 X 射线和造影剂辅助诊断，AI 的发展使其可进行语义分析，有助于医生诊断。 现有血管造影图像分析方法在分析主动脉和髂动脉时存在局限，尤其在血管异常检测和表征方面。因此，本文提出 Dr - SAM 框架，用于外周血管造影图像分析。
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/02/0-Fundus2Angio-A-Conditional-GAN-Architecture-for-Generating-Fluorescein-Angiography-Images-from-Retinal-Fundus-Photography/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="0-Fundus2Angio: A Conditional GAN Architecture for Generating Fluorescein Angiography Images from Retinal Fundus Photography">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/02/0-Fundus2Angio-A-Conditional-GAN-Architecture-for-Generating-Fluorescein-Angiography-Images-from-Retinal-Fundus-Photography/" target="_blank">
          0-Fundus2Angio: A Conditional GAN Architecture for Generating Fluorescein Angiography Images from Retinal Fundus Photography
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/02/0-Fundus2Angio-A-Conditional-GAN-Architecture-for-Generating-Fluorescein-Angiography-Images-from-Retinal-Fundus-Photography/" target="_blank">
        <div>
          Fundus2Angio: A Conditional GAN Architecture for Generating Fluorescein Angiography Images from Retinal Fundus Photography  Fundus2Angio：一种从视网膜眼底摄影生成荧光素血管造影图像的条件 GAN 结构  arXiv:2005.05267v2  [eess.IV]
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/FA/">#FA</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/11/01/%E8%BF%91%E6%9C%9F%E6%9B%B4%E6%96%B0%E8%AE%A1%E5%88%92/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="近期更新计划">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/11/01/%E8%BF%91%E6%9C%9F%E6%9B%B4%E6%96%B0%E8%AE%A1%E5%88%92/" target="_blank">
          近期更新计划
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/11/01/%E8%BF%91%E6%9C%9F%E6%9B%B4%E6%96%B0%E8%AE%A1%E5%88%92/" target="_blank">
        <div>
          主题是关于视网膜眼底图像的增强与分割有关FA（荧光素血管造影），因其在分割中不宜于应用（数据集不够好）故不会再进行更新，Review（R）也不会进行论文总结。11月Dr-SAM: An End-to-End Framework for Vascular Segmentation, Diameter Estimation, and Anomaly Detection on Angiography I
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/10/08/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/" target="_blank">
          <img src="/../images/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/image-20241008112130387.png" srcset="/img/loading.gif" lazyload alt="0-SAM2POINT: SEGMENT ANY 3D AS VIDEOS IN ZERO-SHOT AND PROMPTABLE MANNERS">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/10/08/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/" target="_blank">
          0-SAM2POINT: SEGMENT ANY 3D AS VIDEOS IN ZERO-SHOT AND PROMPTABLE MANNERS
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/10/08/0-SAM2POINT-SEGMENT-ANY-3D-AS-VIDEOS-IN-ZERO-SHOT-AND-PROMPTABLE-MANNERS/" target="_blank">
        <div>
          SAM2POINT: SEGMENT ANY 3D AS VIDEOS IN ZERO-SHOT AND PROMPTABLE MANNERS  arXiv:2408.16768v1 [cs.CV] 29 Aug 2024  SAM2POINT：以零镜头和提示的方式将任何 3D 分割为视频  背景SAM2有Zero-shot和可提示的3D分割，本文作者提出SAM2POINT将任何3D数据解释为多向
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/" target="_blank">
          <img src="/../images/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/image-20240829205246880.png" srcset="/img/loading.gif" lazyload alt="0-A novel attention-guided convolutional network for the detection of">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/" target="_blank">
          0-A novel attention-guided convolutional network for the detection of
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-A-novel-attention-guided-convolutional-network-for-the-detection-of/" target="_blank">
        <div>
          A novel attention-guided convolutional network for the detection of 用于宫颈癌筛查中异常宫颈细胞检测的新型注意力引导的卷积网络背景一些研究已经在探索了自动检测宫颈癌的可能性，论文中举出了如以下提出的三种方法，而这些方法也存在问题，就是那些机器学习方法利用了为特定任务设计的传统手工特征，而这些特征通常不够健壮。 卷积神经网络（CNN
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="医学影像数据集">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" target="_blank">
          医学影像数据集
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" target="_blank">
        <div>
          医学影像数据集肺肺MSD肺癌分割 MSD肺脏分割数据集 LoLa11肺叶分割 LoLa11肺叶分割数据集 肺部多病智能诊断 天池数据 vessel12 肺部血管分割 VESSEL12 肺部血管分割 NIHChest Xray   14种肺部疾病 论文 数据集下载 NIH chest Xray  QIN Lung CT QIN 肺部CT数据 4D-Lung 4D-Lung NSCLC-Radiomi
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/" target="_blank">
          <img src="/../images/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/image-20240925233026212.png" srcset="/img/loading.gif" lazyload alt="0-ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/" target="_blank">
          0-ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-ESP-MedSAM-Efficient-Self-Prompting-SAM-for-Universal-Domain-Generalized-Medical-Image-Segmentation/" target="_blank">
        <div>
          ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation  arXiv:2407.14153v4 [eess.IV] 18 Aug 2024 IEEE TRANSACTIONS ON MEDICAL IMAGING ESP-MedSAM： 用于通用域广义医
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-Learnable-Ophthalmology-SAM/" target="_blank">
          <img src="/../images/0-Learnable-Ophthalmology-SAM/image-20240924194146172.png" srcset="/img/loading.gif" lazyload alt="0-Learnable Ophthalmology SAM">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-Learnable-Ophthalmology-SAM/" target="_blank">
          0-Learnable Ophthalmology SAM
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-Learnable-Ophthalmology-SAM/" target="_blank">
        <div>
          Learnable Ophthalmology SAM  arXiv:2304.13425v1 [cs.CV] 26 Apr 2023 可学习的眼科 SAM code：https://github.com/xianlin7/SAMUS  背景针对眼科图像分析中的分割问题，由于眼科图像的多模态特性，现有的分割算法大多依赖于大量标签的训练或者泛化能力较弱，导致其应用受限。 为了解决这一问题，本研究提出
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/" target="_blank">
          <img src="/../images/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/image-20240913215501362.png" srcset="/img/loading.gif" lazyload alt="0-MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/" target="_blank">
          0-MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-MA-SAM-Modality-agnostic-SAM-adaptation-for-3D-medical-image-segmentation/" target="_blank">
        <div>
          MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation  MA-SAM：用于 3D 医学图像分割的模态不可知的 SAM 自适应 2024年8月  背景SAM模型已经在很多分割任务中取得很好的zero-shot性能，但在医学图像上仍有欠缺，本文提出了一种与模态无关的 SAM 适应框架（MA-SAM)，通过将
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/" target="_blank">
          <img src="/../images/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/image-20240911094929813.png" srcset="/img/loading.gif" lazyload alt="0-MEDICAL SAM 2: SEGMENT MEDICAL IMAGES AS VIDEO VIA SEGMENT ANYTHING MODEL 2">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/" target="_blank">
          0-MEDICAL SAM 2: SEGMENT MEDICAL IMAGES AS VIDEO VIA SEGMENT ANYTHING MODEL 2
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-MEDICAL-SAM-2-SEGMENT-MEDICAL-IMAGES-AS-VIDEO-VIA-SEGMENT-ANYTHING-MODEL-2/" target="_blank">
        <div>
          MEDICAL SAM 2: SEGMENT MEDICAL IMAGES AS VIDEO VIA SEGMENT ANYTHING MODEL 2  MEDSAM2  arXiv:2408.00874v1 2024年8月  背景Meat公司在23年发表了SAM（segment anyting），有一定颠覆传统CV任务的趋势，在24年4月Meat公司继续发表了SAM2模型，基于SAM模型良好的z
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%8ESAM/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="医学影像与SAM">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%8ESAM/" target="_blank">
          医学影像与SAM
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%8ESAM/" target="_blank">
        <div>
          SAM与医学影像SAM SAM 是一种可提示的分割架构，由三个主要组件组成，即图像编码器、提示编码器和掩码解码器。图像编码器采用视觉转换器 （ViT） （Dosovitskiy et al.， 2020） 作为支柱，用一组变压器块提取图像的基本特征。提示编码器接受各种类型的提示，包括点、框或文本，并将这些输入编码到提示嵌入中，以促进分割任务。掩码解码器设计为轻量级，它计算图像嵌入和提示之间的交叉注
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/" target="_blank">
          <img src="/../images/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/image-20240926191429854.png" srcset="/img/loading.gif" lazyload alt="0-SAM-UNet: Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/" target="_blank">
          0-SAM-UNet: Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-SAM-UNet-Enhancing-Zero-Shot-Segmentation-of-SAM-for-Universal-Medical-Images/" target="_blank">
        <div>
          SAM-UNet: Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images  arXiv:2408.09886v1 [cs.CV] 19 Aug 2024  SAM-UNet：增强通用医学图像的 SAM 零样本分割  背景初始SAM在医学图像上并不适配，本文作者受到 U-Net 的模型在医学图像分割中的卓越性能的启发
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/" target="_blank">
          <img src="/../images/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/image-20240924192212703.png" srcset="/img/loading.gif" lazyload alt="0-SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/" target="_blank">
          0-SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation/" target="_blank">
        <div>
          SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation  arXiv:2309.06824v1 [cs.CV] 13 Sep 2023  背景SAM是一种杰出的通用图像分割模型，在医学图像分割领域近来引起了相当大的关注。尽管SAM在自
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-Segment-Anything-in-Medical-Images/" target="_blank">
          <img src="/../images/0-Segment-Anything-in-Medical-Images/image-20240921104718830.png" srcset="/img/loading.gif" lazyload alt="0-Segment Anything in Medical Images">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-Segment-Anything-in-Medical-Images/" target="_blank">
          0-Segment Anything in Medical Images
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-Segment-Anything-in-Medical-Images/" target="_blank">
        <div>
          Segment Anything in Medical Images  arXiv:2304.12306v3 [eess.IV] 1 Apr 2024  背景本文介绍MedSAM这个基础模型，旨在让SAM弥补在医学图像分割领的不足，在大量的图像掩码上开发，涵盖多种病灶类型，证明了比模态专业模型更好的准确性和稳健性。在广泛的任务中提供准确高效的细分。 分割是医学成像分析中的一项基本任务，它涉及识别和
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-Segment-Anything-Model-for-Medical-Images/" target="_blank">
          <img src="/../images/0-Segment-Anything-Model-for-Medical-Images/image-20240921133338408.png" srcset="/img/loading.gif" lazyload alt="0-Segment Anything Model for Medical Images">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-Segment-Anything-Model-for-Medical-Images/" target="_blank">
          0-Segment Anything Model for Medical Images
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-Segment-Anything-Model-for-Medical-Images/" target="_blank">
        <div>
          Segment Anything Model for Medical Images？  分割所有医学图像模型？ arXiv:2304.14660v5 [eess.IV] 12 Dec 2023  MED SAM  背景Segment Anything Model （SAM） 是第一个用于常规图像分割的基础模型。它在各种自然图像分割任务上取得了令人印象深刻的成果。然而，由于模态复杂、解剖结构精细、对
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/" target="_blank">
          <img src="/../images/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/image-20240911160429772.png" srcset="/img/loading.gif" lazyload alt="0-3DSAM-adapter: Holistic adaptation of SAM from 2D to 3D for promptable tumor segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/" target="_blank">
          0-3DSAM-adapter: Holistic adaptation of SAM from 2D to 3D for promptable tumor segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/0-3DSAM-adapter-Holistic-adaptation-of-SAM-from-2D-to-3D-for-promptable-tumor-segmentation/" target="_blank">
        <div>
          3DSAM-adapter: Holistic adaptation of SAM from 2D to 3D for promptable tumor segmentation  3DSAM 适配器：SAM 从 2D 到 3D 的整体适应，用于及时的肿瘤分割 2024年8月  背景SAM框架对于日常的图像已经有良好的分割性能，但是在医学图像分割上表现出的性能不太精确且不稳定，尤其是在处理涉及小尺
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="医学图像处理">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" target="_blank">
          医学图像处理
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" target="_blank">
        <div>
          医学图像处理1.常见的医学图像 MRI  核磁共振图像（MRI），该图像是人体组织器官和病灶中的氢原子核在外部强磁场作用下产生的磁共振信号大小的度量，并通过计算机对体外核磁共振信号探测器接收到的信息数据进行3D图像重建。它能够提供非常清晰的人体软组织解剖结构和病灶影像。  CT  计算机断层扫描(CT)利用精确准直的X射线束对人体某部位一定厚度的断面进行照射扫描，并由与射线线束一起旋转的探测器接收
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/28/C-Vision-Transformer-ViT/" target="_blank">
          <img src="/../images/C-Vision-Transformer-ViT/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240928154923206.png" srcset="/img/loading.gif" lazyload alt="C-Vision Transformer (ViT)">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/28/C-Vision-Transformer-ViT/" target="_blank">
          C-Vision Transformer (ViT)
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/28/C-Vision-Transformer-ViT/" target="_blank">
        <div>
          AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE  [v2] Thu, 3 Jun 2021 13:08:56 UTC Vision Transformer (ViT)  背景虽然Transformer架构已经成为自然语言处理任务的事实上的标准，但它在计算机视觉上的应用仍然有限。在视觉方面，注意力要
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/09/01/0-Segment-Anything/" target="_blank">
          <img src="/../images/0-Segment-Anything/image-20241010160328005.png" srcset="/img/loading.gif" lazyload alt="0-Segment Anything">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/09/01/0-Segment-Anything/" target="_blank">
          0-Segment Anything
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/09/01/0-Segment-Anything/" target="_blank">
        <div>
          Segment Anything  Code:https://github.com/facebookresearch/segment-anything HP:https://segment-anything.com  原理解析ref：【视觉分割大模型SAM（原理解析+代码实践）】link  背景计算机视觉大模型。构建了迄今为止（迄今为止）最大的分割数据集，在 11M 许可和尊重隐私的图像上拥有超过
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/SAM/">#SAM</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/07/05/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/" target="_blank">
          <img src="/../images/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240705130419512.png" srcset="/img/loading.gif" lazyload alt="0-Diffusion Models Beat GANs on Image Synthesis">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/07/05/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/" target="_blank">
          0-Diffusion Models Beat GANs on Image Synthesis
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/07/05/0-Diffusion-Models-Beat-GANs-on-Image-Synthesis/" target="_blank">
        <div>
          Diffusion Models Beat GANs on Image Synthesis  发表在2021年的NeurIPS会议上  背景GANs(生成对抗网络)一直是广泛使用的方法之一，在图片生成领域效果很好，但也有着训练过程不稳定，模式崩溃等问题。Diffusion Models(扩散模型)是一类基于概率生成过程的模型，一开始用于密度建模和生成任务，此研究旨在评估扩散模型在图像生成任务中的表
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/07/03/0-Why-Should-I-Trust-You-Explaining-the-Predictions-of-Any-Classifier/" target="_blank">
          <img src="/../images/%E5%A6%82%E4%BD%95%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9F/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240703151226459.png" srcset="/img/loading.gif" lazyload alt="0-Why Should I Trust You Explaining the Predictions of Any Classifier">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/07/03/0-Why-Should-I-Trust-You-Explaining-the-Predictions-of-Any-Classifier/" target="_blank">
          0-Why Should I Trust You Explaining the Predictions of Any Classifier
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/07/03/0-Why-Should-I-Trust-You-Explaining-the-Predictions-of-Any-Classifier/" target="_blank">
        <div>
          “Why Should I Trust You”Explaining the Predictions of Any Classifier  LIME 这篇论文发表在2016年的KDD会议上  背景机器模型虽然被广泛采用，但是其对人们来说，还是一个黑匣子。然而，了解机器学习背后的原理对于其评估非常重要，因此一种称为“LIME（Local Interpretable Model-agnostic Ex
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/06/22/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/" target="_blank">
          <img src="/../images/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624205657449.png" srcset="/img/loading.gif" lazyload alt="0-Dropout: A Simple Way to Prevent Neural Networks from Overfitting">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/06/22/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/" target="_blank">
          0-Dropout: A Simple Way to Prevent Neural Networks from Overfitting
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/06/22/0-Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/" target="_blank">
        <div>
          Dropout: A Simple Way to Prevent Neural Networks from Overfitting  Journal of Machine Learning Research 15 (2014)  背景“Improving neural networks by preventing co-adaptation of feature detectors”这篇文章与本文
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/06/22/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/" target="_blank">
          <img src="/../images/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240630190852246.png" srcset="/img/loading.gif" lazyload alt="0-Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/06/22/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/" target="_blank">
          0-Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/06/22/0-Binarized-Neural-Networks-Training-Neural-Networks-with-Weights-and-Activations-Constrained-to-1-or-%E2%88%921/" target="_blank">
        <div>
          Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1  arXiv:1602.02830v2 [cs.LG] 29 Feb 2016  背景本文提出了一种称为二值化神经网络（Binarized Neural Networks, BNNs）的方法
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/06/22/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/" target="_blank">
          <img src="/../images/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/image-20240622194336563.png" srcset="/img/loading.gif" lazyload alt="0-Decoupled Neural Interfaces using Synthetic Gradients">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/06/22/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/" target="_blank">
          0-Decoupled Neural Interfaces using Synthetic Gradients
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/06/22/0-Decoupled-Neural-Interfaces-using-Synthetic-Gradients/" target="_blank">
        <div>
          Decoupled Neural Interfaces using Synthetic  使用合成梯度的解耦神经接口arXiv:1608.05343v2 ICML2016  背景训练神经网络需要数据通过前向传播，随后反向传播误差来更新权重，在这个过程中，网络和模块各层之间的相互依赖，需要等待其他层的计算完成才能完成更新，导致效率低下。本文的作者使用建模误差梯度，通过使用建模用合成梯度代替真正的反向
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/06/22/0-Layer-Normalization/" target="_blank">
          <img src="/../images/0-Layer-Normalization/image-20240622151144967.png" srcset="/img/loading.gif" lazyload alt="0-Layer Normalization">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/06/22/0-Layer-Normalization/" target="_blank">
          0-Layer Normalization
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/06/22/0-Layer-Normalization/" target="_blank">
        <div>
          Layer Normalization  层标准化 arXiv:1607.06450v1  2016年  背景BN（2015）、LN做为常用的标准化方法，不同之处就是在于对于激活函数的改变方式。标准化的目的是为了把输入转化成均值为0,方差为1的数据。 BN通过在深度神经网络中加入额外的归一化阶段来减少训练时间，除了训练时间的改善外，批量统计的随机性还可在训练过程中充当正则化器。但是BN在处理RNN
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/06/22/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/" target="_blank">
          <img src="/../images/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/image-20240612143024238.png" srcset="/img/loading.gif" lazyload alt="0-HyKGE AHypothesis Knowledge Graph Enhanced Framework">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/06/22/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/" target="_blank">
          0-HyKGE AHypothesis Knowledge Graph Enhanced Framework
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/06/22/0-HyKGE-AHypothesis-Knowledge-Graph-Enhanced-Framework/" target="_blank">
        <div>
          HyKGE：利用知识图谱增强大语言模型在医学领域提升准确度  arXiv:2312.15883v2 2024年4月19日(v2)  背景LLM增强的知识图谱问答：是指结合大型语言模型（LLM）和知识图谱（KG）来改进和增强问答系统的能力。通过利用LLM的自然语言处理和生成能力，结合知识图谱的结构化数据。通过结合LLM和KG，问答系统可以处理更复杂和多样化的问题，同时提供更高质量和更可信的回答。这种
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/26/0-Network-Morphism/" target="_blank">
          <img src="/../images/0-Network-Morphism/image-20240526152658190.png" srcset="/img/loading.gif" lazyload alt="0-Network Morphism">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/26/0-Network-Morphism/" target="_blank">
          0-Network Morphism
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/26/0-Network-Morphism/" target="_blank">
        <div>
          Network Morphism  网络态射 ICML 2016  背景在深度学习中，模型架构的设计和优化是一个复杂且耗时的过程。现有的方法通常需要从头开始训练新的模型，或者进行复杂的超参数优化。论文提出了网络态射的概念，旨在通过调整现有网络结构，保持或提高网络性能，同时减少训练时间和资源。 实验方法网络态射包括以下几种主要操作：  增加层数（Layer Morphism）：  在现有网络中增加新
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/26/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/" target="_blank">
          <img src="/../images/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/image-20240526135132205.png" srcset="/img/loading.gif" lazyload alt="0-Net2Net: Accelerating Learning Via Knowledge Transfer">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/26/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/" target="_blank">
          0-Net2Net: Accelerating Learning Via Knowledge Transfer
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/26/0-Net2Net-Accelerating-Learning-Via-Knowledge-Transfer/" target="_blank">
        <div>
          Net2Net: Accelerating Learning Via Knowledge Transfer  ICLR 2016  背景大型的深度神经网络的训练通常需要大量的计算资源和时间。随着模型需求增加（更深和更宽的网络），训练时间和资源也随之增加。于是作者给出了一种通过迁移学习来加速训练的方法。 传统的机器学习算法是接受一个固定的数据集作为输入，在不接受任何知识情况下初始化，并训练模型至收敛
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/25/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/" target="_blank">
          <img src="/../images/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/image-20240525163201675.png" srcset="/img/loading.gif" lazyload alt="0-Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/25/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/" target="_blank">
          0-Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/25/0-Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift/" target="_blank">
        <div>
          Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift  批量归一化：通过减少内部协变量偏移加速深度网络训练  arXiv:1502.03167 ICML 2015  背景提到BN操作，一定会想到CNN，如果说之前各种Net是模型创新，那么本篇就是优化创新。BN是对CN
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/25/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/" target="_blank">
          <img src="/../images/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/image-20240525154637137.png" srcset="/img/loading.gif" lazyload alt="0-Improving neural networks by preventing coadaptation of feature detectors">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/25/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/" target="_blank">
          0-Improving neural networks by preventing coadaptation of feature detectors
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/25/0-Improving-neural-networks-by-preventing-coadaptation-of-feature-detectors/" target="_blank">
        <div>
          Improving neural networks by preventing co-adaptation of feature detectors  arXiv:1207.0580v1 2012 06  背景简而言之 Dropout 的提出，用于解决神经网络在训练过程中的过拟合问题，提升模型在测试集上的泛化能力。 Dropout 就是在每个训练步骤中，随机忽略（即“丢弃”）一部分神经元，使得网络
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/25/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-4-%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="1-基础部分-4-常用英文">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/25/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-4-%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/" target="_blank">
          1-基础部分-4-常用英文
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/25/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-4-%E5%B8%B8%E7%94%A8%E8%8B%B1%E6%96%87/" target="_blank">
        <div>
          英文 翻译    review 总结；综述   high-resolution 高分辨率   top-1 error rate top1错误率，即分类预测的最大可能结果不是正确标签的概率   top-5 error rate top5错误率，即分类预测的前5个可能结果都不是正确标签的概率   neuron 神经元   non-saturating 非饱和的   object recognit
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/" class="category-chain-item">基础部分</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/24/0-Going-Deeper-with-Convolutions/" target="_blank">
          <img src="/../images/0-Going-Deeper-with-Convolutions/image-20240524144235051.png" srcset="/img/loading.gif" lazyload alt="0-Going Deeper with Convolutions">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/24/0-Going-Deeper-with-Convolutions/" target="_blank">
          0-Going Deeper with Convolutions
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/24/0-Going-Deeper-with-Convolutions/" target="_blank">
        <div>
          Going Deeper with Convolutions  GoogLeNet CVPR2015  背景在大规模图像识别挑战赛2014上，仅用AlexNet $\frac{1}{12}$ 的参数，就有比其更好的准确率。提出了名为“Inception”的网络架构（也称Inception v1），提高网络内部计算资源的利用率，增加网络深度和广度并保持计算预算不变。同时考虑到了移动与嵌入式设备的应用
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/24/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/" target="_blank">
          <img src="/../images/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/image-20240506182339276.png" srcset="/img/loading.gif" lazyload alt="0-SimCSE: Simple Contrastive Learning of Sentence Embeddings">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/24/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/" target="_blank">
          0-SimCSE: Simple Contrastive Learning of Sentence Embeddings
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/24/0-SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings/" target="_blank">
        <div>
          SimCSE: Simple Contrastive Learning of Sentence Embeddings SimCSE：对比学习句向量表示 发布于EMNLP 2021  背景Embedding是指将高维度的数据（例如文字、图片、音频）映射到低维度空间的过程。Embedding向量是包含语义信息的。也就是含义相近的单词，Embedding向量在空间中有相似的位置。Embedding是数据
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/24/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/" target="_blank">
          <img src="/../images/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/img-$%7BHH%7D-$%7Bmm%7D-$%7Bss%7D.$%7Bextension%7D/image-20240624151929402.png" srcset="/img/loading.gif" lazyload alt="0-Knowledge Mining with Scene Text for Fine-Grained Recognition">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/24/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/" target="_blank">
          0-Knowledge Mining with Scene Text for Fine-Grained Recognition
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/24/0-Knowledge-Mining-with-Scene-Text-for-Fine-Grained-Recognition/" target="_blank">
        <div>
          Knowledge Mining with Scene Text for Fine-Grained Recognition  基于场景文字知识挖掘的细粒度图像识别算法 CVPR 2022  背景场景文字的识别：和文档文本不同，场景文字具有稀疏性，通常以少许关键词的形式存在于自然环境中。通过稀疏的关键词，机器难以获取精准的语义。然而，人类能够较为充分地理解稀疏的场景文字。原因在于，人类具有大量的外部
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/24/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/" target="_blank">
          <img src="/../images/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/image-20240506183518983.png" srcset="/img/loading.gif" lazyload alt="0-Instance and Panoptic Segmentation Using Conditional Convolutions">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/24/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/" target="_blank">
          0-Instance and Panoptic Segmentation Using Conditional Convolutions
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/24/0-Instance-and-Panoptic-Segmentation-Using-Conditional-Convolutions/" target="_blank">
        <div>
          Instance and Panoptic Segmentation Using Conditional Convolutions  IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 45, NO. 1, JANUARY 2023  背景​	作者提出了一种实例和全景分割框架,其在COCO数据集上的表现优于其他几
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/21/0-Faster-R-CNN/" target="_blank">
          <img src="/../images/0-Faster-R-CNN/image-20240521164920800.png" srcset="/img/loading.gif" lazyload alt="0-Faster R-CNN">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/21/0-Faster-R-CNN/" target="_blank">
          0-Faster R-CNN
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/21/0-Faster-R-CNN/" target="_blank">
        <div>
          Faster R-CNN  发布于NIPS 2015  背景 R-CNN：使用选择性搜索算法生成候选区域，然后对每个区域进行卷积神经网络（CNN）特征提取和分类。这种方法的计算效率低，因为每个候选区域都要单独进行特征提取。 Fast R-CNN：改进了R-CNN，通过在整个图像上进行一次特征提取，然后使用区域兴趣（RoI）池化层对候选区域进行分类和回归。这减少了冗余计算，但候选区域的生成仍是一个瓶
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/05/16/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/" target="_blank">
          <img src="/../images/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/image-20240516203813793.png" srcset="/img/loading.gif" lazyload alt="0-CDDSA: Contrastive Domain Disentanglement and Style Augmentation for Generalizable Medical Image Segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/05/16/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/" target="_blank">
          0-CDDSA: Contrastive Domain Disentanglement and Style Augmentation for Generalizable Medical Image Segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/05/16/0-CDDSA-Contrastive-Domain-Disentanglement-and-Style-Augmentation-for-Generalizable-Medical-Image-Segmentation/" target="_blank">
        <div>
          CDDSA:用于广义医学图像分割的对比域去纠缠和风格增强  发表于：Medical Image Analysis  Volume 89 ,2023年10月, 102904   背景在分割未见过的临床医学图像的过程中，区分域特定特征和域不变特征的能力是实现域泛化（鼓励模型DG）的关键。现有的DG方法难以有效的解纠缠，从而获得高泛化能力，故提出了本文的方法：CDDSA框架（对比域去纠缠和风格增强），用
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/04/22/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/" target="_blank">
          <img src="/../images/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/image-20240422232943298.png" srcset="/img/loading.gif" lazyload alt="0-ImageNet Classification with Deep Convolutional Neural Networks">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/04/22/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/" target="_blank">
          0-ImageNet Classification with Deep Convolutional Neural Networks
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/04/22/0-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/" target="_blank">
        <div>
          AlexNet 2012 NIPS 背景为了从数以百万计的图像中学习出数千种的目标，需要一个具有很强学习能力的模型。尽管CNNs有效率的局部结构，但大规模地应用于高分辨率图像消耗资源仍然过多。本文介绍了一种可以进行图像识别的卷积神经网络，包含了大量的不常见和新的特征来提升网络性能，减少训练时间。 包含6千万个参数和65万个神经元，包含了5个卷积层，其中有几层后面跟着最大池化层，以及3个全连接层，最
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/04/22/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/" target="_blank">
          <img src="/../images/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/1713777253973.png" srcset="/img/loading.gif" lazyload alt="0-Very Deep Convolutional Networks For Large-Scale Image Recognition">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/04/22/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/" target="_blank">
          0-Very Deep Convolutional Networks For Large-Scale Image Recognition
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/04/22/0-Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition/" target="_blank">
        <div>
          用于大规模图像识别的超深卷积网络 2015 (VGG)  ImageNet Large-ScaleVisual Recognition Challenge (ILSVRC)：ImageNet大规模视觉识别挑战  背景卷积核到底该设置为多少？AlexNet采用了极大的size(11x11)、ZFNet将size调小了但仍然使用到了7x7，GoogLeNet同时使用了不同的filter size… 本
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/03/06/Leetcode/" target="_blank">
          <img src="/images/leetcode.jpeg" srcset="/img/loading.gif" lazyload alt="Leetcode">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/03/06/Leetcode/" target="_blank">
          Leetcode
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/03/06/Leetcode/" target="_blank">
        <div>
          简单 中等  困难    2024-03-06简单2917. 找出数组中的 K-or 值 位运算问题，考虑到K-or数只看第i位的值是否为1，并且需要知道的仅仅是超过k值的数组中的数，使用O(n)来解决此问题 简单的位运算模拟。 123456789101112131415161718class Solution &#123;public:    int findKOr(vector&lt;int&
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/C/" class="category-chain-item">C++</a>
  
  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/%E7%AE%97%E6%B3%95/">#算法</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/03/06/0-Fast-R-CNN/" target="_blank">
          <img src="/../images/0-Fast-R-CNN/image-20240321162127988.png" srcset="/img/loading.gif" lazyload alt="0-Fast R-CNN">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/03/06/0-Fast-R-CNN/" target="_blank">
          0-Fast R-CNN
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/03/06/0-Fast-R-CNN/" target="_blank">
        <div>
          Fast R-CNN 背景​	上回说到R-CNN，而Fast R-CNN是原作者在2015年发表的续作，性能比之前的R-CNN块9倍。目标检测要面临的两大问题是（1）需要处理的候选框过多（2）候选框的位置不精确要进行微调。 ​	这就不得不提到R-CNN的缺点：训练以及测试的过程复杂，需要大量的RAM，R-CNN网络需要对候选框进行形变操作后再输入CNN网络提取特征，形变会产生一些列问题。 相比于R
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">#目标检测</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/03/05/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/" target="_blank">
          <img src="/../images/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/image-20240305204216064.png" srcset="/img/loading.gif" lazyload alt="0-Rich feature hierarchies for accurate object detection and semantic segmentation">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/03/05/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/" target="_blank">
          0-Rich feature hierarchies for accurate object detection and semantic segmentation
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/03/05/0-Rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation/" target="_blank">
        <div>
          基于区域的卷积神经网络 (R-CNN) Rich feature hierarchies for accurate object detection and semantic segmentation  背景​	2013 年 11 月：R-CNN。给定输入图像，R-CNN 首先应用一种称为选择性搜索的机制来提取感兴趣区域(ROI)，其中每个 ROI 是一个可以表示图像中对象边界的矩形。根据场景的不
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">#目标检测</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/03/05/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="1-基础部分-3-读论文">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/03/05/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/" target="_blank">
          1-基础部分-3-读论文
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/03/05/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-3-%E8%AF%BB%E8%AE%BA%E6%96%87/" target="_blank">
        <div>
          学位论文摘要第一章绪论第二章材料与方法第三章结果与讨论(1)第四章结果与讨论(2)第五章结果与讨论(3)结论参考文献攻读硕士学位期间取得创新性成果学位论文原创性声明及使用授权致谢个人简历  功能：·题目→点睛，文章的极致浓缩;题目信息量≥50%文章的内容· ·摘要→浓缩的论文（重要程度超过论文主体) ·关键词→漂流瓶上的GPS(频道要一致) ·引言→背景（目的) -现状（那个等待修补的重要拼图）-
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/" class="category-chain-item">基础部分</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2024/03/05/0-Deep-Residual-Learning-for-Image-Recognition/" target="_blank">
          <img src="/../images/0-Deep-Residual-Learning-for-Image-Recognition/image-20240305100734044.png" srcset="/img/loading.gif" lazyload alt="0-Deep Residual Learning for Image Recognition">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2024/03/05/0-Deep-Residual-Learning-for-Image-Recognition/" target="_blank">
          0-Deep Residual Learning for Image Recognition
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2024/03/05/0-Deep-Residual-Learning-for-Image-Recognition/" target="_blank">
        <div>
          用于图像识别的深度残差学习ResNet  文章发表于2015年  背景越深的神经网络训练起来越发困难，利用残差学习框架，能够简化深层的的网络训练。根据输入来学习残差函数而非原神函数，在ImageNet数据集使用了152曾的网络来评价残差网络，具有很低的复杂度，并且多个ensemble在测试集上的错误率很低。 在深度学习神经网络的训练中，层次越深，训练越困难，优化越困难，并且会出现梯度消失&#x2F
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">#目标检测</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="markdown中的数学公式">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/" target="_blank">
          markdown中的数学公式
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/12/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/" target="_blank">
        <div>
          设置 math: true 符号大全   写法 符号 备注    \sin(x) $$\sin(x)$$ 正弦函数   \log(x) $$\log(x)$$ 对数函数   \sum_{i&#x3D;0}^n $$\sum_{i&#x3D;0}^n$$ 累加和   \prod_{i&#x3D;0}^n $$\prod_{i&#x3D;0}^n$$ 累积乘   \displaystyle $$\di
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/markdown/" class="category-chain-item">markdown</a>
  
  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/markdown/">#markdown</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/hello-world/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="HEXO GUIDE">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/hello-world/" target="_blank">
          HEXO GUIDE
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/hello-world/" target="_blank">
        <div>
          HEXO头操作分类文章\文章标签123456789101112131415并列分类，了解一下：categories:- [Linux]- [Tools]并列+子分类，再了解一下：categories:- [Linux, Hexo]- [Tools, PHP]categories:- Diarytags:- PS3- Games    归档文章如果只是想让文章在首页隐藏，但仍需要在归档分类页里展示，
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Linux/" class="category-chain-item">Linux</a>
  
  
    <span>></span>
    
  <a href="/categories/Linux/Hexo/" class="category-chain-item">Hexo</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/Linux/">#Linux</a>
            
              <a href="/tags/Hexo/">#Hexo</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="2-工具与软件-5-TensorFlow">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/" target="_blank">
          2-工具与软件-5-TensorFlow
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-5-TensorFlow/" target="_blank">
        <div>
          环境的安装首先去conda官网下载  conda  linux系统先使用bash安装 1sudo bash xxx.sh  安装后在pycharm配置conda环境，然后新建AI项目，选择conda，然后在所选择的解释器中安装tensorflow 选择pycharm自动安装（会自动安装其他依赖，十分方便）  所需安装：  conda tensorflow  如果你是N卡，可继续在项目终端中输入 1
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6/" class="category-chain-item">工具与软件</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/TensorFlow/">#TensorFlow</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="2-工具与软件-4-PyTorch">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/" target="_blank">
          2-工具与软件-4-PyTorch
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-4-PyTorch/" target="_blank">
        <div>
          安装CUDA UPDATEｔｉｍｅ； ９．２２　１８：００
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6/" class="category-chain-item">工具与软件</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/PyTorch/">#PyTorch</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="2-工具与软件-3-数据分析实战">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/" target="_blank">
          2-工具与软件-3-数据分析实战
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-3-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/" target="_blank">
        <div>
          使用Python进行数据分析，对其编程、库，以及⽤于数据分析的⼯具的相关学习与研究。  一.准备工作1 重要的Python库NumPyNumPy（Numerical Python的简称）是Python科学计算的基础包。详见它提供了以下功能（不限于此）：  快速⾼效的多维数组对象ndarray。 ⽤于对数组执⾏元素级计算以及直接对数组执⾏数学运算的函数。 ⽤于读写硬盘上基于数组的数据集的⼯具。 线
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6/" class="category-chain-item">工具与软件</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="2-工具与软件-2-Pandas">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/" target="_blank">
          2-工具与软件-2-Pandas
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-2-Pandas/" target="_blank">
        <div>
          安装在pycharm中对应的python解释器内安装pandas。  123import pandasprint(pandas.__version__)  Output: 1232.1.0进程已结束,退出代码0  Pandas 数据结构 - SeriesSeries 相当于表格中的一个列，函数如下： pandas.Series( data, index, dtype, name, copy)  d
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6/" class="category-chain-item">工具与软件</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/Pandas/">#Pandas</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="2-工具与软件-1-Numpy">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/" target="_blank">
          2-工具与软件-1-Numpy
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/2-%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6-1-Numpy/" target="_blank">
        <div>
          NumPy用于数据分析，提供了大量的维度数组与矩阵运算，NumPy 通常与 SciPy（Scientific Python）和 Matplotlib（绘图库）一起使用。 安装sudo apt-get install python3-numpy python3-scipy python3-matplotlib ipython ipython-notebook python-pandas python
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%BD%AF%E4%BB%B6/" class="category-chain-item">工具与软件</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/Numpy/">#Numpy</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="1-基础部分-2-数学基础">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/" target="_blank">
          1-基础部分-2-数学基础
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/" target="_blank">
        <div>
          回归最优化问题目标函数Error:$$E(\theta)&#x3D;\frac{1}{2} \sum_{i&#x3D;1}^n(y_i-f_\theta(x_i))^2$$i是指第 i 个训练数据.对每个训练数据的误差取平方之后，全部相加，然后乘以0.5 。这么做是为了找到使 E(θ) 的值最小的 θ。这样的问题称为最优化问题。 最速下降法：$$\theta_0 :&#x3D;\theta_0 -
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/" class="category-chain-item">基础部分</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/%E6%95%B0%E5%AD%A6/">#数学</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="1-基础部分-1-Python">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/" target="_blank">
          1-基础部分-1-Python
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/1-%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86-1-Python/" target="_blank">
        <div>
          Chapter 1  1.1 分解序列需要元素数量匹配，除了元组和列表，其余可迭代也可执行。 12345data = [&#x27;ACME&#x27;, 50, 91.9, (2023, 9, 9)]name, shares, price, data = dataprint(name, data)  Output1ACME (2023, 9, 9)  1.2 从可迭代对象中分解元素1234567
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/" class="category-chain-item">基础部分</a>
  
  

  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/Python/">#Python</a>
            
          </div>
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="3-机器学习-1-理论">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/" target="_blank">
          3-机器学习-1-理论
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1-%E7%90%86%E8%AE%BA/" target="_blank">
        <div>
          
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a>
  
  

      </span>
    
  
</span>

          </div>
        
        
      </div>
    </article>
  </div>

  <div class="row mx-auto index-card">
    
    
      <div class="col-12 col-md-4 m-auto index-img">
        <a href="/2023/09/08/Linux%E4%B8%8B%E7%9A%84%E9%94%90%E6%8D%B7%E8%AE%A4%E8%AF%81/" target="_blank">
          <img src="/images/example.jpeg" srcset="/img/loading.gif" lazyload alt="Linux下的锐捷认证">
        </a>
      </div>
    
    <article class="col-12 col-md-8 mx-auto index-info">
      <h2 class="index-header">
        
        <a href="/2023/09/08/Linux%E4%B8%8B%E7%9A%84%E9%94%90%E6%8D%B7%E8%AE%A4%E8%AF%81/" target="_blank">
          Linux下的锐捷认证
        </a>
      </h2>

      
      <a class="index-excerpt " href="/2023/09/08/Linux%E4%B8%8B%E7%9A%84%E9%94%90%E6%8D%B7%E8%AE%A4%E8%AF%81/" target="_blank">
        <div>
          12ping baidu.com -n 100|foreach -&quot; -f (Get-Date),$_&#125;#显示时间的PING指令  背景第一次使用校园网，才知道校园网原来需要登录认证①，并且限制设备②，在没有办理校内校园流量卡的情况下，原来的流量卡只有100kb&#x2F;s速度（办了校园卡之后，速度也仅有2M&#x2F;s），已经严重影响使用，另外校园全覆盖WiFi，同样需要
        </div>
      </a>

      <div class="index-btm post-metas">
        
        
          <div class="post-meta mr-3 d-flex align-items-center">
            <i class="iconfont icon-category"></i>
            

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Linux/" class="category-chain-item">Linux</a>
  
  

      </span>
    
  
</span>

          </div>
        
        
          <div class="post-meta">
            <i class="iconfont icon-tags"></i>
            
              <a href="/tags/Linux/">#Linux</a>
            
          </div>
        
      </div>
    </article>
  </div>





              </div>
            </div>
          </div>
        </div>
      </div>
    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       Copyright © 2024 WuYueYu | Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
